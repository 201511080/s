{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7375eb",
   "metadata": {},
   "source": [
    "```\n",
    "➜  s git:(master) pyspark\n",
    "Python 3.9.6 (default, Jun 29 2021, 06:20:32) \n",
    "[Clang 12.0.0 (clang-1200.0.32.29)] on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    "21/09/22 04:23:06 WARN Utils: Your hostname, kangui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.14 instead (on interface en0)\n",
    "21/09/22 04:23:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
    "WARNING: An illegal reflective access operation has occurred\n",
    "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
    "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
    "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
    "WARNING: All illegal access operations will be denied in a future release\n",
    "21/09/22 04:23:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.1.2\n",
    "      /_/\n",
    "\n",
    "Using Python version 3.9.6 (default, Jun 29 2021 06:20:32)\n",
    "Spark context Web UI available at http://192.168.0.14:4040\n",
    "Spark context available as 'sc' (master = local[*], app id = local-1632252188331).\n",
    "SparkSession available as 'spark'.\n",
    ">>> exit\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736e72a",
   "metadata": {},
   "source": [
    "# 문제 1: 오픈API를 통해 데이터를 5천 ~ 1만 건 정도 수집해서 파일로 저장한다 (초과해도 좋다).\n",
    "\n",
    "- 열린데이터, 공공데이터 또는 (할 수 있다면) 트위터와 같은 SNS, 댓글 등 적합한 소스를 자신이 선택한다.\n",
    "\n",
    "- 과정의 후반으로 가서, 이 데이터를 분석하는 과제가 주어지게 된다.\n",
    "\n",
    "- 프로그램에서 몇 건을 읽었는지와 마지막 줄을 화면 출력한다.\n",
    "\n",
    "- !dir 명령어로 파일이 존재하는지 출력한다. 1만 건 정도 저장되었으니 파일의 크기가 적당한지 가늠해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205b9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d52d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae9a0e27",
   "metadata": {},
   "source": [
    "# 문제 2: 노트북에서 pyspark 실행\n",
    "\n",
    "주피터 노트북을 실행한 후, 셀에서 아래 명령어를 실행하여 spark를 생성하고, 그 버전을 출력하세요.\n",
    "\n",
    "[In] spark.version\n",
    "\n",
    "[Out] '3.x.x'\n",
    "\n",
    "\n",
    "\n",
    "그리고 다음과 같이 버전을 출력한다.\n",
    "\n",
    "pyspark는 jdk가 설치되어 있어야 한다.\n",
    "\n",
    "!java --version   #spark v2.x는 java 8이 적당.\n",
    "\n",
    "!javac --version  #java 버전과 동일한지 확인한다.\n",
    "\n",
    "!python --version  \n",
    "\n",
    "!python3 --version # python 2, 3 멀티 버전이 설치된 경우에만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c2b44",
   "metadata": {},
   "source": [
    "붙여서 제출해라?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc457fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "붙여서 제출해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e168904f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ddfbef905b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8420ee3",
   "metadata": {},
   "source": [
    "# 문제 3: 다음 파일을 읽어서 RDD를 생성하고, 5줄을 화면출력하세요.\n",
    "\n",
    "결과가 깨져보인다면, 그 이유를 간단히 적으세요.\n",
    "\n",
    "* 1) 경기도 의정부시 인구현황 (파일명: ```경기도 의정부시_인구현황_20200904```)\n",
    "\n",
    "https://www.data.go.kr/data/15009613/fileData.do\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* 2) 제주특별자치도 서귀포시 내 연도별 65세이상 인구수 및 고령화비율, 노령화지수 현황 (파일명: ```제주특별자치도 서귀포시_고령화비율및노령화지수현황_20200623```)\n",
    "\n",
    "https://www.data.go.kr/data/15051545/fileData.do\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a7d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6056a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
