{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark DataFrame\n",
    "\n",
    "* Last updated 20200923WED1800\n",
    "    20191029_20170606_20170221_20161125\n",
    "\n",
    "## S.1 학습내용\n",
    "\n",
    "### S.1.1 목표\n",
    "\n",
    "* Spark DataFrame을 생성하고, API를 사용할 수 있다.\n",
    "* Spark SQL을 사용하여 데이터를 조회할 수 있다.\n",
    "* Spark 데이터를 MongoDB에 쓰고, 읽을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.1.2 목차\n",
    "* S.2 Jupyter Notebook에서 SparkSession 생성\n",
    "* S.3 DataFrame\n",
    "    * 특징\n",
    "    * Schema\n",
    "    * DataFrame의 API\n",
    "* S.4 DataFrame 생성\n",
    "* S.4.1 schema에서 생성하기\n",
    "* S.4.2 RDD에서 생성하기\n",
    "* S.4.3 Pandas\n",
    "* S.4.4 csv 파일 읽기\n",
    "* S.4.5 tsv 파일 읽기\n",
    "* S.4.6 JSON 파일 읽기\n",
    "* 문제: 월드컵 데이터 JSON\n",
    "* S.4.7 Parquet 파일 읽기, 쓰기\n",
    "* S.5 DataFrame API 사용해 보기\n",
    "    * 컬럼 추가 withColumn, 컬럼 삭제 Drop\n",
    "    * 사용자정의 함수 udf\n",
    "    * 컬럼명 변경 withColumnRenamed\n",
    "    * 그래프\n",
    "    * 컬럼 조회 select\n",
    "    * filter\n",
    "    * regexp_replace 컬럼의 내용 변경\n",
    "    * groupBy\n",
    "    * partition\n",
    "    * 통계 요약 describe\n",
    "    * 결측값\n",
    "* 문제: 년별 분기별 대여건수\n",
    "* S.6 Spark SQL\n",
    "* 문제 S-1: 네트워크에 불법적으로 침입하는 사용자의 분석\n",
    "* 문제 S-2: Twitter JSON 데이터 읽기\n",
    "* 문제 S-3: 뉴욕에서 출생한 신생아 분석\n",
    "* 문제 S-4: 우버 택시의 운행기록 분석\n",
    "* 문제 S-5: JDBC를 사용해서 데이터 읽기\n",
    "* S.7 MongoDB Spark connector\n",
    "* S.7.1 설정\n",
    "* S.7.2 uri \n",
    "* S.7.3 MongoDB Python API \n",
    "* S.7.4 연습으로 쓰기, 읽기\n",
    "* S.8 spark-submit\n",
    "* S.8.1 간단한 작업\n",
    "* S.8.2 MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## S.2 Jupyter Notebook에서 SparkSession 생성\n",
    "\n",
    "### Spark를 설치한 경우\n",
    "\n",
    "Spark를 설치했다면, Spark가 설치된 디렉토리를 SPARK_HOME으로 설정하고, 실행에 필요한 'py4j-0.10.1-src.zip', 'pyspark.zip' 라이브러리를 추가해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"]=os.path.join(os.environ['HOME'],'Downloads','spark-2.0.0-bin-hadoop2.7')\n",
    "os.environ[\"PYLIB\"]=os.path.join(os.environ[\"SPARK_HOME\"],'python','lib')\n",
    "sys.path.insert(0,os.path.join(os.environ[\"PYLIB\"],'py4j-0.10.1-src.zip'))\n",
    "sys.path.insert(0,os.path.join(os.environ[\"PYLIB\"],'pyspark.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "그러나 pyspark만을 설치한 경우에는, 별도로 라이브러리를 추가하지 않아도 된다.\n",
    "혹시 Python 2, 3 여러 버전이 설치된 경우에는 그 경로를 설정해 주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(conf=myConf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "print (spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.3 DataFrame\n",
    "\n",
    "### 특징\n",
    "\n",
    "DataFrame은 **행, 열로 구조화**된 데이터구조이다.\n",
    "관계형데이터베이스 RDB의 테이블이나 엑셀 쉬트sheet와 비슷하다.\n",
    "또는 Pandas 또는 R을 사용해 보았다면 거기서 제공되는 DataFrame과 유사하다.\n",
    "Apache Spark 1.0에서는 **SchemaRDD**라는 명칭으로 시험적으로 제공되었다. 이름에서 보듯이 RDD에 스키마를 얹어서 만든 개념이다.\n",
    "그러나 Spark의 DataFrame은 **대용량 데이터를 처리하기 위해 만들어진 프레임워크로 분산**해서 사용할 수 있게 고안되었다.\n",
    "\n",
    "앞서 사용했던 **RDD가 schema를 정하지 않는** 것과 달리, **DataFrame은 모델 schema**를 설정해서 사용을 한다. '열'에 대해 명칭 및 **데이터 타잎**을 가지고 있고, 이를 지켜서 데이터를 저장하게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Schema\n",
    "\n",
    "**Row**는 DataFrame의 행으로, 데이터 요소항목을 묶어서 구성한다. **Python list나 dict**를 사용하여 Row를 구성할 수 있다.\n",
    "**Column**은 DataFrame의 **열**이고, 다음과 같은 **데이터 타잎**을 가진다.\n",
    "\n",
    "```python\n",
    "- NullType\n",
    "- StringType\n",
    "- BinaryType\n",
    "- BooleanType\n",
    "- DateType\n",
    "- TimestampType\n",
    "- DoubleType\n",
    "- DecimalType\n",
    "- ShortType\n",
    "- ArrayType\n",
    "- MapType\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DataFrame의 API\n",
    "\n",
    "RDD와 마찬가지로 DataFrame을 구성하여 **머신러닝**의 입력데이터로 사용할 수 있다.\n",
    "현재 버전 2.0부터 RDD에 대한 지원은 줄여나가고, **버전 3.0 이후에는 DataFrame API를 공식적으로 지원**한다고 발표한 바 있다. RDD보다 우선적으로 사용하는 것이 좋겠다. 아래는 DataFrame에서 제공하는 일부 API이다.\n",
    "\n",
    "기능 | 설명 | 예제\n",
    "-------|-------|-------\n",
    "```json``` | json 파일에서 읽기 | ```spark.read.json(\"employee.json\")```\n",
    "```show``` | DataFrame에 로딩된 데이터 읽기 | ```df.show()```\n",
    "```schema``` | 데이터 schema 보기 | ```df.printSchema()```\n",
    "```select``` | 열을 선택 | ```df.select(\"name\")```\n",
    "```filter``` | 조건으로 선택하여 읽기 | ```df.filter(dfs(\"age\") > 23).show()```\n",
    "```groupBy``` | 그룹으로 나누기 | ```df.groupBy(\"age\").count().show()```\n",
    "```dropna``` | na를 삭제 | ```df.dropna()``` ```df.na.drop()```\n",
    "```fillna``` | na를 값으로 채우기 | ```fillna()```\n",
    "```count``` | 행 세기 | ```df.count()```\n",
    "```drop``` | 삭제 | ```df.drop(\"name\")```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.4 DataFrame 생성\n",
    "\n",
    "DataFrame은 관계형데이터베이스 RDB 테이블과 같이, schema를 정해서 생성한다.\n",
    "**schema를 정해주지 않으면, Spark가 자동으로 유추**하게 된다.\n",
    "RDD와 같이, 외부 파일 또는 배열과 같은 자료구조에서 읽어서 생성하고, 생성된 DataFrame은 분산하여 처리할 수 있게 된다.\n",
    "\n",
    "생성 방법 | 설명 | 함수\n",
    "----------|----------|----------\n",
    "**외부**에서 읽기 | Hive, csv, JSON, RDB, XML, Parquet, Apache Cassandra, RDD 등 | **```spark.createDataFrame()```** 또는 **```spark.read()```**\n",
    "**내부**에서 읽기 | Python list, dict 또는 ```pyspark.sql.Row``` 객체를 사용해서 한 줄씩 만들 수 있다. | **```spark.createDataFrame()```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```createDataFrame()``` 함수는 RDD 또는 List와 같은 데이터에서 DataFrame을 생성한다.\n",
    "반면에 ```spark.read()``` 함수는 csv, json과 같은 파일에서 데이터를 읽을 수 있고, 옵션을 설정해서 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.4.1 schema 생성하기\n",
    "\n",
    "DataFrame은 데이터 모델 schema를 정의하고, 각 컬럼의 명칭과 데이터타입을 정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 자동으로 인식하는 schema\n",
    "\n",
    "우선 단순하게 Python 자료구조를 사용해서 생성해 본다.\n",
    "아래 열이 3개인 데이터를 **```createDataFrame()```** 함수를 사용하여 넣어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myList=[('1','kim, js', 170),\n",
    "        ('1','lee, sm', 175),\n",
    "        ('2','lim, yg',180),\n",
    "        ('2','lee', 170)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "myDf=spark.createDataFrame(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이 경우 Spark가 **자동으로 schema를 설정**한다.\n",
    "```printSchema()``` 함수로 schema를 출력해 보기로 하자.\n",
    "* **컬럼**명은 **일련번호**를 가지고 생성된다. schema를 정하지 않았으므로, 열은 '_1', '_2'와 같이 명명된다.\n",
    "* **데이터 타잎**도 유추해서 생성한다. 올바르게 되지 않을 경우도 있다는 점에 유의한다. 아래에서 보듯이 컬럼 1 학년은 ```String```, 컬럼 2 이름은 ```String```, 컬럼 3 키는 ```long```으로 인식하고 있다.\n",
    "* nullable은 결측값이 허용되는지를 말하는 것이다. true이면 허용된다는 의미이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_1', '_2', '_3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 줄을 출력해 보자. 출력은 Row() 타입으로 앞서 정의한 schema와 일치하는 값을 포함하여 출력한다.\n",
    "즉 첫째, 둘째는 문자열로 세째는 long 타입이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(_1='1', _2='kim, js', _3=170)]\n"
     ]
    }
   ],
   "source": [
    "print (myDf.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 컬럼명 설정\n",
    "\n",
    "앞서 컬럼 Column을 정의하지 않고 DataFrame을 생성하였는데, 이번에는 **컬럼을 정해서** 생성하자.\n",
    "**```createDataFrame()```** 함수에 **인자로 컬럼명을 리스트 ```['year','name','height']```로** 정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['year','name','height']\n",
    "_myDf = spark.createDataFrame(myList, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'name', 'height']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_myDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 한 줄 출력해 보면, 컬럼명이 변경되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(year='1', name='kim, js', height=170)]\n"
     ]
    }
   ],
   "source": [
    "print (_myDf.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 100개를 생성해 보자.\n",
    "우선 데이터의 원천이 되는 names, items를 정의하자.\n",
    "여기서 하나씩 선택하여 데이터를 생성하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"kim\",\"lee\",\"lee\",\"lim\"]\n",
    "items = [\"espresso\",\"latte\",\"americano\",\"affocato\",\"long black\",\"macciato\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이 names, items 배열에서 **modulus**를 활용하여 하나씩 선택하여 데이터를 생성한다.\n",
    "**names**는 4개이므로 4로 나눈 나머지와 **items**는 6개이므로 6으로 나눈 나머지를 하나씩 선택하고 있다.\n",
    "그리고 컬럼명을 ```[\"name\",\"coffee\"]```으로 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coffeeDf = spark.createDataFrame([(names[i%4], items[i%6]) for i in range(100)],\\\n",
    "                           [\"name\",\"coffee\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동으로 생성된 schema가 데이터타입을 잘 집어내고 있다.\n",
    "name, coffee 모두 string이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- coffee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coffeeDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|name|    coffee|\n",
      "+----+----------+\n",
      "| kim|  espresso|\n",
      "| lee|     latte|\n",
      "| lee| americano|\n",
      "| lim|  affocato|\n",
      "| kim|long black|\n",
      "| lee|  macciato|\n",
      "| lee|  espresso|\n",
      "| lim|     latte|\n",
      "| kim| americano|\n",
      "| lee|  affocato|\n",
      "+----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coffeeDf.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Row 객체를 사용해서 생성\n",
    "\n",
    "**Row**를 사용해 보자.\n",
    "Row는 **이름(Column)이 붙여진 행**으로 **관계형데이터베이스 레코드 Record**와 같다. \n",
    "속성 명은 'year', 'name', 'height'로 명명한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "Person = Row('year','name', 'height')\n",
    "row1=Person('1','kim, js',170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "속성명을 읽을 때에는 **```row.key```** 또는 Python dict형식으로 **```row[key]```**와 같이 속성을 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row1:  1 kim, js 170\n"
     ]
    }
   ],
   "source": [
    "print (\"row1: \", row1.year, row1.name, row1.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "위에서 설정한 Row를 사용하여 DataFrame을 만들어 보자.\n",
    "**Python list에 Row를 넣어** 구성한다.\n",
    "첫번째는 앞서 만든 row1 객체를 넣을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myRows = [row1,\n",
    "          Person('1','lee, sm', 175),\n",
    "          Person('2','lim, yg',180),\n",
    "          Person('2','lee',170)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "myDf=spark.createDataFrame(myRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "printSchema()를 해보면, **데이터 타잎**은 string, long으로 Spark에서 **자동** 인식되었다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- height: long (nullable = true)\n",
      "\n",
      "None\n",
      "+----+-------+------+\n",
      "|year|   name|height|\n",
      "+----+-------+------+\n",
      "|   1|kim, js|   170|\n",
      "|   1|lee, sm|   175|\n",
      "|   2|lim, yg|   180|\n",
      "|   2|    lee|   170|\n",
      "+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (myDf.printSchema())\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### schema를 정의하고 생성\n",
    "\n",
    "모델 schema를 정하고, **데이터 타잎**을 정의해 DataFrame을 생성해 본다.\n",
    "**```StructType```**으로 구조체를 선언하고, 컬럼에 대해 **```StructField```**를 설정한다.\n",
    "* **컬럼**의 명칭\n",
    "* 앞서 소개했던 **데이터 타잎**\n",
    "* 마지막은 **NULL**이 허용되는지 여부\n",
    "\n",
    "```python\n",
    "StructType([\n",
    "    StructField(컬럼명, StringType(), True),\n",
    "    ...\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "mySchema=StructType([\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"height\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "앞서 **myRows**를 데이터로, **mySchema**에서는 컬럼 명과 데이터타잎을 정의하여 ```createDataFrame()```함수의 인자로 넘겨주고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDf=spark.createDataFrame(myRows, mySchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 설정한 데이터타입으로 설정되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year='1', name='kim, js', height=170)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### S.4.2 RDD에서 생성하기\n",
    "\n",
    "RDD는 schema가 정해지지 않은 비구조적 데이터이다.\n",
    "이와 같이 **schema를 정의하지 않으면, Spark는 schema를 유추**하게 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### schema 자동 인식\n",
    "\n",
    "RDD로부터 DataFrame을 생성할 수 있다. 이 경우 schema를 설정하지 않으면 자동으로 인식된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myList=[('1','kim, js',170), ('1','lee, sm', 175), ('2','lim, yg',180), ('2','lee',170)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myRdd = spark.sparkContext.parallelize(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```toDF()```로 변환하거나 직접 ```createDataFrame()``` 함수를 사용하여 DataFrame을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rddDf=myRdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "또는 RDD에서 DataFrame을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rddDf=spark.createDataFrame(myRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Row를 사용\n",
    "\n",
    "학년year는 앞에서는 **string**으로 인식되었다. 이번 예제에서는 **형변환**을 해 본다.\n",
    "RDD의 ```map()``` 함수를 사용하여 각 속성을 읽고 ```int()``` 함수로 형변환을 한다.\n",
    "각 속성에 명칭, year, name, height를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "_myRdd=myRdd.map(lambda x:Row(year=int(x[0]), name=x[1], height=int(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_myDf=spark.createDataFrame(_myRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- height: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=1, name='kim, js', height=170)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_myDf.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```Row()```를 사용하여 RDD를 생성할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "r1=Row(name=\"js1\", age=10)\n",
    "r2=Row(name=\"js2\", age=20)\n",
    "_myRdd=spark.sparkContext.parallelize([r1,r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='js1', age=10), Row(name='js2', age=20)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_myRdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "####  schema를 정의하고 생성\n",
    "\n",
    "앞서 보았듯이, schema를 정의하고 RDD에서 DataFrame을 생성할 수 있다.\n",
    "**```StructType```**을 선언하고,\n",
    "컬럼에 대해 **```StructField```**를 **컬럼명**, **데이터 타잎**, **NULL**이 허용되는지 여부를 설정한다.\n",
    "과거 버전에서는 컬럼명이 정렬되면서 age, name 순서가 변경되었다.\n",
    "현재는 **컬럼명을 정렬하지 않으므로, 순서대로** 아래와 같이 생성하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema=StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    #StructField(\"created\", TimestampType(), True)\n",
    "])\n",
    "_myDf=spark.createDataFrame(_myRdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "| js1| 10|\n",
      "| js2| 20|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "schema를 정해서 RDD로부터 DataFrame을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "myRdd=spark.sparkContext.parallelize([(1, 'kim', 50.0), (2, 'lee', 60.0), (3, 'park', 70.0)])\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"height\", DoubleType(), True)\n",
    "])\n",
    "_myDf = spark.createDataFrame(myRdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|height|\n",
      "+---+----+------+\n",
      "|  1| kim|  50.0|\n",
      "|  2| lee|  60.0|\n",
      "|  3|park|  70.0|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.4.3 Pandas\n",
    "\n",
    "Spark Dataframe은 다른 프로그래밍 언어에서도 분석도구로 많이 사용되는 형식이다.\n",
    "엑셀 스프레드쉬트와 비슷하다. 또한 최근 많이 사용되는 **R**의 Dataframe이나 **Python Pandas**를 예로 들 수 있다.\n",
    "Spark와 Pandas의 Dataframe을 비교하면,\n",
    "**Pandas**는 데이터 양이 적은 경우, Spark는 분산처리할 수 있으므로 빅데이터에 보다 적합하다.\n",
    "API를 사용하게 되면 Spark Dataframe과 Pandas 간에는 차이가 있다.\n",
    "\n",
    "구분 | DataFrame | Pandas\n",
    "-------|-------|-------\n",
    "csv 파일 읽기 | read.json() | read_csv()\n",
    "데이터타입 | inferschema=True 설정하면 추정 | 모두 strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataframe을 Pandas로 변환\n",
    "\n",
    "Spark Dataframe을 ```toPandas()``` 함수를 사용하여 **Pandas로 변환**할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>kim, js</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lee, sm</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lim, yg</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>lee</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _1       _2   _3\n",
       "0  1  kim, js  170\n",
       "1  1  lee, sm  175\n",
       "2  2  lim, yg  180\n",
       "3  2      lee  170"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pandas에서 csv 쓰기\n",
    "\n",
    "Dataframe을 **csv**파일로 내보내고 Pandas로 읽어보자.\n",
    "\n",
    "Dataframe을 csv로 쓰려면 라이브러리 ```com.databricks.spark.csv```를 사용해야 한다. **파일이 아니라 디렉토리가 생성**되고 그 안에 파일로 쓰여지게 된다. Pandas를 사용하면 우리가 보통 사용하는 하나의 파일로 쓰여진다.\n",
    "\n",
    "한 번 생성이 되면 덮어쓰기를 하지 않기 때문에, 다시 write() 할 경우에는 이전 디렉토리를 삭제하도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myDf.write.format('com.databricks.spark.csv').save(os.path.join('data','_myDf.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "-rw-r--r-- 1 jsl jsl 58  9월 16 15:56 part-00000-2627fdd4-7668-4ee9-840c-9e84fdadb86a-c000.csv\r\n",
      "-rw-r--r-- 1 jsl jsl  0  9월 16 15:56 _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/_myDf.csv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pandas를 이용하여 Dataframe을 csv파일로 내보낼 수 있다.\n",
    "\n",
    "```python\n",
    ",year,name,height\n",
    "0,1,\"kim, js\",170\n",
    "1,1,\"lee, sm\",175\n",
    "2,2,\"lim, yg\",180\n",
    "3,2,lee,170\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDf.toPandas().to_csv(os.path.join('data','myDf.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas에서 컬럼을 생성,삭제 해보자.\n",
    "recode - 현재 변수 값을 다시 줄 경우\n",
    "\n",
    "나라변 국제전화코드는 Japan: 81, South Korea: 82, Hong Kong: 852, Australia: 61을 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "icc = pd.DataFrame( { 'country': ['South Korea','Japan','Hong Kong'],'codes': [81, 82, 852] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  codes\n",
       "0  South Korea     81\n",
       "1        Japan     82\n",
       "2    Hong Kong    852"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전화코드가 81인 경우 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  codes\n",
       "0  South Korea     81"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc[icc['codes']==81]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### S.4.4 csv 파일에서 생성\n",
    "\n",
    "#### RDD에서 DataFrame\n",
    "\n",
    "앞서 RDD에서 읽었던 csv파일을 다시 읽어보자.\n",
    "\n",
    "```sparkContext.textFile()``` 함수로 읽은 파일은 RDD이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "cfile= os.path.join(\"data\", \"ds_spark_2cols.csv\")\n",
    "lines = spark.sparkContext.textFile(cfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "RDD에서 ```Row()```를 사용하여 Dataframe으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_col12 = lines.map(lambda l: l.split(\",\"))\n",
    "col12 = _col12.map(lambda p: Row(col1=int(p[0].strip()), col2=int(p[1].strip())))\n",
    "\n",
    "_myDf = spark.createDataFrame(col12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col1: long (nullable = true)\n",
      " |-- col2: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(col1=35, col2=2),\n",
       " Row(col1=40, col2=27),\n",
       " Row(col1=12, col2=38),\n",
       " Row(col1=15, col2=31),\n",
       " Row(col1=21, col2=1),\n",
       " Row(col1=14, col2=19),\n",
       " Row(col1=46, col2=1),\n",
       " Row(col1=10, col2=34),\n",
       " Row(col1=28, col2=3),\n",
       " Row(col1=48, col2=1),\n",
       " Row(col1=16, col2=2),\n",
       " Row(col1=30, col2=3),\n",
       " Row(col1=32, col2=2),\n",
       " Row(col1=48, col2=1),\n",
       " Row(col1=31, col2=2),\n",
       " Row(col1=22, col2=1),\n",
       " Row(col1=12, col2=3),\n",
       " Row(col1=39, col2=29),\n",
       " Row(col1=19, col2=37),\n",
       " Row(col1=25, col2=2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_myDf.printSchema()\n",
    "_myDf.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### DataFrame으로 직접 읽기\n",
    "\n",
    "format().load() 또는 csv() 함수로 csv 파일을 읽어서 DataFrame을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/ds_spark.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/ds_spark.csv\n",
    "1,2,3,4\n",
    "11,22,33,44\n",
    "111,222,333,444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### format load\n",
    "\n",
    "csv 패키지를 사용해서 읽어 본다. 우선 [Spark의 csv 패키지를 추가한다.](https://spark-packages.org/package/databricks/spark-csv) 패키지는 설정파일 ```spark-defaults.conf```에 추가할 수 있다.\n",
    "\n",
    "```python\n",
    "$ vim conf/spark-defaults.conf\n",
    "spark.jars.packages=com.databricks:spark-csv_2.11:1.5.0\n",
    "```\n",
    "\n",
    "```format(\"csv\").load(\"path\")```이라고 하고, options() 설정을 미리 넣을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = spark\\\n",
    "        .read\\\n",
    "        .format('com.databricks.spark.csv')\\\n",
    "        .options(header='true', inferschema='true', delimiter=',')\\\n",
    "        .load(os.path.join('data','ds_spark.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "|  1|  2|  3|  4|\n",
      "+---+---+---+---+\n",
      "| 11| 22| 33| 44|\n",
      "|111|222|333|444|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 1: integer (nullable = true)\n",
      " |-- 2: integer (nullable = true)\n",
      " |-- 3: integer (nullable = true)\n",
      " |-- 4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "inferschema를 제외하면, string으로 자동인식한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark\\\n",
    "        .read\\\n",
    "        .format('com.databricks.spark.csv')\\\n",
    "        .options(header='true', delimiter=',')\\\n",
    "        .load(os.path.join('data','ds_spark.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 1: string (nullable = true)\n",
      " |-- 2: string (nullable = true)\n",
      " |-- 3: string (nullable = true)\n",
      " |-- 4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### csv\n",
    "\n",
    "또는 \n",
    "```csv(\"path\")```로 직접 DataFrame으로 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "|  1|  2|  3|  4|\n",
      "+---+---+---+---+\n",
      "| 11| 22| 33| 44|\n",
      "|111|222|333|444|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark\\\n",
    "        .read\\\n",
    "        .options(header='true', inferschema='true', delimiter=',')\\\n",
    "        .csv(os.path.join('data', 'ds_spark.csv'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### S.4.5 tsv 파일 읽기\n",
    "\n",
    "tsv (tab-separated values)는 **Tab으로 분리된 파일**을 말한다.\n",
    "'\\t'이 포함되어 있는 경우, 혹시 string으로 데이터타잎을 설정하기도 한다 (과거 Spark 버전에서)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TAB은 whitespace이므로 그냥 split()을 해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.658985, 4.285136])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([float(x) for x in '1.658985\t4.285136'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "URL로 가서 http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights\n",
    "마우스로 긁어서 50행만 복사해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# %load data/ds_spark_heightweight.txt\n",
    "1\t65.78\t112.99\n",
    "2\t71.52\t136.49\n",
    "3\t69.40\t153.03\n",
    "4\t68.22\t142.34\n",
    "5\t67.79\t144.30\n",
    "6\t68.70\t123.30\n",
    "7\t69.80\t141.49\n",
    "8\t70.01\t136.46\n",
    "9\t67.90\t112.37\n",
    "10\t66.78\t120.67\n",
    "11\t66.49\t127.45\n",
    "12\t67.62\t114.14\n",
    "13\t68.30\t125.61\n",
    "14\t67.12\t122.46\n",
    "15\t68.28\t116.09\n",
    "16\t71.09\t140.00\n",
    "17\t66.46\t129.50\n",
    "18\t68.65\t142.97\n",
    "19\t71.23\t137.90\n",
    "20\t67.13\t124.04\n",
    "21\t67.83\t141.28\n",
    "22\t68.88\t143.54\n",
    "23\t63.48\t97.90\n",
    "24\t68.42\t129.50\n",
    "25\t67.63\t141.85\n",
    "26\t67.21\t129.72\n",
    "27\t70.84\t142.42\n",
    "28\t67.49\t131.55\n",
    "29\t66.53\t108.33\n",
    "30\t65.44\t113.89\n",
    "31\t69.52\t103.30\n",
    "32\t65.81\t120.75\n",
    "33\t67.82\t125.79\n",
    "34\t70.60\t136.22\n",
    "35\t71.80\t140.10\n",
    "36\t69.21\t128.75\n",
    "37\t66.80\t141.80\n",
    "38\t67.66\t121.23\n",
    "39\t67.81\t131.35\n",
    "40\t64.05\t106.71\n",
    "41\t68.57\t124.36\n",
    "42\t65.18\t124.86\n",
    "43\t69.66\t139.67\n",
    "44\t67.97\t137.37\n",
    "45\t65.98\t106.45\n",
    "46\t68.67\t128.76\n",
    "47\t66.88\t145.68\n",
    "48\t67.70\t116.82\n",
    "49\t69.82\t143.62\n",
    "50\t69.09\t134.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### RDD\n",
    "\n",
    "우선 RDD로 읽어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "_tRdd=spark.sparkContext\\\n",
    "    .textFile(os.path.join('data','ds_spark_heightweight.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "tsv는 '\\t'로 분리해도 되고, split() 함수는 <TAB>을 포함한 whitespace로 분할하게 되므로 그냥 두어도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tRdd=rdd.map(lambda x:x.split('\\t'))\n",
    "_tRddSplitted = _tRdd.map(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 형변환\n",
    "\n",
    "위 tsv 파일에서 생성한 RDD를 탭으로 분리하면서, ```float()```로 형변환을 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 65.78, 112.99]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#myRdd=rdd.map(lambda line:np.array([float(x) for x in line.split('\\t')]))\n",
    "tRdd=_tRdd.map(lambda line:[float(x) for x in line.split('\\t')])\n",
    "tRdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### schema 설정\n",
    "\n",
    "schema를 **자동으로 설정하면, string**으로 읽혀진다.\n",
    "schema를 설정한다고 해도, string -> integer, double로 형변환은 이루어지지 않는다.\n",
    "string의 **형변환을 명시적**으로 해주어야 한다.\n",
    "\n",
    "```python\n",
    "mySchema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"weight\", DoubleType(), True),\n",
    "    StructField(\"height\", DoubleType(), True)\n",
    "])\n",
    "myDf=spark.createDataFrame(myRdd, mySchema)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### DataFrame 생성\n",
    "\n",
    "위 tRdd로부터 컬럼명을 주어 DataFrame을 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tDfNamed = spark.createDataFrame(tRdd, [\"id\",\"weight\",\"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tDfNamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1.0, weight=65.78, height=112.99)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tDfNamed.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼을 split으로 분할\n",
    "\n",
    "text() 함수를 이용해서 파일을 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tDftxt = spark.read.text(os.path.join('data','ds_spark_heightweight.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<TAB>으로 분리되지 못해 전체를 변수명 value, 타입은 string으로 읽고 있어, 이를 분리해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tDftxt.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "pyspark.sql.functions은 함수이므로, import할 경우\n",
    "\n",
    "* ```import pyspark.sql.functions.split``` 이렇게 하지 않고, \n",
    "* ```from pyspark.sql.functions import split``` 이렇게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "split_col = split(tDftxt['value'], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "분리된 컬럼은 getItem() 함수로 가져와서 각 각 weight, height 컬럼이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'split(value, \\t, -1)[1]'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_col.getItem(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tDftxt = tDftxt.withColumn('weight', split_col.getItem(1))\n",
    "tDftxt = tDftxt.withColumn('height', split_col.getItem(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+------+\n",
      "|          value|weight|height|\n",
      "+---------------+------+------+\n",
      "| 1\t65.78\t112.99| 65.78|112.99|\n",
      "| 2\t71.52\t136.49| 71.52|136.49|\n",
      "| 3\t69.40\t153.03| 69.40|153.03|\n",
      "| 4\t68.22\t142.34| 68.22|142.34|\n",
      "| 5\t67.79\t144.30| 67.79|144.30|\n",
      "| 6\t68.70\t123.30| 68.70|123.30|\n",
      "| 7\t69.80\t141.49| 69.80|141.49|\n",
      "| 8\t70.01\t136.46| 70.01|136.46|\n",
      "| 9\t67.90\t112.37| 67.90|112.37|\n",
      "|10\t66.78\t120.67| 66.78|120.67|\n",
      "|11\t66.49\t127.45| 66.49|127.45|\n",
      "|12\t67.62\t114.14| 67.62|114.14|\n",
      "|13\t68.30\t125.61| 68.30|125.61|\n",
      "|14\t67.12\t122.46| 67.12|122.46|\n",
      "|15\t68.28\t116.09| 68.28|116.09|\n",
      "|16\t71.09\t140.00| 71.09|140.00|\n",
      "|17\t66.46\t129.50| 66.46|129.50|\n",
      "|18\t68.65\t142.97| 68.65|142.97|\n",
      "|19\t71.23\t137.90| 71.23|137.90|\n",
      "|20\t67.13\t124.04| 67.13|124.04|\n",
      "+---------------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tDftxt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv 함수로 tsv 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "|_c0|  _c1|   _c2|\n",
      "+---+-----+------+\n",
      "|  1|65.78|112.99|\n",
      "|  2|71.52|136.49|\n",
      "|  3| 69.4|153.03|\n",
      "|  4|68.22|142.34|\n",
      "|  5|67.79| 144.3|\n",
      "|  6| 68.7| 123.3|\n",
      "|  7| 69.8|141.49|\n",
      "|  8|70.01|136.46|\n",
      "|  9| 67.9|112.37|\n",
      "| 10|66.78|120.67|\n",
      "| 11|66.49|127.45|\n",
      "| 12|67.62|114.14|\n",
      "| 13| 68.3|125.61|\n",
      "| 14|67.12|122.46|\n",
      "| 15|68.28|116.09|\n",
      "| 16|71.09| 140.0|\n",
      "| 17|66.46| 129.5|\n",
      "| 18|68.65|142.97|\n",
      "| 19|71.23| 137.9|\n",
      "| 20|67.13|124.04|\n",
      "+---+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tDf = spark\\\n",
    "    .read\\\n",
    "    .options(header='false', inferschema='true', delimiter='\\t')\\\n",
    "    .csv(os.path.join('data', 'ds_spark_heightweight.txt'))\n",
    "tDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### S.4.6 JSON 파일에서 생성\n",
    "\n",
    "#### JSON\n",
    "JSON은 JavaScript Object Notation, 즉 자바스크립트에서 사용되는 표기법. 사람이 읽을 수 있는 텍스트로 표기하며, key-value 쌍으로 되어 있다.\n",
    "현재 널리 쓰이고 있어 XML 대용으로 널리 쓰이고 있다.\n",
    "Spark example 폴더에 있는 ```people.json``` JSON 파일이다.\n",
    "\n",
    "```python\n",
    "{\"name\":\"Michael\"}\n",
    "{\"name\":\"Andy\", \"age\":30}\n",
    "{\"name\":\"Justin\", \"age\":19}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트위터 데이터\n",
    "\n",
    "트위터 데이터는 JSON 형식을 가지고 있다.\n",
    "아래는 트윗 1개의 샘플이다.\n",
    "실제 트윗 데이터를 구할 수 없다면 아래 샘플을 파일로 저장한 후 사용하면 된다.\n",
    "\n",
    "```python\n",
    "{\"contributors\": null, \"truncated\": false, \"text\": \"RT @soompi: #SEVENTEEN’s Mingyu, Jin Se Yeon, And Leeteuk To MC For 2016 Super Seoul Dream Concert \\nhttps://t.co/1XRSaRBbE0 https://t.co/fi…\", \"is_quote_status\": false, \"in_reply_to_status_id\": null, \"id\": 801657325836763136, \"favorite_count\": 0, \"entities\": {\"symbols\": [], \"user_mentions\": [{\"id\": 17659206, \"indices\": [3, 10], \"id_str\": \"17659206\", \"screen_name\": \"soompi\", \"name\": \"Soompi\"}], \"hashtags\": [{\"indices\": [12, 22], \"text\": \"SEVENTEEN\"}], \"urls\": [{\"url\": \"https://t.co/1XRSaRBbE0\", \"indices\": [100, 123], \"expanded_url\": \"http://www.soompi.com/2016/11/20/seventeens-mingyu-jin-se-yeon-leeteuk-mc-dream-concert/\", \"display_url\": \"soompi.com/2016/11/20/sev…\"}]}, \"retweeted\": false, \"coordinates\": null, \"source\": \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\", \"in_reply_to_screen_name\": null, \"in_reply_to_user_id\": null, \"retweet_count\": 1487, \"id_str\": \"801657325836763136\", \"favorited\": false, \"retweeted_status\": {\"contributors\": null, \"truncated\": false, \"text\": \"#SEVENTEEN’s Mingyu, Jin Se Yeon, And Leeteuk To MC For 2016 Super Seoul Dream Concert \\nhttps://t.co/1XRSaRBbE0 https://t.co/fifXHpF8or\", \"is_quote_status\": false, \"in_reply_to_status_id\": null, \"id\": 800593781586132993, \"favorite_count\": 1649, \"entities\": {\"symbols\": [], \"user_mentions\": [], \"hashtags\": [{\"indices\": [0, 10], \"text\": \"SEVENTEEN\"}], \"urls\": [{\"url\": \"https://t.co/1XRSaRBbE0\", \"indices\": [88, 111], \"expanded_url\": \"http://www.soompi.com/2016/11/20/seventeens-mingyu-jin-se-yeon-leeteuk-mc-dream-concert/\", \"display_url\": \"soompi.com/2016/11/20/sev…\"}], \"media\": [{\"expanded_url\": \"https://twitter.com/soompi/status/800593781586132993/photo/1\", \"display_url\": \"pic.twitter.com/fifXHpF8or\", \"url\": \"https://t.co/fifXHpF8or\", \"media_url_https\": \"https://pbs.twimg.com/media/CxxHMk8UsAA4cUT.jpg\", \"id_str\": \"800593115165798400\", \"sizes\": {\"small\": {\"h\": 382, \"resize\": \"fit\", \"w\": 680}, \"large\": {\"h\": 449, \"resize\": \"fit\", \"w\": 800}, \"medium\": {\"h\": 449, \"resize\": \"fit\", \"w\": 800}, \"thumb\": {\"h\": 150, \"resize\": \"crop\", \"w\": 150}}, \"indices\": [112, 135], \"type\": \"photo\", \"id\": 800593115165798400, \"media_url\": \"http://pbs.twimg.com/media/CxxHMk8UsAA4cUT.jpg\"}]}, \"retweeted\": false, \"coordinates\": null, \"source\": \"<a href=\\\"https://about.twitter.com/products/tweetdeck\\\" rel=\\\"nofollow\\\">TweetDeck</a>\", \"in_reply_to_screen_name\": null, \"in_reply_to_user_id\": null, \"retweet_count\": 1487, \"id_str\": \"800593781586132993\", \"favorited\": false, \"user\": {\"follow_request_sent\": false, \"has_extended_profile\": true, \"profile_use_background_image\": true, \"default_profile_image\": false, \"id\": 17659206, \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/699864769/1cdde0a85f5c0a994ae1fb06d545a5ec.png\", \"verified\": true, \"translator_type\": \"none\", \"profile_text_color\": \"999999\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/792117259489583104/4khJk3zz_normal.jpg\", \"profile_sidebar_fill_color\": \"000000\", \"entities\": {\"url\": {\"urls\": [{\"url\": \"http://t.co/3evT80UlR9\", \"indices\": [0, 22], \"expanded_url\": \"http://www.soompi.com\", \"display_url\": \"soompi.com\"}]}, \"description\": {\"urls\": []}}, \"followers_count\": 987867, \"profile_sidebar_border_color\": \"000000\", \"id_str\": \"17659206\", \"profile_background_color\": \"1E1E1E\", \"listed_count\": 3982, \"is_translation_enabled\": true, \"utc_offset\": -28800, \"statuses_count\": 80038, \"description\": \"The original K-pop community. We take gifs, OTPs, and reporting on your bias' fashion choices seriously. But not rumors. Ain't nobody got time for that.\", \"friends_count\": 3532, \"location\": \"Worldwide\", \"profile_link_color\": \"31B6F4\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/792117259489583104/4khJk3zz_normal.jpg\", \"following\": false, \"geo_enabled\": false, \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/17659206/1478803767\", \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/699864769/1cdde0a85f5c0a994ae1fb06d545a5ec.png\", \"screen_name\": \"soompi\", \"lang\": \"en\", \"profile_background_tile\": true, \"favourites_count\": 1493, \"name\": \"Soompi\", \"notifications\": false, \"url\": \"http://t.co/3evT80UlR9\", \"created_at\": \"Wed Nov 26 20:48:27 +0000 2008\", \"contributors_enabled\": false, \"time_zone\": \"Pacific Time (US & Canada)\", \"protected\": false, \"default_profile\": false, \"is_translator\": false}, \"geo\": null, \"in_reply_to_user_id_str\": null, \"possibly_sensitive\": false, \"lang\": \"en\", \"created_at\": \"Mon Nov 21 06:56:46 +0000 2016\", \"in_reply_to_status_id_str\": null, \"place\": null, \"extended_entities\": {\"media\": [{\"expanded_url\": \"https://twitter.com/soompi/status/800593781586132993/photo/1\", \"display_url\": \"pic.twitter.com/fifXHpF8or\", \"url\": \"https://t.co/fifXHpF8or\", \"media_url_https\": \"https://pbs.twimg.com/media/CxxHMk8UsAA4cUT.jpg\", \"id_str\": \"800593115165798400\", \"sizes\": {\"small\": {\"h\": 382, \"resize\": \"fit\", \"w\": 680}, \"large\": {\"h\": 449, \"resize\": \"fit\", \"w\": 800}, \"medium\": {\"h\": 449, \"resize\": \"fit\", \"w\": 800}, \"thumb\": {\"h\": 150, \"resize\": \"crop\", \"w\": 150}}, \"indices\": [112, 135], \"type\": \"photo\", \"id\": 800593115165798400, \"media_url\": \"http://pbs.twimg.com/media/CxxHMk8UsAA4cUT.jpg\"}]}, \"metadata\": {\"iso_language_code\": \"en\", \"result_type\": \"recent\"}}, \"user\": {\"follow_request_sent\": false, \"has_extended_profile\": false, \"profile_use_background_image\": true, \"default_profile_image\": true, \"id\": 791090169818521600, \"profile_background_image_url_https\": null, \"verified\": false, \"translator_type\": \"none\", \"profile_text_color\": \"333333\", \"profile_image_url_https\": \"https://abs.twimg.com/sticky/default_profile_images/default_profile_6_normal.png\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"entities\": {\"description\": {\"urls\": []}}, \"followers_count\": 0, \"profile_sidebar_border_color\": \"C0DEED\", \"id_str\": \"791090169818521600\", \"profile_background_color\": \"F5F8FA\", \"listed_count\": 0, \"is_translation_enabled\": false, \"utc_offset\": null, \"statuses_count\": 96, \"description\": \"\", \"friends_count\": 7, \"location\": \"\", \"profile_link_color\": \"1DA1F2\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_6_normal.png\", \"following\": false, \"geo_enabled\": false, \"profile_background_image_url\": null, \"screen_name\": \"enriquesanq\", \"lang\": \"es\", \"profile_background_tile\": false, \"favourites_count\": 161, \"name\": \"Enrique santos\", \"notifications\": false, \"url\": null, \"created_at\": \"Wed Oct 26 01:32:49 +0000 2016\", \"contributors_enabled\": false, \"time_zone\": null, \"protected\": false, \"default_profile\": true, \"is_translator\": false}, \"geo\": null, \"in_reply_to_user_id_str\": null, \"possibly_sensitive\": false, \"lang\": \"en\", \"created_at\": \"Thu Nov 24 05:22:55 +0000 2016\", \"in_reply_to_status_id_str\": null, \"place\": null, \"metadata\": {\"iso_language_code\": \"en\", \"result_type\": \"recent\"}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파일에서 트윗 읽기\n",
    "\n",
    "그러나 JSON파일은 **JSON이 아니라 문자열**이다. 파일에서 읽은 후 **JSON으로 변환**을 해야 한다.\n",
    "트윗은 '\\n'으로 하나씩 구분되어 있고 ```readlines()``` 함수로 전체를 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "_jfname=os.path.join('src','ds_twitter_seoul_3.json')\n",
    "with open(_jfname, 'rb') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data_json_str = json.loads(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas에서  트윗 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "위 Tweet데이터는 json형식이다. 따라서 list 구조로 만들어 주려면, 앞 뒤로 대괄호 ```[ ]```를 넣고, 각 tweet은 컴마로 연결한다.\n",
    "```join()``` 함수는 인자를 구분자 \",\"로 병합한다.\n",
    "\n",
    "```python\n",
    "\",\".join([\"A\", \"B\", \"C\"]) # A,B,C\n",
    "```\n",
    "\n",
    "data는 bytes이고, 이를 join()하는 함수는 str을 대상으로 하기 때문에, 문자열에 ```b```를 붙여 bytes로 변환한 후 연결한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_json_str = b\"[\" + b','.join(data) + b\"]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 JSON으로 변환이 되지 않았고, 문자열 전체 길이를 알아 보자. 파일의 크기를 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11310468"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Pandas로 읽어 보자. Pandas 라이브러리에서 제공하는 read_json()함수를 사용한다.\n",
    "\n",
    "read_json()에 경로를 넘겨주어도 되지 않나??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweetPd = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape()은 행과 열의 갯수를 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 30)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetPd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count() 함수는 행의 갯수를 나타내는데, 숫자가 서로 다른 것은 비워있는 경우가 서로 다르기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contributors                    0\n",
      "truncated                    2013\n",
      "text                         2013\n",
      "is_quote_status              2013\n",
      "in_reply_to_status_id         131\n",
      "id                           2013\n",
      "favorite_count               2013\n",
      "entities                     2013\n",
      "retweeted                    2013\n",
      "coordinates                    55\n",
      "source                       2013\n",
      "in_reply_to_screen_name       153\n",
      "in_reply_to_user_id           153\n",
      "retweet_count                2013\n",
      "id_str                       2013\n",
      "favorited                    2013\n",
      "retweeted_status             1304\n",
      "user                         2013\n",
      "geo                            55\n",
      "in_reply_to_user_id_str       153\n",
      "possibly_sensitive           1097\n",
      "lang                         2013\n",
      "created_at                   2013\n",
      "in_reply_to_status_id_str     131\n",
      "place                          65\n",
      "metadata                     2013\n",
      "extended_entities             506\n",
      "quoted_status_id              133\n",
      "quoted_status                  19\n",
      "quoted_status_id_str          133\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (tweetPd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컬럼 'id'를 10개만 읽어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    801657325836763136\n",
       "1    801657325677400064\n",
       "2    801657307637678080\n",
       "3    801657305628430336\n",
       "4    801657297449586688\n",
       "5    801657287697895424\n",
       "6    801657280760397824\n",
       "7    801657276788523008\n",
       "8    801657268177604608\n",
       "9    801657258400616449\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetPd['id'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame에서 트윗 읽기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jfile= os.path.join('src','ds_twitter_seoul_3.json')\n",
    "\n",
    "tweetDf= spark.read.json(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- contributors: string (nullable = true)\n",
      " |-- coordinates: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- hashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- symbols: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- urls: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |-- extended_entities: struct (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |-- source_user: struct (nullable = true)\n",
      " |    |    |    |    |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |    |-- entities: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- description: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- favourites_count: long (nullable = true)\n",
      " |    |    |    |    |    |-- follow_request_sent: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |    |    |    |-- following: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |    |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- has_extended_profile: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- is_translation_enabled: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- is_translator: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- lang: string (nullable = true)\n",
      " |    |    |    |    |    |-- listed_count: long (nullable = true)\n",
      " |    |    |    |    |    |-- location: string (nullable = true)\n",
      " |    |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |    |-- notifications: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- profile_background_color: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_image_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_link_color: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_text_color: string (nullable = true)\n",
      " |    |    |    |    |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |    |    |    |-- statuses_count: long (nullable = true)\n",
      " |    |    |    |    |    |-- time_zone: string (nullable = true)\n",
      " |    |    |    |    |    |-- translator_type: string (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- utc_offset: long (nullable = true)\n",
      " |    |    |    |    |    |-- verified: boolean (nullable = true)\n",
      " |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- duration_millis: long (nullable = true)\n",
      " |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- bitrate: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- favorited: boolean (nullable = true)\n",
      " |-- geo: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      " |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |-- in_reply_to_status_id: long (nullable = true)\n",
      " |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |-- in_reply_to_user_id: long (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- is_quote_status: boolean (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- iso_language_code: string (nullable = true)\n",
      " |    |-- result_type: string (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- contained_within: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- full_name: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |-- possibly_sensitive: boolean (nullable = true)\n",
      " |-- quoted_status: struct (nullable = true)\n",
      " |    |-- contributors: string (nullable = true)\n",
      " |    |-- coordinates: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- symbols: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |-- extended_entities: struct (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- favorite_count: long (nullable = true)\n",
      " |    |-- favorited: boolean (nullable = true)\n",
      " |    |-- geo: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |    |-- in_reply_to_status_id: long (nullable = true)\n",
      " |    |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: long (nullable = true)\n",
      " |    |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |    |-- is_quote_status: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- metadata: struct (nullable = true)\n",
      " |    |    |-- iso_language_code: string (nullable = true)\n",
      " |    |    |-- result_type: string (nullable = true)\n",
      " |    |-- place: struct (nullable = true)\n",
      " |    |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- contained_within: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- country_code: string (nullable = true)\n",
      " |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- place_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |-- possibly_sensitive: boolean (nullable = true)\n",
      " |    |-- quoted_status_id: long (nullable = true)\n",
      " |    |-- quoted_status_id_str: string (nullable = true)\n",
      " |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- retweeted: boolean (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- truncated: boolean (nullable = true)\n",
      " |    |-- user: struct (nullable = true)\n",
      " |    |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- entities: struct (nullable = true)\n",
      " |    |    |    |-- description: struct (nullable = true)\n",
      " |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- url: struct (nullable = true)\n",
      " |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- favourites_count: long (nullable = true)\n",
      " |    |    |-- follow_request_sent: boolean (nullable = true)\n",
      " |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |-- following: boolean (nullable = true)\n",
      " |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |    |-- has_extended_profile: boolean (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- is_translation_enabled: boolean (nullable = true)\n",
      " |    |    |-- is_translator: boolean (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- listed_count: long (nullable = true)\n",
      " |    |    |-- location: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- notifications: boolean (nullable = true)\n",
      " |    |    |-- profile_background_color: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_link_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |    |-- profile_text_color: string (nullable = true)\n",
      " |    |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- statuses_count: long (nullable = true)\n",
      " |    |    |-- time_zone: string (nullable = true)\n",
      " |    |    |-- translator_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- utc_offset: long (nullable = true)\n",
      " |    |    |-- verified: boolean (nullable = true)\n",
      " |-- quoted_status_id: long (nullable = true)\n",
      " |-- quoted_status_id_str: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- retweeted_status: struct (nullable = true)\n",
      " |    |-- contributors: string (nullable = true)\n",
      " |    |-- coordinates: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- symbols: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |-- extended_entities: struct (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- duration_millis: long (nullable = true)\n",
      " |    |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- bitrate: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- favorite_count: long (nullable = true)\n",
      " |    |-- favorited: boolean (nullable = true)\n",
      " |    |-- geo: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |    |-- in_reply_to_status_id: long (nullable = true)\n",
      " |    |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: long (nullable = true)\n",
      " |    |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |    |-- is_quote_status: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- metadata: struct (nullable = true)\n",
      " |    |    |-- iso_language_code: string (nullable = true)\n",
      " |    |    |-- result_type: string (nullable = true)\n",
      " |    |-- place: struct (nullable = true)\n",
      " |    |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- contained_within: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- country_code: string (nullable = true)\n",
      " |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- place_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |-- possibly_sensitive: boolean (nullable = true)\n",
      " |    |-- quoted_status: struct (nullable = true)\n",
      " |    |    |-- contributors: string (nullable = true)\n",
      " |    |    |-- coordinates: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- entities: struct (nullable = true)\n",
      " |    |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- symbols: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- extended_entities: struct (nullable = true)\n",
      " |    |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- favorite_count: long (nullable = true)\n",
      " |    |    |-- favorited: boolean (nullable = true)\n",
      " |    |    |-- geo: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |    |    |-- in_reply_to_status_id: long (nullable = true)\n",
      " |    |    |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: long (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |    |    |-- is_quote_status: boolean (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- metadata: struct (nullable = true)\n",
      " |    |    |    |-- iso_language_code: string (nullable = true)\n",
      " |    |    |    |-- result_type: string (nullable = true)\n",
      " |    |    |-- place: struct (nullable = true)\n",
      " |    |    |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- contained_within: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- country: string (nullable = true)\n",
      " |    |    |    |-- country_code: string (nullable = true)\n",
      " |    |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- place_type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- possibly_sensitive: boolean (nullable = true)\n",
      " |    |    |-- quoted_status_id: long (nullable = true)\n",
      " |    |    |-- quoted_status_id_str: string (nullable = true)\n",
      " |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- retweeted: boolean (nullable = true)\n",
      " |    |    |-- source: string (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- truncated: boolean (nullable = true)\n",
      " |    |    |-- user: struct (nullable = true)\n",
      " |    |    |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |-- entities: struct (nullable = true)\n",
      " |    |    |    |    |-- description: struct (nullable = true)\n",
      " |    |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |    |-- url: struct (nullable = true)\n",
      " |    |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- favourites_count: long (nullable = true)\n",
      " |    |    |    |-- follow_request_sent: boolean (nullable = true)\n",
      " |    |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |    |-- following: boolean (nullable = true)\n",
      " |    |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |    |    |-- has_extended_profile: boolean (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- is_translation_enabled: boolean (nullable = true)\n",
      " |    |    |    |-- is_translator: boolean (nullable = true)\n",
      " |    |    |    |-- lang: string (nullable = true)\n",
      " |    |    |    |-- listed_count: long (nullable = true)\n",
      " |    |    |    |-- location: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- notifications: boolean (nullable = true)\n",
      " |    |    |    |-- profile_background_color: string (nullable = true)\n",
      " |    |    |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |    |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |    |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |    |-- profile_image_url: string (nullable = true)\n",
      " |    |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |    |-- profile_link_color: string (nullable = true)\n",
      " |    |    |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |    |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |    |    |-- profile_text_color: string (nullable = true)\n",
      " |    |    |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |    |-- statuses_count: long (nullable = true)\n",
      " |    |    |    |-- time_zone: string (nullable = true)\n",
      " |    |    |    |-- translator_type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- utc_offset: long (nullable = true)\n",
      " |    |    |    |-- verified: boolean (nullable = true)\n",
      " |    |-- quoted_status_id: long (nullable = true)\n",
      " |    |-- quoted_status_id_str: string (nullable = true)\n",
      " |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- retweeted: boolean (nullable = true)\n",
      " |    |-- scopes: struct (nullable = true)\n",
      " |    |    |-- followers: boolean (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- truncated: boolean (nullable = true)\n",
      " |    |-- user: struct (nullable = true)\n",
      " |    |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- entities: struct (nullable = true)\n",
      " |    |    |    |-- description: struct (nullable = true)\n",
      " |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- url: struct (nullable = true)\n",
      " |    |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- favourites_count: long (nullable = true)\n",
      " |    |    |-- follow_request_sent: boolean (nullable = true)\n",
      " |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |-- following: boolean (nullable = true)\n",
      " |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |    |-- has_extended_profile: boolean (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- is_translation_enabled: boolean (nullable = true)\n",
      " |    |    |-- is_translator: boolean (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- listed_count: long (nullable = true)\n",
      " |    |    |-- location: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- notifications: boolean (nullable = true)\n",
      " |    |    |-- profile_background_color: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_link_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |    |-- profile_text_color: string (nullable = true)\n",
      " |    |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- statuses_count: long (nullable = true)\n",
      " |    |    |-- time_zone: string (nullable = true)\n",
      " |    |    |-- translator_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- utc_offset: long (nullable = true)\n",
      " |    |    |-- verified: boolean (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- truncated: boolean (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- description: struct (nullable = true)\n",
      " |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- url: struct (nullable = true)\n",
      " |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: boolean (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: boolean (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- has_extended_profile: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translation_enabled: boolean (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: boolean (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- translator_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: long (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark DataFrame에서도 위 Pandas와 컬럼 'id'를 10개 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|                id|\n",
      "+------------------+\n",
      "|801657325836763136|\n",
      "|801657325677400064|\n",
      "|801657307637678080|\n",
      "|801657305628430336|\n",
      "|801657297449586688|\n",
      "|801657287697895424|\n",
      "|801657280760397824|\n",
      "|801657276788523008|\n",
      "|801657268177604608|\n",
      "|801657258400616449|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDf.select('id').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 문제: 월드컵 데이터 JSON\n",
    "\n",
    "### URL에서 JSON 읽기\n",
    "\n",
    "웹에서 읽는 JSON은 문자열이라는 점에 유의한다. 따라서 json()함수로 변환하는 것이 필요하다.\n",
    "```python\n",
    "[\n",
    "  {\n",
    "    \"Competition\": \"World Cup\",\n",
    "    \"Year\": 1930,\n",
    "    \"Team\": \"Argentina\",\n",
    "    \"Number\": \"\",\n",
    "    \"Position\": \"GK\",\n",
    "    \"FullName\": \"Ãngel Bossio\",\n",
    "    \"Club\": \"Club AtlÃ©tico Talleres de Remedios de Escalada\",\n",
    "    \"ClubCountry\": \"Argentina\",\n",
    "    \"DateOfBirth\": \"1905-5-5\",\n",
    "    \"IsCaptain\": false\n",
    "  },\n",
    "  {\n",
    "    \"Competition\": \"World Cup\",\n",
    "    ...\n",
    "    \"IsCaptain\": false\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r=requests.get(\"https://raw.githubusercontent.com/jokecamp/FootballData/master/World%20Cups/all-world-cup-players.json\")\n",
    "wc=r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wc는 아래와 같이 ```[ {...}, {...}, ...]```, 즉 배열내에 dictionary가 컴마로 연결되어 있다.\n",
    "이와 같이 파일에서 읽을 경우, 그 구조를 정확하게 이해하는 것이 중요하다.\n",
    "\n",
    "```python\n",
    "[{'Competition': 'World Cup',\n",
    "  'Year': 1930,\n",
    "  'Team': 'Argentina',\n",
    "  'Number': '',\n",
    "  'Position': 'GK',\n",
    "  'FullName': 'Ãngel Bossio',\n",
    "  'Club': 'Club AtlÃ©tico Talleres de Remedios de Escalada',\n",
    "  'ClubCountry': 'Argentina',\n",
    "  'DateOfBirth': '1905-5-5',\n",
    "  'IsCaptain': False},\n",
    " {'Competition': 'World Cup',\n",
    "  'Year': 1930,\n",
    "  'Team': 'Argentina',\n",
    "  'Number': '',\n",
    "  'Position': 'GK',\n",
    "  'FullName': 'Juan Botasso',\n",
    "  'Club': 'Quilmes AtlÃ©tico Club',\n",
    "  'ClubCountry': 'Argentina',\n",
    "  'DateOfBirth': '1908-10-23',\n",
    "  'IsCaptain': False},\n",
    " ... ]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print (type(wc), type(wc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Competition': 'World Cup',\n",
       " 'Year': 1930,\n",
       " 'Team': 'Argentina',\n",
       " 'Number': '',\n",
       " 'Position': 'GK',\n",
       " 'FullName': 'Ãngel Bossio',\n",
       " 'Club': 'Club AtlÃ©tico Talleres de Remedios de Escalada',\n",
       " 'ClubCountry': 'Argentina',\n",
       " 'DateOfBirth': '1905-5-5',\n",
       " 'IsCaptain': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DataFrame 생성\n",
    "\n",
    "위 ```wc```는 JSON을 포함하는 리스트이다.\n",
    "JSON은 key, value로 구성되어, 컬럼명을 key에서 가져올 수 있다.\n",
    "이전 버전에서는 가능했으나, 현재는 Python dict로부터 DataFrame을 생성하려면 아래와 같이 pyspark.sql.Row를 활용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsl/.local/lib/python3.6/site-packages/pyspark/sql/session.py:378: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    }
   ],
   "source": [
    "_wcDf=spark.createDataFrame(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Row를 이용해서 Dictionary에서 DataFrame 생성하기\n",
    "\n",
    "앞서 살펴보았듯이, wc는 리스트이고 그 요소는 dictionary이다.\n",
    "dictionary를 풀어서 Row에 넘겨주어야 한다.\n",
    "우선 Python에서 어떻게 인자를 풀어 넘겨주는지 배워보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 복수의 함수 인자 ```*args```, ```**args```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def f(*args):\n",
    "    print((args))\n",
    "f(0, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인자가 리스트, dictinary와 같은 구조를 가지고 있고, 함수 호출할 때 풀어야할 필요가 있을 경우에 별표 연산자를 사용한다.\n",
    "\n",
    "* 별표 1개 ```*```: 리스트에서 인자 풀어내기\n",
    "\n",
    "range() 함수는 시작과 끝을 인자로 가지는 함수이다.\n",
    "시작, 끝 변수가 따로 없을 경우, 리스트를 넘겨주고 여기서 풀어서 하나씩 인자를 사용할 경우 ```*```를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList = [1, 6]\n",
    "list(range(*myList))  # unpack args and get 1 for the start and 6 for the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 별표 2 개 ```**```: dictionary에서 인자 풀어내기\n",
    "\n",
    "dictionary를 넘겨주고 여기서 key, value를 하나씩 사용할 경우 ```**```를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsl in 2020\n"
     ]
    }
   ],
   "source": [
    "def printCapital(name, year):\n",
    "    print(f\"{name} in {year}\")\n",
    "\n",
    "myDict = {\"name\": \"jsl\", \"year\": 2020}\n",
    "printCapital(**myDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dictionary인자를 풀어서 Row에 넘겨주기\n",
    "\n",
    "반복문으로 하나의 dictionary를 가져와 ```Row()```를 생성하고 있다.\n",
    "별표 2개를 겹쳐 쓴 ```**```는 dictionary를 풀어서 Row 생성자에 넘겨주고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "wcDf = spark.createDataFrame(Row(**x) for x in wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Competition: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Number: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- FullName: string (nullable = true)\n",
      " |-- Club: string (nullable = true)\n",
      " |-- ClubCountry: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- IsCaptain: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 잘 읽혔는지, 일부를 출력해보자. 아래에서 보듯이, 아르헨티나 문자가 유니코드로 잘 출력이 되고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Competition='World Cup', Year=1930, Team='Argentina', Number='', Position='GK', FullName='Ãngel Bossio', Club='Club AtlÃ©tico Talleres de Remedios de Escalada', ClubCountry='Argentina', DateOfBirth='1905-5-5', IsCaptain=False)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcDf.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  DataFrame의 shema 설정\n",
    "\n",
    "wcRdd에서 DataFrame을 생성하려고 하면 아래와 같이 schema를 설정할 수 있다.\n",
    "그러나 영어가 아닌 다른 나라의 유니코드 문자 또는 생년월일의 결측값 등으로 오류가 발생한다.\n",
    "자동으로 인식한 Schema가 더 낫게 인식하고 있다.\n",
    "\n",
    "```python\n",
    "from pyspark.sql.types import *\n",
    "wcSchema=StructType([\n",
    "    StructField(\"Club\", StringType(), True),\n",
    "    StructField(\"ClubCountry\", StringType(), True),\n",
    "    StructField(\"Competition\", StringType(), True),\n",
    "    StructField(\"DateOfBirth\", DateType(), True),\n",
    "    StructField(\"FullName\", StringType(), True),\n",
    "    StructField(\"IsCaptain\", BooleanType(), True),\n",
    "    StructField(\"Number\", IntegerType(), True),\n",
    "    StructField(\"Position\", StringType(), True),\n",
    "    StructField(\"Team\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### RDD 생성\n",
    "\n",
    "RDD를 통해서 DataFrame 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wcRdd=spark.sparkContext.parallelize(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Competition': 'World Cup',\n",
       "  'Year': 1930,\n",
       "  'Team': 'Argentina',\n",
       "  'Number': '',\n",
       "  'Position': 'GK',\n",
       "  'FullName': 'Ãngel Bossio',\n",
       "  'Club': 'Club AtlÃ©tico Talleres de Remedios de Escalada',\n",
       "  'ClubCountry': 'Argentina',\n",
       "  'DateOfBirth': '1905-5-5',\n",
       "  'IsCaptain': False}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcRdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Club: string (nullable = true)\n",
      " |-- ClubCountry: string (nullable = true)\n",
      " |-- Competition: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- FullName: string (nullable = true)\n",
      " |-- IsCaptain: boolean (nullable = true)\n",
      " |-- Number: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcDfFromRdd = spark.createDataFrame(wcRdd)\n",
    "wcDfFromRdd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Club='Club AtlÃ©tico Talleres de Remedios de Escalada', ClubCountry='Argentina', Competition='World Cup', DateOfBirth='1905-5-5', FullName='Ãngel Bossio', IsCaptain=False, Number='', Position='GK', Team='Argentina', Year=1930)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcDfFromRdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측 값\n",
    "\n",
    "\n",
    "* ```null```은 결측, 즉 \"no value\" 또는 \"nothing\"을 말한다.\n",
    "* ```NaN```은 \"Not a Number\", 즉 수학에서 0.0/0.0과 같이 의미가 없는 연산의 결과를 말한다.\n",
    "\n",
    "```IsCaptain``` 항목은 boolean 타입이라 isnan() 함수가 오류를 발생한다. ```'isnan(`IsCaptain`)' due to data type mismatch: argument 1 requires (double or float) type, however, '`IsCaptain`' is of boolean type.```\n",
    "그래서 항목에서 제거하고 확인하기로 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = wcDf.columns\n",
    "cols.remove('IsCaptain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----+------+--------+--------+----+-----------+-----------+\n",
      "|Competition|Year|Team|Number|Position|FullName|Club|ClubCountry|DateOfBirth|\n",
      "+-----------+----+----+------+--------+--------+----+-----------+-----------+\n",
      "|          0|   0|   0|     0|       0|       0|   0|          0|          0|\n",
      "+-----------+----+----+------+--------+--------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "wcDf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in cols]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 형변환\n",
    "\n",
    "컬럼명 'DateOfBirth'는 'DoB'로 ```DateType()```, 컬럼명 'Number'는 'NumberInt'로 \"integer\" 형으로 설정하였다.\n",
    "schema를 출력하면 이를 확인할 수 있다.\n",
    "\n",
    "구분 | 의미\n",
    "-----|-----\n",
    "%d | 일자 1 ~ 31\n",
    "%m | 월 1 ~ 12\n",
    "%y | 세기 불포함 2자리 년수 00 ~ 99\n",
    "%Y | 세기 포함한 4자리 년수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### ```DateType``` 형변환\n",
    "\n",
    "* ```datetime``` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991-11-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print (datetime.strptime(\"11/25/1991\", '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "toDate = udf(lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wcDf = wcDf.withColumn('date1', toDate(wcDF['DateOfBirth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* ```to_date()``` 함수\n",
    "\n",
    "to_date() 함수는 string (StringType)을 date (DateType) 으로 형변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "_wcDfCasted=wcDf.withColumn('date2', to_date(wcDf['DateOfBirth'], 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* ```cast()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "\n",
    "wcDfCasted = _wcDfCasted.withColumn('date3', _wcDfCasted['DateOfBirth'].cast(DateType()))\n",
    "wcDfCasted = _wcDfCasted.withColumn('NumberInt', _wcDfCasted['Number'].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Competition: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Number: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- FullName: string (nullable = true)\n",
      " |-- Club: string (nullable = true)\n",
      " |-- ClubCountry: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- IsCaptain: boolean (nullable = true)\n",
      " |-- date2: date (nullable = true)\n",
      " |-- NumberInt: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcDfCasted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcDf=wcDf.drop('date1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그대로 출력하면 오류가 발생한다.\n",
    "```SparkUpgradeException: You may get a different result due to the upgrading of Spark 3.0```\n",
    "```spark.sql.legacy.timeParserPolicy=LEGACY```라고 설정을 변경해주어야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Competition='World Cup', Year=1930, Team='Argentina', Number='', Position='GK', FullName='Ãngel Bossio', Club='Club AtlÃ©tico Talleres de Remedios de Escalada', ClubCountry='Argentina', DateOfBirth='1905-5-5', IsCaptain=False, date2=datetime.date(1905, 5, 5), NumberInt=None)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "wcDfCasted.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.4.7 Parquet 파일 읽기, 쓰기\n",
    "\n",
    "Parquet는 Apache Hadoop에서 사용하는 데이터 압축형식으로, JSON에서 읽어서 생성할 수 있다.\n",
    "\n",
    "```python\n",
    "-rw-r--r-- 1 jsl jsl 522 10월  7 15:27 part-r-00000-0318688b-018f-4e55-858b-b4b78ac56532.snappy.parquet\n",
    "-rw-r--r-- 1 jsl jsl   0 10월  7 15:27 _SUCCESS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_myDf.write.parquet(os.path.join(\"data\",\"people.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "앞서 쓰여진 parquet으로부터 읽어서 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_pDf=spark.read.parquet(os.path.join(\"data\",\"people.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_pDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.5 DataFrame API 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼 추가 withColumn, 컬럼 삭제 Drop\n",
    "\n",
    "```withColumn()```은 열을 추가한다.\n",
    "앞서 사용하였던 키, 몸무게 파일에서 DataFrame을 생성하고 컬럼을 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tDf = spark\\\n",
    "    .read\\\n",
    "    .options(header='false', inferschema='true', delimiter='\\t')\\\n",
    "    .csv(os.path.join('data', 'ds_spark_heightweight.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컬럼은 자동 생성이 되었으므로, ```'_c0', '_c1', '_c2'```이고 사용하기 불편하므로 의미있는 컬럼으로 변경하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존에 있는 ```_1```행을 ```integer```로 형변환해서 ```id```행을 만들고, 기존의 ```_1```행을 삭제해보자.\n",
    "```drop()```은 열을 삭제할 때 사용한다. 같은 방식으로 나머지도 변경해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tDf=tDf.withColumn(\"id\", tDf['_c0'].cast(\"integer\")).drop('_c0')\n",
    "tDf=tDf.withColumn(\"height\", tDf['_c1'].cast(\"double\")).drop('_c1')\n",
    "tDf=tDf.withColumn(\"weight\", tDf['_c2'].cast(\"double\")).drop('_c2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형변환이 잘 되었고 컬럼명이 변경된 결과를 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, height=65.78, weight=112.99)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tDf.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자정의 함수 udf\n",
    "\n",
    "UDF User Defined Functions는 사용자 정의함수로서 DataFrame의 행을 처리할 경우 유용하다.\n",
    "보통 함수와 같이 함수명과 반환 값을 미리 정의해서 lambda 함수 또는 만든 함수를 사용할 수 있다.\n",
    "\n",
    "앞서 배운 ```withColumn()```에서 udf를 호출해서 ```height``` 컬럼을 ```long```에서 ```DoubleType()```으로 만들어 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 Pandas로 저장한 csv파일을 읽어서 DataFrame을 만들어 보자.\n",
    "header를 있는 그대로 가져오고,\n",
    "schema도 현재 데이터에서 추정하도록 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myDf = spark\\\n",
    "        .read.format('com.databricks.spark.csv')\\\n",
    "        .options(header='true', inferschema='true')\\\n",
    "        .load(os.path.join('data','myDf.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```header='true'```라고 설정을 해서, 컬럼명은 있는 그대로 year, name, height로 읽는다.\n",
    "printSchema()를 출력해보면, year는 정수, name은 문자열, height는 정수로 정의되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+\n",
      "|_c0|year|   name|height|\n",
      "+---+----+-------+------+\n",
      "|  0|   1|kim, js|   170|\n",
      "|  1|   1|lee, sm|   175|\n",
      "|  2|   2|lim, yg|   180|\n",
      "|  3|   2|    lee|   170|\n",
      "+---+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "myList=[('1','kim, js',170),\n",
    "        ('1','lee, sm', 175),\n",
    "        ('2','lim, yg',180),\n",
    "        ('2','lee',170)]\n",
    "\n",
    "myDf=spark.createDataFrame(myList)\n",
    "\n",
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### udf함수로 Double변환 withColumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "toDoublefunc = udf(lambda x: float(x),DoubleType())\n",
    "myDf = myDf.withColumn(\"heightD\",toDoublefunc(myDf.height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dtypes```로 컬럼명과 데이터타입을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('year', 'int'),\n",
       " ('name', 'string'),\n",
       " ('height', 'int'),\n",
       " ('heightD', 'double')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### udf함수로 정수변환 withColumn\n",
    "\n",
    "year의 문자열을 정수로 형변환 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import udf, struct\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "toint=udf(lambda x:int(x),IntegerType())\n",
    "myDf=myDf.withColumn(\"yearI\",toint(myDf['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      " |-- heightD: double (nullable = true)\n",
      " |-- yearI: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+-------+-----+\n",
      "|_c0|year|   name|height|heightD|yearI|\n",
      "+---+----+-------+------+-------+-----+\n",
      "|  0|   1|kim, js|   170|  170.0|    1|\n",
      "|  1|   1|lee, sm|   175|  175.0|    1|\n",
      "|  2|   2|lim, yg|   180|  180.0|    2|\n",
      "|  3|   2|    lee|   170|  170.0|    2|\n",
      "+---+----+-------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yearI 컬럼명만 선택하여 조회해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|yearI|\n",
      "+-----+\n",
      "|    1|\n",
      "|    1|\n",
      "|    2|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.select('yearI').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### udf함수로 대문자 변환 withColumn\n",
    "\n",
    "대문자로 만들고 문자열로 만들어 보자.\n",
    "반환값의 타잎을 ```StringType()```으로 정의하고 있다는 점에 유의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    " \n",
    "def uppercase(s):\n",
    "    return s.upper()\n",
    "\n",
    "upperUdf = udf(uppercase, StringType())\n",
    "myDf = myDf.withColumn(\"nameUpper\", upperUdf(myDf['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+-------+-----+---------+\n",
      "|_c0|year|   name|height|heightD|yearI|nameUpper|\n",
      "+---+----+-------+------+-------+-----+---------+\n",
      "|  0|   1|kim, js|   170|  170.0|    1|  KIM, JS|\n",
      "|  1|   1|lee, sm|   175|  175.0|    1|  LEE, SM|\n",
      "|  2|   2|lim, yg|   180|  180.0|    2|  LIM, YG|\n",
      "|  3|   2|    lee|   170|  170.0|    2|      LEE|\n",
      "+---+----+-------+------+-------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### udf함수로 조건에 따른 withColumn\n",
    "\n",
    "키를 175를 기준으로 이분화하고 반환값을 ```StringType()```으로 정의해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "height_udf = udf(lambda height: \"taller\" if height >=175 else \"shorter\", StringType())\n",
    "heightDf=myDf.withColumn(\"height>175\", height_udf(myDf.heightD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+-------+-----+---------+----------+\n",
      "|_c0|year|   name|height|heightD|yearI|nameUpper|height>175|\n",
      "+---+----+-------+------+-------+-----+---------+----------+\n",
      "|  0|   1|kim, js|   170|  170.0|    1|  KIM, JS|   shorter|\n",
      "|  1|   1|lee, sm|   175|  175.0|    1|  LEE, SM|    taller|\n",
      "|  2|   2|lim, yg|   180|  180.0|    2|  LIM, YG|    taller|\n",
      "|  3|   2|    lee|   170|  170.0|    2|      LEE|   shorter|\n",
      "+---+----+-------+------+-------+-----+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heightDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼명 변경 withColumnRenamed\n",
    "\n",
    "앞서 ```withCoumun()``` 명령어로 열을 추가해 보았다. ```withColumnRenamed()``` 함수는 컬럼명을 변경한다. 컬럼명을 ```name```에서 ```full name```으로 변경해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tDf=tDf.withColumnRenamed('id','ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| ID|height|weight|\n",
      "+---+------+------+\n",
      "|  1| 65.78|112.99|\n",
      "|  2| 71.52|136.49|\n",
      "|  3|  69.4|153.03|\n",
      "+---+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tDf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 그래프\n",
    "\n",
    "Spark에는 그래프를 그리는 기능이 없다.\n",
    "Python matplotlib을 이용해서 그래프를 표현한다.\n",
    "2차원 ```plot()```을 하기 위해서는, x와 y축 값이 필요하다.\n",
    "DataFrame -> RDD로 변환하고, map() 함수를 사용하여 배열로부터 weight, height를 분리해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_weightRdd=tDf.rdd.map(lambda fields:fields[1]).collect()\n",
    "_heightRdd=tDf.rdd.map(lambda fields:fields[2]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x, y 값이 잘 추출되었는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65.78 71.52 69.4  68.22 67.79]\n",
      "[112.99 136.49 153.03 142.34 144.3 ]\n"
     ]
    }
   ],
   "source": [
    "print (np.array(_weightRdd)[:5])\n",
    "print (np.array(_heightRdd)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 추출한 height, weight RDD를 numpy array를 사용해서 2차원 x, y로 변환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.array(_weightRdd), np.array(_heightRdd),'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 컬럼 조회 select\n",
    "\n",
    "컬럼은 아래와 같이 ```select()```로 선택할 수 있다.\n",
    "컬럼은 그 명칭을 사용하거나 ```myDf.name```, 인덱스 ```myDf['name']```로 선택할 수 있다.\n",
    "\n",
    "컬럼 선택 | 예제 | 권고\n",
    "-----|-----|-----\n",
    "점 연산자로 컬럼을 선택 | myDf.name | N\n",
    "인덱스로 컬럼을 선택 | myDf['name'] | Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 컬럼명으로 직접 조회 못해\n",
    "\n",
    "컬럼명만 아래와 같이 적어주어도 조회할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'name'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 컬럼 데이터를 조회하기 위해 컬럼에 show(), collect() 함수를 사용해서는 안된다. ```select()```를 사용해서 컬럼을 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-2fdc8d3e858e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyDf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "myDf['name'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select후 collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|kim, js|\n",
      "|lee, sm|\n",
      "|lim, yg|\n",
      "|    lee|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_name=myDf.select('name')\n",
    "_name.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 컬럼을 조회하기 위해서는 해당 컬럼을 넣어주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|height|\n",
      "+-------+------+\n",
      "|kim, js|   170|\n",
      "|lee, sm|   175|\n",
      "|lim, yg|   180|\n",
      "|    lee|   170|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_name=myDf.select('name', 'height').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+\n",
      "|   name|height|name LIKE % lee %|\n",
      "+-------+------+-----------------+\n",
      "|kim, js|   170|            false|\n",
      "|lee, sm|   175|            false|\n",
      "|lim, yg|   180|            false|\n",
      "|    lee|   170|            false|\n",
      "+-------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.select(\"name\", \"height\", myDf.name.like(\"% lee %\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select startswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------------------+\n",
      "|   name|height|startswith(name, kim)|\n",
      "+-------+------+---------------------+\n",
      "|kim, js|   170|                 true|\n",
      "|lee, sm|   175|                false|\n",
      "|lim, yg|   180|                false|\n",
      "|    lee|   170|                false|\n",
      "+-------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.select(\"name\", \"height\", myDf.name.startswith(\"kim\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select endswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------------------+\n",
      "|   name|height|endswith(name, lee)|\n",
      "+-------+------+-------------------+\n",
      "|kim, js|   170|              false|\n",
      "|lee, sm|   175|              false|\n",
      "|lim, yg|   180|              false|\n",
      "|    lee|   170|               true|\n",
      "+-------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.select(\"name\", \"height\", myDf.name.endswith(\"lee\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### alias\n",
    "\n",
    "이름을 변경할 경우 alias() 함수를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame의 명칭을 변경해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myDf1 = myDf.alias(\"myDf1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컬럼의 명칭을 변경해보자.\n",
    "그러기 위해서는 우선 컬럼을 **```select()```** 함수로 골라낸 후, **```alias```**로 **컬럼명**을 정할 수 있다.\n",
    "name 컬럼을 **```substr```**으로 1,3문자를 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|short name|\n",
      "+----------+\n",
      "|       kim|\n",
      "|       lee|\n",
      "|       lim|\n",
      "+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf1.select(myDf1.name.substr(1,3).alias(\"short name\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행과 열을 선택 select, when, otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------------+\n",
      "|height|CASE WHEN (height < 175) THEN 1 ELSE 0 END|\n",
      "+------+------------------------------------------+\n",
      "|   170|                                         1|\n",
      "|   175|                                         0|\n",
      "|   180|                                         0|\n",
      "|   170|                                         1|\n",
      "+------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "myDf.select(\"height\", when(myDf.height < 175, 1).otherwise(0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alias 명령어로 컬럼을 변경해 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|height|<175|\n",
      "+------+----+\n",
      "|   170|   1|\n",
      "|   175|   0|\n",
      "|   180|   0|\n",
      "|   170|   1|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "myDf.select(\"height\", (when(myDf.height < 175, 1).otherwise(0)).alias('<175')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 0, 1이 아닌 문자열로 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "_myDf=myDf.select(when(myDf['heightD'] >175.0, \">175\").otherwise(\"<175\").alias(\"how tall\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|how tall|\n",
      "+--------+\n",
      "|    <175|\n",
      "|    <175|\n",
      "|    >175|\n",
      "|    <175|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "withColumn() 함수를 사용하면, DataFrame에 컬럼을 추가하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+-------+-----+---------+--------+\n",
      "|_c0|year|   name|height|heightD|yearI|nameUpper|how tall|\n",
      "+---+----+-------+------+-------+-----+---------+--------+\n",
      "|  0|   1|kim, js|   170|  170.0|    1|  KIM, JS|    <175|\n",
      "|  1|   1|lee, sm|   175|  175.0|    1|  LEE, SM|    <175|\n",
      "|  2|   2|lim, yg|   180|  180.0|    2|  LIM, YG|    >175|\n",
      "|  3|   2|    lee|   170|  170.0|    2|      LEE|    <175|\n",
      "+---+----+-------+------+-------+-----+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_myDf = myDf.withColumn('how tall', when(myDf['heightD'] >175.0, \">175\").otherwise(\"<175\"))\n",
    "_myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행과 열을 선택  where, select\n",
    "\n",
    "\n",
    "DataFrame은 관계형데이터베이스의 테이블과 매우 유사하다. **SQL 명령**을 사용하듯이 ```where()```, ```select()```, ```groupby()``` 함수를 사용할 수 있다.\n",
    "\n",
    "* 행: ```where()```에 따라 컬럼의 조건에 맞는 행을 선택하고,\n",
    "* 열: 앞서 배운 ```select()```로 열을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|height|\n",
      "+-------+------+\n",
      "|kim, js|   170|\n",
      "|    lee|   170|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.where(myDf['height'] < 175)\\\n",
    "    .select(myDf['name'], myDf['height']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter\n",
    "\n",
    "```filter()```는 조건에 따라 데이터를 걸러낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+-------+-----+---------+\n",
      "|_c0|year|   name|height|heightD|yearI|nameUpper|\n",
      "+---+----+-------+------+-------+-----+---------+\n",
      "|  2|   2|lim, yg|   180|  180.0|    2|  LIM, YG|\n",
      "+---+----+-------+------+-------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.filter(myDf['height'] > 175).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Row의 split (앞 tDf에서 split??)\n",
    "\n",
    "Row 객체의 값은 아래와 같이 단순하게 split 할 수 없으며, 오류가 발생한다. ```dict```로 변환한 후 그 값을 split해야 한다.\n",
    "\n",
    "```python\n",
    "_name.rdd.map(lambda line:[line.split(',')])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict_values' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-bae4ff6e3a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'kim, js'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict_values' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "r=Row(name=u'kim, js')\n",
    "rd=r.asDict()\n",
    "print (rd.values().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regexp_replace 컬럼의 내용 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+-------+-----+---------+----------+-------+\n",
      "|_c0|year|   name|height|heightD|yearI|nameUpper|height>175|nameNew|\n",
      "+---+----+-------+------+-------+-----+---------+----------+-------+\n",
      "|  0|   1|kim, js|   170|  170.0|    1|  KIM, JS|   shorter|kim, js|\n",
      "|  1|   1|lee, sm|   175|  175.0|    1|  LEE, SM|    taller|lim, sm|\n",
      "|  2|   2|lim, yg|   180|  180.0|    2|  LIM, YG|    taller|lim, yg|\n",
      "|  3|   2|    lee|   170|  170.0|    2|      LEE|   shorter|    lim|\n",
      "+---+----+-------+------+-------+-----+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "_heightDf = heightDf.withColumn('nameNew', regexp_replace('name', 'lee', 'lim'))\n",
    "_heightDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupBy\n",
    "\n",
    "컬럼을 학년에 따라,\n",
    "```groupBy()```하면 아래와 같이 데이터만 집단화하게 된다.\n",
    "집단화하면 개수를 세거나, 합계를 내거나 어떤 통계량을 계산이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7f794caf5b38>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.groupby(myDf['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupBy하고 max\n",
    "\n",
    "컬럼을 기준으로 구분지어서 평균, 합계, 갯수, 최대, 최소 등을 구할 수 있다.\n",
    "첫 컬럼 학년을 ```groupby()```해서 최대값 ```max()```를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+-----------+------------+----------+\n",
      "|year|max(_c0)|max(year)|max(height)|max(heightD)|max(yearI)|\n",
      "+----+--------+---------+-----------+------------+----------+\n",
      "|   1|       1|        1|        175|       175.0|         1|\n",
      "|   2|       3|        2|        180|       180.0|         2|\n",
      "+----+--------+---------+-----------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.groupby(myDf['year']).max().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupBy, agg\n",
    "\n",
    "```agg()```는 합계 함수를 계산할 수 있으며, 지원하는 함수는 ```avg, max, min, sum, count```이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```year``` 컬럼에 대해 ```agg()``` 함수로 계산할 수 있다.\n",
    "\n",
    "dictionary 형식으로 key는 컬럼명, value는 합계 함수를 적어준다.\n",
    "예를 들어 {\"heightD\":\"avg\"}에서 \"heightD\"는 컬럼명, \"avg\"는 합계함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|avg(heightD)|\n",
      "+----+------------+\n",
      "|   1|       172.5|\n",
      "|   2|       175.0|\n",
      "+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.groupBy('year').agg({\"heightD\":\"avg\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupBy 국가별 인원수\n",
    "\n",
    "월드컵 데이터를 groupBy 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wcDf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-bd2eaec1ce74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwcDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwcDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClubCountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wcDf' is not defined"
     ]
    }
   ],
   "source": [
    "wcDf.groupBy(wcDf.ClubCountry).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupBy 국가별 포지션별 인원수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "wcDf.groupBy('ClubCountry').pivot('Position').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F 함수\n",
    "\n",
    "또는 아래와 같이 별도 ```pyspark.sql.functions```을 사용할 수 있다.\n",
    "앞서 pyspark.sql.functions은 함수이므로, ```from pyspark.sql.functions import split``` 이렇게 한다.\n",
    "또는 ```from pyspark.sql import functions as F```라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+\n",
      "|min(heightD)|max(heightD)|avg(heightD)|sum(heightD)|\n",
      "+------------+------------+------------+------------+\n",
      "|       170.0|       180.0|      173.75|       695.0|\n",
      "+------------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "myDf.agg(F.min(myDf.heightD),F.max(myDf.heightD),F.avg(myDf.heightD),F.sum(myDf.heightD)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### partition 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repartition\n",
    "\n",
    "repartition()은 partition의 개수를 늘리거나 줄이거나 재설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "_myDf = myDf.repartition(4)\n",
    "print(_myDf.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coalesce\n",
    "\n",
    "coalesce()는 partition을 줄일 때 사용한다.\n",
    "앞서 4개의 partition을 가진 ```_myDf```를 2로 줄여보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "_myDf2 = _myDf.coalesce(2)\n",
    "print(_myDf2.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 통계 요약 describe\n",
    "\n",
    "column이 연산가능한 데이터타잎인 경우, 요약 값을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            height|           heightD|             yearI|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|                 4|                 4|                 4|\n",
      "|   mean|            173.75|            173.75|               1.5|\n",
      "| stddev|4.7871355387816905|4.7871355387816905|0.5773502691896257|\n",
      "|    min|               170|             170.0|                 1|\n",
      "|    max|               180|             180.0|                 2|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측값\n",
    "\n",
    "* Replacing null values\n",
    "dataframe.na.fill()\n",
    "dataFrame.fillna()\n",
    "dataFrameNaFunctions.fill()\n",
    "* Returning new dataframe restricting rows with null valuesdataframe.na.drop()\n",
    "dataFrame.dropna()\n",
    "dataFrameNaFunctions.drop()\n",
    "* Return new dataframe replacing one value with another\n",
    "dataframe.na.replace(5, 15)\n",
    "dataFrame.replace()\n",
    "dataFrameNaFunctions.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, year: int, name: string, height: int, heightD: double, yearI: int, nameUpper: string]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "myDf.where(F.col(\"height\").isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+------+-------+-----+---------+\n",
      "|_c0|year|name|height|heightD|yearI|nameUpper|\n",
      "+---+----+----+------+-------+-----+---------+\n",
      "|  0|   0|   0|     0|      0|    0|        0|\n",
      "+---+----+----+------+-------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "myDf.select([count(when(isnan(c), c)).alias(c) for c in myDf.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+------+-------+-----+---------+\n",
      "|_c0|year|name|height|heightD|yearI|nameUpper|\n",
      "+---+----+----+------+-------+-----+---------+\n",
      "|  0|   0|   0|     0|      0|    0|        0|\n",
      "+---+----+----+------+-------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "myDf.select([count(when(col(c).isNull(), c)).alias(c) for c in myDf.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제: 년별 분기별 대여건수\n",
    "\n",
    "서울시 열린데이터 https://data.seoul.go.kr/ 서울시 공공자전거 이용현황 데이터를 분석해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.6 Spark SQL\n",
    "\n",
    "DataFrame을 관계형 데이터베이스에서 우리가 사용하는 Sql을 사용할 수 있다. RDD는 비구조적인 경우에 사용하므로 테이블로 변환한 후 Sql을 사용하게 된다.\n",
    "\n",
    "* Spark SQL 구성\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "Language API | Python, Java, Scala, Hive QL API를 제공\n",
    "Schema RDD | RDD에 Schema를 적용해 임시 테이블로 변환한다.<br>createOrReplaceTempView<br>createGlobalTempView\n",
    "Data Sources | 다양한 형식 지원 - HDFS, Cassandra, HBase, RDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "앞서 만들어 놓은 World Cup 데이터를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Competition: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Number: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- FullName: string (nullable = true)\n",
      " |-- Club: string (nullable = true)\n",
      " |-- ClubCountry: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- IsCaptain: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이제 임시 테이블 ```wc```를 만들고, Sql문으로 데이터를 조회해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----+\n",
      "|                Club|     Team|Year|\n",
      "+--------------------+---------+----+\n",
      "|Club AtlÃ©tico Ta...|Argentina|1930|\n",
      "+--------------------+---------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcDf.createOrReplaceTempView(\"wc\")\n",
    "spark.sql(\"select Club,Team,Year from wc\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+----+\n",
      "|    FullName|                Club|     Team|Year|\n",
      "+------------+--------------------+---------+----+\n",
      "|Ãngel Bossio|Club AtlÃ©tico Ta...|Argentina|1930|\n",
      "+------------+--------------------+---------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcPlayers=spark.sql(\"select FullName,Club,Team,Year from wc\")\n",
    "wcPlayers.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='wc', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```wcPlayers```를 RDD로 변환해서 이름만 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full name: Ãngel Bossio\n",
      "Full name: Juan Botasso\n",
      "Full name: Roberto Cherro\n",
      "Full name: Alberto Chividini\n",
      "Full name: \n"
     ]
    }
   ],
   "source": [
    "namesRdd=wcPlayers.rdd.map(lambda x: \"Full name: \"+x[0])\n",
    "for e in namesRdd.take(5):\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### sql.functions and join\n",
    "\n",
    "리스트에 포함되어 있는 과일에 고유번호를 할당해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucketDf=spark.createDataFrame([[1,[\"orange\", \"apple\", \"pineapple\"]],\n",
    "                                [2,[\"watermelon\",\"apple\",\"bananas\"]]],\n",
    "                               [\"bucketId\",\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------+\n",
      "|bucketId|items                       |\n",
      "+--------+----------------------------+\n",
      "|1       |[orange, apple, pineapple]  |\n",
      "|2       |[watermelon, apple, bananas]|\n",
      "+--------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucketDf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* explode\n",
    "\n",
    "컬럼에 List 또는 배열이 포함된 경우 ```explode()``` 함수는 이를 flat해서 새로운 컬럼을 생성하게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "bDf=bucketDf.select(bucketDf.bucketId, explode(bucketDf.items).alias('item'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|bucketId|      item|\n",
      "+--------+----------+\n",
      "|       1|    orange|\n",
      "|       1|     apple|\n",
      "|       1| pineapple|\n",
      "|       2|watermelon|\n",
      "|       2|     apple|\n",
      "|       2|   bananas|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "또 다른 DataFrame을 생성해보자. 나중에 앞의 DataFrame과 join하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fDf=spark.createDataFrame([[\"orange\", \"F1\"],\n",
    "                            [\"\", \"F2\"],\n",
    "                            [\"pineapple\",\"F3\"],\n",
    "                            [\"watermelon\",\"F4\"],\n",
    "                            [\"bananas\",\"F5\"]],\n",
    "                            [\"item\",\"itemId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      item|itemId|\n",
      "+----------+------+\n",
      "|    orange|    F1|\n",
      "|          |    F2|\n",
      "| pineapple|    F3|\n",
      "|watermelon|    F4|\n",
      "|   bananas|    F5|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* join\n",
    "\n",
    "join은 ```inner, cross, outer, full, full_outer, left, left_outer, right, right_outer, left_semi, left_anti``` 여러 종류가 있다. ```inner```기준으로 item이 일치하지 않는 것은 제외하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "joinDf=fDf.join(bDf, fDf.item==bDf.item, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+\n",
      "|itemId|      item|bucketId|\n",
      "+------+----------+--------+\n",
      "|    F5|   bananas|       2|\n",
      "|    F1|    orange|       1|\n",
      "|    F3| pineapple|       1|\n",
      "|    F4|watermelon|       2|\n",
      "+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinDf.select(fDf.itemId,fDf.item,bDf.bucketId).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 S-1: 네트워크에 불법적으로 침입하는 사용자의 분석\n",
    "\n",
    "### 문제\n",
    "\n",
    "네트워크에 불법적으로 침입하는 시도는 허용되어서는 안된다.\n",
    "1998년 MIT Lincoln Labs에서 DARPA Intrusion Detection Evaluation Program을 연구하였다.\n",
    "이 데이터의 일부가 1999년 KDD로 만들어져 배포되고 있다.\n",
    "https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "\n",
    "### 해결\n",
    "\n",
    "마지막 행에 attack의 유형이 구분되어 있다. 네트워크 침입 유형의 특징을 분석해 보자.\n",
    "탐지예방 모델을 구축할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 S-2: Twitter JSON 데이터 읽기\n",
    "\n",
    "* [nok] 현재 디렉토리 _tweet.json\n",
    "    * src/ds_twitter_3.py로 변경 (ds_twitter_3.json으로 저장)\n",
    "\n",
    "\n",
    "\n",
    "* Twitter JSON을 읽을 경우\n",
    "\n",
    "구분 | 예\n",
    "-------|-------\n",
    "unicode를 사용하면 backslash | \"{\\\"created_at\\\":\\\"Sun Nov 13 00:05:19 +0000 2016\\\"\n",
    "보통 | {\"created_at\":\"Sun Nov 13 00:05:19 +0000 2016\"\n",
    "\n",
    "* allowBackslashEscapingAnyCharacter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 S-3: 뉴욕에서 출생한 신생아 분석\n",
    "\n",
    "### 뉴욕에서 출생한 신생아가 년도별 성별에 차이가 있을까?\n",
    "\n",
    "뉴욕에서 2007년 출생한 유아의 기록이다.\n",
    "https://health.data.ny.gov/Health/Baby-Names-Beginning-2007/jxy9-yhdk\n",
    "\n",
    "Column Name | 설명\n",
    "-----|-----\n",
    "Year | Year data was collected.\n",
    "First Name | 이름\n",
    "County | Location where the baby’s mother resided as stated on their birth certificate.\n",
    "Sex | F= Female M= Male\n",
    "Count | Five (5) or more of the same baby name in a county outside of NYC; Ten (10) or more of the same baby name in a NYC borough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 S-4: 우버 택시의 운행기록 분석\n",
    "\n",
    "* 질문: 2015년 가장 많은 운행을 한 base는?\n",
    "https://github.com/tmcgrath/spark-with-python-course/blob/master/Spark-SQL-CSV-with-Python.ipynb\n",
    "\n",
    "* fivethirtyeight\n",
    "    * git clone https://github.com/fivethirtyeight/uber-tlc-foil-response.git\n",
    "        daily Uber trip statistics in January and February 2015\n",
    "\n",
    "dispatching_base_number | date | active_vehicles | trips\n",
    "----------|----------|----------|----------\n",
    "B02512 | 1/1/2015 | 190 | 1132\n",
    "B02765 | 1/1/2015 | 225 | 1765\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 S-5: JDBC를 사용해서 데이터 읽기\n",
    "\n",
    "* jdbc를 연결하는 방식은 Java와 같이 'driver', 'url'을 설정하면 된다.\n",
    "* 여기서는 sqlite를 실습한다.\n",
    "\n",
    "* sqlite와 같이 Spark 패키지가 없는 경우, jar를 다운로드하고\n",
    "설정파일 conf/spark-defaults.conf에 'spark.driver.extraClassPath'를 추가한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.7 MongoDB Spark connector\n",
    "\n",
    "* Spark에서 MongoDB에 저장된 데이터를 읽어 온다.\n",
    "* 참조: pymongo-spark (Spark와 PyMongo를 사용하는 Python 라이브러리, 설치하려면 pip install pymongo-spark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### S.7.1 설정\n",
    "\n",
    "* 참조 https://docs.mongodb.com/spark-connector/\n",
    "* 설정파일 conf/spark-defaults.conf 수정\n",
    "    * Spark 버전에 맞는 jar를 선택한다.\n",
    "    * MongoDB<3.2인 경우, spark.mongodb.input.partitioner가 필요하다.\n",
    "    * packages 여러 개를 넣을 경우에는 컴마로 분리한다.\n",
    "\n",
    "```python\n",
    "$vim conf/spark-defaults.conf \n",
    "spark.jars.packages=org.mongodb.spark:mongo-spark-connector_2.10:1.1.0\n",
    "spark.mongodb.input.partitioner=MongoPaginateBySizePartitioner\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphframes:graphframes:0.4.0-spark2.0-s_2.11,org.mongodb.spark:mongo-spark-connector_2.10:2.0.0,com.databricks:spark-csv_2.11:1.5.0\n"
     ]
    }
   ],
   "source": [
    "print spark.conf.get('spark.jars.packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.8 spark-submit\n",
    "\n",
    "* spark-submit는 일괄실행 (self-contained app in quick-start 참조)\n",
    "\n",
    "* MongoDB를 사용하려면, spark-defaults.conf에 jar를 추가한다 (앞서 미리 설정하였다.)\n",
    "\n",
    "* spark-submit을 실행하기 전, 'conf/log4j.properties'를 수정 log level을 ERROR로 설정하였다.\n",
    "```python\n",
    "log4j.rootCategory=ERROR, console\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.8.1 간단한 작업\n",
    "\n",
    "* DataFrame 만들고, 출력하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ds_spark_sql.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds_spark_sql.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "import pyspark\n",
    "\n",
    "def doIt():\n",
    "    d = [{'name': 'Alice', 'age': 1}]\n",
    "    print spark.createDataFrame(d).collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    myConf=pyspark.SparkConf()\n",
    "    spark = pyspark.sql.SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"myApp\")\\\n",
    "        .config(conf=myConf)\\\n",
    "        .getOrCreate()\n",
    "    doIt()\n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jsl/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jsl/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/home/jsl/Downloads/spark-2.0.0-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "graphframes#graphframes added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.10 added as a dependency\n",
      "com.databricks#spark-csv_2.11 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.4.0-spark2.0-s_2.11 in spark-packages\n",
      "\tfound com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central\n",
      "\tfound com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.11.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.7 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.10;2.0.0 in central\n",
      "\tfound org.mongodb#mongo-java-driver;3.2.2 in central\n",
      "\tfound com.databricks#spark-csv_2.11;1.5.0 in central\n",
      "\tfound org.apache.commons#commons-csv;1.1 in central\n",
      "\tfound com.univocity#univocity-parsers;1.5.1 in central\n",
      ":: resolution report :: resolve 245ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.databricks#spark-csv_2.11;1.5.0 from central in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]\n",
      "\tcom.univocity#univocity-parsers;1.5.1 from central in [default]\n",
      "\tgraphframes#graphframes;0.4.0-spark2.0-s_2.11 from spark-packages in [default]\n",
      "\torg.apache.commons#commons-csv;1.1 from central in [default]\n",
      "\torg.mongodb#mongo-java-driver;3.2.2 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.10;2.0.0 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.7 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   10  |   0   |   0   |   0   ||   10  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 10 already retrieved (0kB/7ms)\n",
      "/home/jsl/Downloads/spark-2.0.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/session.py:316: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n",
      "[Row(age=1, name=u'Alice')]\n"
     ]
    }
   ],
   "source": [
    "!/home/jsl/Downloads/spark-2.0.0-bin-hadoop2.7/bin/spark-submit src/ds_spark_sql.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
