{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 웹 데이터 추출\n",
    "\n",
    "* Last updated: 20181105MON0720 20170917 20170401 20161004\n",
    "\n",
    "## 1.1 학습내용\n",
    "\n",
    "### 1.1.1 목표\n",
    "\n",
    "* 웹페이지를 읽어서 파싱할 수 있다.\n",
    "* 웹페이지에서 xpath, css selector를 사용하여 원하는 데이터를 추출할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.2 목차\n",
    "\n",
    "* 1.2 Parsing\n",
    "* 1.3 Developer tools\n",
    "* 1.3.1 브라우저에서 Javascript concole 창 열기\n",
    "* 1.3.2 Console 창에서 selector 찾기¶ \n",
    "* 1.3.3 Elements 창에서 selector 찾기\n",
    "* 1.4 dom \n",
    "* 1.5 BeautifulSoup\n",
    "* 1.5.1 설치\n",
    "* 1.5.2 BeautifulSoup 객체\n",
    "* 1.5.3 태그 객체\n",
    "* 1.5.4 문자열 객체\n",
    "* 1.5.5 Comment 객체\n",
    "* 1.5.6 찾기\n",
    "* 1.6 regex\n",
    "* 1.6.1 문자, 순자 추출해 보기\n",
    "* 1.6.2 BeautifulSoup과 같이 regex를 사용\n",
    "* --- \n",
    "* 1.7 xpath\n",
    "* 1.7.1 lxml\n",
    "* 1.7.2 파일에서 파싱\n",
    "* 1.7.2 문자열에서 파싱\n",
    "* 1.8 css selectors\n",
    "* 1.8.1 html에서 css \n",
    "* 1.8.2 lxml을 사용해서 하기\n",
    "* 1.8.3 BeautifulSoup을 사용해서 하기\n",
    "* 1.8.4 테이블을 읽기\n",
    "---\n",
    "* 1.9 동적 페이지에서 데이터 수집\n",
    "* 1.9.1 동적 페이지\n",
    "* 1.9.2 Selenium\n",
    "* 1.9.3 간단한 명령어\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.3 문제\n",
    "\n",
    "* 문제 웹데이터-1: python.org 페이지가 가지고 있는 최근 뉴스 출력하기\n",
    "* 문제 웹데이터-2: python.org 페이지를 크롤링해서 http url를 출력하기\n",
    "    * BeautifulSoup, regex, xpath, css selector\n",
    "* 문제 웹데이터-3: 위키페이지에서 'python'을 검색해서 본문내용을 출력하기\n",
    "    * 위키에서 검색하기, 위키에서 css selector\n",
    "* 문제 웹데이터-4: 한국 포털사이트에서 노래 제목을 검색해서 가져오기\n",
    "    * regex, lxml css selector - 노래제목, 아티스트, 앨범 출력\n",
    "* 문제 웹데이터-5: 국제학회 목록을 가져오기\n",
    "    * lxml css.selector, Scrapy에서 연속 추출\n",
    "* 문제 웹데이터-6: 한국 프로야구 팀순위 가져오기\n",
    "    * kbreport.com, regex 단순 문자열 검색, xpath\n",
    "* 문제 웹데이터-7: 로그인이 필요한 사이버강의실에서 강의계획서를 가져오기\n",
    "* 문제 웹데이터-8: 한국 프로야구 선수 기록 크롤링하기 (1)\n",
    "* 문제 웹데이터-9: 한국 프로야구 선수 기록 크롤링하기 (2)\n",
    "* 문제 웹데이터-10: 다음에서 환율 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.4 연습\n",
    "\n",
    "* 연습 웹데이터-1: UC Irvine 기계학습 데이터\n",
    "* 연습 웹데이터-2: 기상청 도별 날씨 가져오기기\n",
    "* 연습 웹데이터-3: 국가통계 가져오기\n",
    "* 연습 웹데이터-4: 신문 크롤링 해보기\n",
    "* 연습 웹데이터-5: 영화 리뷰의 분석\n",
    "* 주식, tripadvisor는 'scrapy'에서 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Parsing\n",
    "\n",
    "웹에서 데이터를 수집하고 나면 그로부터 원하는 정보를 추출하는 과정이 필요하다.\n",
    "웹페이지는 그냥 보통 **텍스트**일 뿐이다. 앞서 설명한 바와 텍스트는 문자로 구성되어서 '숫자'로 연산을 하려해도 문자이기 때문에 변환을 해야만 한다. 이러한 **텍스트를 웹 태그로 구성된 형태로 변환**해야 하는데, 이를 파싱 parsing한다고 말한다.\n",
    "\n",
    "> 파싱 Parsing\n",
    "\n",
    "> 데이터를 분석하기 위해 **의미가 있는 구조로 변환**하는 것을 말한다. 웹데이터를 태그구조인 **DOM, Document Object Model**로 변환해서 원하는 항목을 추출할 수 있다. 또 다른 예는 우리가 말하는 문장은 주어, 목적어, 동사와 같은 문법구조로 변환하는 것도 파싱한다고 한다.\n",
    "\n",
    "파싱을 하지 않으면, 태그를 추출하기 위해서는 문자 하나 하나씩 처리해야 하기 때문에 많은 노력이 필요하다. 예를 들어 ```<h1>...</h1>```은 **부등호문자,h,1과 같은 문자로 구성**된 것으로 간주한다. 따라서 시작태그, 끝태그를 찾으려면 꽤 복잡한 처리과정이 필요하다. 파싱을 하면, 이런 **태그 요소를 분리하고, tree구조로 만들어** 분석을 용이하게 할 수 있다.\n",
    "웹에서 수집하는 데이터는 보통 **HTML DOM**, **XML**, **json**으로 되어 있고, 이들은 파싱하기 전에는 그냥 일반적인 문자로 만들어져 있고 태그구조를 가지고 있지만, 태그를 처리하기 용이한 tree구조를 만들어서 데이터를 추출해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "그럼 단계별로 어떻게 하는지 살펴보자.\n",
    "* 첫째, 파서를 선택하고\n",
    "* 둘째로 html을 읽어서 tree구조로 변환한 후\n",
    "* 세째 필요한 데이터항목을 결정하고\n",
    "* 마지막으로 그 데이터를 추출하는 과정을 실행한다.\n",
    "\n",
    "단계 | 작업절차 | BeautifulSoup 예 | lxml 예\n",
    "-----|-----|-----|-----\n",
    "단계 1 | 사용하려는 파서 선택 | from bs4 import BeautifulSoup | import lxml.etree\n",
    "단계 2 | 페이지를 파싱하고, 트리를 생성한다 | soup=BeautifulSoup('my.html') | tree=lxml.etree.parse('my.html')\n",
    "단계 3 | 트리에서 필요한 요소를 정한다. | 태그, 클래스... | 좌동\n",
    "단계 4 | 필요한 요소를 가져온다. | soup.select() | tree.xpath() 또는 tree.css()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import iplantuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"391px\" style=\"width:292px;height:391px;\" version=\"1.1\" viewBox=\"0 0 292 391\" width=\"292px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><filter height=\"300%\" id=\"f1\" width=\"300%\" x=\"-1\" y=\"-1\"><feGaussianBlur result=\"blurOut\" stdDeviation=\"2.0\"/><feColorMatrix in=\"blurOut\" result=\"blurOut2\" type=\"matrix\" values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0\"/><feOffset dx=\"4.0\" dy=\"4.0\" in=\"blurOut2\" result=\"blurOut3\"/><feBlend in=\"SourceGraphic\" in2=\"blurOut3\" mode=\"normal\"/></filter></defs><g><ellipse cx=\"144.5\" cy=\"18\" fill=\"#000000\" filter=\"url(#f1)\" rx=\"10\" ry=\"10\" style=\"stroke: none; stroke-width: 1.0;\"/><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9629\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"150\" x=\"69.5\" y=\"68\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"130\" x=\"79.5\" y=\"89.4023\">stage 1: import library</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9629\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"277\" x=\"6\" y=\"142\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"257\" x=\"16\" y=\"163.4023\">stage 2: transform web page string to a tree</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9629\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"167\" x=\"61\" y=\"216\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"147\" x=\"71\" y=\"237.4023\">stage 3: define a selector</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9629\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"277\" x=\"6\" y=\"290\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"257\" x=\"16\" y=\"311.4023\">stage 4: get selected elements from the tree</text><ellipse cx=\"144.5\" cy=\"374\" fill=\"none\" filter=\"url(#f1)\" rx=\"10\" ry=\"10\" style=\"stroke: #000000; stroke-width: 1.0;\"/><ellipse cx=\"145\" cy=\"374.5\" fill=\"#000000\" rx=\"6\" ry=\"6\" style=\"stroke: none; stroke-width: 1.0;\"/><path d=\"M144.5,28.038 C144.5,36.932 144.5,50.844 144.5,62.572 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"144.5,67.781,148.5,58.781,144.5,62.781,140.5,58.781,144.5,67.781\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M144.5,102.338 C144.5,112.464 144.5,125.584 144.5,136.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"144.5,141.727,148.5,132.727,144.5,136.727,140.5,132.727,144.5,141.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M144.5,176.338 C144.5,186.464 144.5,199.584 144.5,210.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"144.5,215.727,148.5,206.727,144.5,210.727,140.5,206.727,144.5,215.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M144.5,250.338 C144.5,260.464 144.5,273.584 144.5,284.5432 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"144.5,289.7267,148.5,280.7267,144.5,284.7267,140.5,280.7267,144.5,289.7267\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M144.5,324.0674 C144.5,334.5986 144.5,348.2536 144.5,358.4618 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"144.5,363.7367,148.5,354.7367,144.5,358.7367,140.5,354.7367,144.5,363.7367\" style=\"stroke: #A80036; stroke-width: 1.0;\"/></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%plantuml\n",
    "@startuml\n",
    "(*)--> \"stage 1: import library\"\n",
    "--> \"stage 2: transform web page string to a tree\"\n",
    "--> \"stage 3: define a selector\"\n",
    "--> \"stage 4: get selected elements from the tree\"\n",
    "-->(*)\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* parsing 관련 라이브러리\n",
    "    * HTMLParser - Python에서 **기본**으로 제공\n",
    "    * BeautifulSoup - lxml을 사용해서 구현된 parser (css는 지원하지만 XPath는 지원하지 않는다.)\n",
    "    * lxml - C로 구현되어서 빠르다. 단독 또는 BeautifulSoup에서 사용할 수 있다. xml, html 파싱을 할 수 있다.\n",
    "    * regex - HTML 파서가 아니다. 패턴으로 파싱을 한다. BeautifulSoup과 같은 파서와 결합하여 사용할 수 있다.\n",
    "    * pyquery - jquery와 같은 기능의 라이브러리\n",
    "    * scrapy - 프레임워크로 대규모 프로젝트에 적합하다. 파이프라인pipelines을 사용하므로 빠르다.\n",
    "\n",
    "구분 | 라이브러리 | 설명\n",
    "-----|-----|-----\n",
    "웹데이터 수집 | urllib, requests, curl | 웹페이지 열고, http request(s), http response(s)\n",
    "웹데이터 파싱 | HTMLParser, BeautifulSoup, lxml, regex | 문자열 또는 xml, json을 파싱\n",
    "프레임워크 | scrapy (java nutch, crawler4j) | 큰 프로젝트에 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3 Developer tools\n",
    "\n",
    "파싱을 하기 위해서는 그 대상이 되는 HTML 소스가 어떻게 구성되었는지 알아야 한다.\n",
    "웹브라우저에서 해당 페이지를 열고나서, 기능키 F12를 이용해 **HTML 소스**의 구조를 볼 수 있다.\n",
    "여기서는 크롬을 사용해 보자. 크롬은 구글 사이트에 사용법이 자세하게 설명되어 있다 https://developers.google.com/web/tools/chrome-devtools/console/. 이 창에서 HTML 태그, css selector 등을 테스트하고 프로그램에 사용하면 매우 유용하다.\n",
    "\n",
    "### 1.3.1 브라우저에서 Javascript concole 창 열기\n",
    "\n",
    "브라우저 | 콘솔창\n",
    "-----|-----\n",
    "Chrome | 브라우저 우측 상단 메뉴 > More tools > Developer Tools 또는 F12\n",
    "Internet Explorer | F12\n",
    "Firefox | Tools > Web Developer > Inspector\n",
    "Safari | advanced preferences > enable Develop menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3.2 Javascript console 창에서 selector 찾기\n",
    "\n",
    "콘솔창에서 javascript를 사용하여 selector를 추출할 수 있다.\n",
    "**xpath는 ```$x()```**, **css selecotr는 ```$()```**를 사용한다.\n",
    "\n",
    "단축키 | 설명\n",
    "-----|-----\n",
    "\\$x('xpath') | XPath와 일치하는 요소의 배열을 반환\n",
    "\\$('selector') | CSS 선택기와 일치하는 첫 번째 요소를 반환, document.querySelector()의 단축\n",
    "\\$$('selector all') | CSS 선택기와 일치하는 모든 요소의 배열을 반환, document.querySelectorAll()의 단축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* HTML title을 xpath, css로 추출하는 예이다. selector 텍스트를 추출하려면 'innerText'를 사용한다.\n",
    "\n",
    "선택 | xpath | css\n",
    "-----|-----|-----\n",
    "title태그 선택 | ```$x('//head/title') 또는 $x('//title')``` | ```$$('title')```\n",
    "선택의 결과가 복수인 경우, 배열을 반환 | ```$x('//head/title')[0]``` | ```$$('title')[0]```\n",
    "태그의 문자열을 추출 | ```$x('//head/title')[0].innerText``` | ```$$('title')[0].innerText```\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3.3 Elements 창에서 selector 찾기\n",
    "\n",
    "'Elements' 메뉴에서 xpath 또는 selector를 사용할 수 있다.\n",
    "\n",
    "* html소스에서, html tag를 누르면 맨 앞 '...'가 생김\n",
    "    * 이것을 누르면 팝업메뉴가 뜬다. 그리고 copy > xpath(또는 selector)를 선택하여 복사\n",
    "* 또는 단축키 **```<CTRL-F>```**로 '검색'창을 열고 검색 문자열, xpath, selector를 입력한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/2_elementCSScopy.png \"python.org F12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4 dom\n",
    "\n",
    "HTML을 파싱하면 tree구조로 변환할 수 있는데, 이러한 구조를 **DOM, Document Object Model**이라고 한다.\n",
    "DOM은 태그의 노드로 구성이 된다. 특정 DOM 노드를 선택하여 텍스트를 쓰거나, 속성을 설정할 수 있다.\n",
    "**document.querySelector()** 함수를 사용해 '.my'라는 클래스를 선택한다. 앞의 점이 class를 의미한다.\n",
    "h2태그의 배경색을 파란색으로 변경하는 기능이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h2 class=\"my\">Turn this into blue</h2>\n",
       "<button onclick=\"myFunction()\">Click</button>\n",
       "<script>\n",
       "    function myFunction() {\n",
       "        document.querySelector(\".my\").style.backgroundColor = \"blue\";\n",
       "    }\n",
       "</script>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<body>\n",
    "<h2 class=\"my\">Turn this into blue</h2>\n",
    "<button onclick=\"myFunction()\">Click</button>\n",
    "<script>\n",
    "    function myFunction() {\n",
    "        document.querySelector(\".my\").style.backgroundColor = \"blue\";\n",
    "    }\n",
    "</script>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이번에는 **document.getElementById()**를 사용해 p2라는 명칭을 선택한다. id가 p2인 ```<p>```태그를 빨간색으로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
       "    <p id=\"p2\">Hello World!</p>\n",
       "    <script>\n",
       "        document.getElementById(\"p2\").style.color = \"RED\";\n",
       "    </script>\n",
       "    <p>Hello World turned into RED!</p>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<body>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.5 BeautifulSoup\n",
    "\n",
    "BeautifulSoup은 Python에서 사용하는 html, xml 파서이다. **Java**로 만들어진 jsoup도 비슷한 기능을 가지고 있다. 이전 버전은 더 이상 지원되지 않으므로, 버전은 4로 한다.\n",
    "\n",
    "### 1.5.1 설치\n",
    "\n",
    "명령창에서 pip로 설치한다. 윈도우 Anaconda는 기본 설치되어 있다.\n",
    "```python\n",
    "pip install beautifulsoup4 (beautifulsoup은 버전3을 설치한다)\n",
    "```\n",
    "\n",
    "Linux Ubuntu에서 apt를 사용하여 설치할 수 있다. 'sudo'는 관리자 권한이다.\n",
    "```python\n",
    "sudo apt install python-bs4 (Python 2을 사용하는 경우)\n",
    "sudo apt install python3-bs4 (Python 3을 사용하는 경우)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* BeautifulSoup은 html을 DOM으로 변환하여, 다음 4가지 객체를 생성하여 사용한다.\n",
    "\n",
    "객체 | 설명\n",
    "-----|-----\n",
    "BeautifulSoup | html을 DOM으로 변환한 문서 전체를 말한다. 아래에서 파싱한 결과가 들어있는 'soup' 이다.\n",
    "Tag | html 태그이다. 태그명, 태그속성, 태그의 텍스트를 가지고 있다.\n",
    "NavigableString | Python에서 사용하는 unicode 문자열과 유사하지만, 몇 가지 추가되는 기능을 제공한다.\n",
    "Comment | html comment, 도움말을 뜻한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.2 BeautifulSoup 객체\n",
    "\n",
    "첫째로 BeautifulSoup객체는 html을 DOM으로 변환한 문서 전체를 말한다. \n",
    "BeautifulSoup을 사용할 경우, 파서를 넣어서 사용한다. Python에 내장된 html.parser 또는 lxml을 사용하면 된다.\n",
    "\n",
    "파서 | 설치 | 설정\n",
    "-----|-----\n",
    "**html.parser** | Python에 내장 | BeautifulSoup(markup, \"html.parser\")\n",
    "**lxml** parser | C로 만든 파서, 별도 설치가 필요 | BeautifulSoup(markup, \"lxml\")\n",
    "\n",
    "* Linux Ubuntu에서 'lxml' 설치\n",
    "\n",
    "```python\n",
    "apt-get install python-lxml\n",
    "```\n",
    "\n",
    "* 파이썬 패키지 저장소에서 'lxml' 설치\n",
    "\n",
    "```python\n",
    "pip install lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BeautifulSoup 라이브러리는 **from ... import ...** 호출방식으로 사용한다.\n",
    "'from import' 방식은 라이브러리 간 서로 의존하는 문제가 있을 경우에 경우에 사용한다. 예를 들어 my.py에서 x.py를 호출한다고 하자.\n",
    "* (1) x.py가 import y를 가지고 있다고 하자.\n",
    "* (2) my.py에서 x.py는 import mylib.x라고 불러 사용할 수 있다.\n",
    "* (3) 그러면 **x.py에서 가지고 있는 import y는 오류**가 된다. 즉, **상대적 호출**이라서 from mylib import y로 변경해 주어야 맞다.\n",
    "\n",
    "```python\n",
    "my.py       # 2) 여기서 x.py를 호출하려면 import mylib.x는 오류(x) \n",
    "mylib\\\n",
    "      x.py  # 1) 여기 import y를 가지고 있다고 하자. 3) import y => from mylib import y (o)\n",
    "      y.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "간단한 HTML문서를 파싱하여 BeautifulSoup 객체를 만들어 보자. 파서는 html.parser를 사용하고, BeautifulSoup객체는 변수 'soup'에 저장하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "_html=\"\"\"<html>\n",
    "<body>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(_html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[document]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <b>\n",
      "   <!--This page is to show how to use BeautifulSoup-->\n",
      "  </b>\n",
      "  <p id=\"p2\">\n",
      "   Hello World!\n",
      "  </p>\n",
      "  <script>\n",
      "   document.getElementById(\"p2\").style.color = \"RED\";\n",
      "  </script>\n",
      "  <p>\n",
      "   Hello World turned into RED!\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.3 태그 객체\n",
    "\n",
    "두번째로는 **태그 객체**이다. HTML 태그명, 속성, 텍스트 등을 읽을 수 있다.\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "soup.p | dot 연산자를 사용해 태그를 읽을 수 있다. 태그 자체를 읽으며 여러 개가 있더라도 처음 태그를 읽어 온다.\n",
    "soup.p.attrs | 태그의 속성을 dictionary 구조로 읽는다.\n",
    "soup.p['id'] | 태그의 속성을 dictionary 구조로 []괄호를 사용하여 읽는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "soup은 DOM을 가지고 있고, 그 중 'p' 태그객체를 살펴 보자.\n",
    "파싱을 하면서 자신이 어떤 타잎을 다루고 있는지 알고 있는 편이 좋다.\n",
    "'soup.p'의 type을 확인하면, 아래와 같이 **bs4.element.Tag**이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "soup.p 태그객체의 속성을 HTML 소스에서 확인해보자.\n",
    "속성은 'id'가 하나만 있고, 그 값을 알아볼 수 있다.\n",
    "또한 부모객체를 알아볼 수 있다. 계층을 하나 위 부모는 'body' 태그가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n",
      "{u'id': u'p2'}\n",
      "p2\n"
     ]
    }
   ],
   "source": [
    "print soup.p\n",
    "print soup.p.attrs\n",
    "print soup.p['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "DOM 트리로 구성되어 있기 때문에 트리를 따라 인접 태그노드로 이동할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<b><!--This page is to show how to use BeautifulSoup--></b>\n",
      "<p id=\"p2\">Hello World!</p>\n",
      "<script>\n",
      "        document.getElementById(\"p2\").style.color = \"RED\";\n",
      "    </script>\n",
      "<p>Hello World turned into RED!</p>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "print soup.p.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.4 문자열 객체\n",
    "\n",
    "세째로 BeautifulSoup에서 사용하는 객체는 '문자열'이다. 태그의 텍스트를 '.string'으로 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup.p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print soup.p.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.5 Comment 객체\n",
    "\n",
    "마지막으로 Comment 객체는 html 문서에 도움말을 넣을 경우, 사용하는 <!–– 도움말 ––> 태그를 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Comment'>\n",
      "This page is to show how to use BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "print type(soup.b.string)\n",
    "print soup.b.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.6 찾기\n",
    "\n",
    "find() 또는 find_all() 함수를 사용한다.\n",
    "**문자열이 아니라, 태그**를 찾아 준다.\n",
    "조건은 함수 인자에 적는다. 태그명, 태그속성을 **'=' 또는 dictionary 형식**으로 적는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n"
     ]
    }
   ],
   "source": [
    "print soup.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n"
     ]
    }
   ],
   "source": [
    "print soup.find(\"p\",id=\"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "Hello World!\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "p2tag=soup.find(\"p\", {\"id\":\"p2\"})\n",
    "print type(p2tag)\n",
    "print p2tag.text     # 모든 child의 string을 출력\n",
    "print p2tag.string   # 해당 Tag의 string을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "찾은 태그의 내용을 출력하기 위해서는 ```text``` 또는 ```string```을 사용할 수 있다.\n",
    "**```text```**는 **child의 text까지 합성**해서 돌려준다.\n",
    "반면 **```string```**은 좀 복잡하다. **child tag와 섞여 있을 경우 제외**하고 출력한다.\n",
    "다음의 테이블 태그를 가지고 테스트해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\"\"\"<td>cell 1</td>\n",
       "<td></td>\n",
       "<td><bold>cell 3 with bold child tag</bold></td>\n",
       "<td>cell 4<bold>bold child tag</bold></td>\"\"\""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\"\"\"<td>cell 1</td>\n",
    "<td></td>\n",
    "<td><bold>cell 3 with bold child tag</bold></td>\n",
    "<td>cell 4<bold>bold child tag</bold></td>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myhtml=\"\"\"<td>cell 1</td>\n",
    "<td></td>\n",
    "<td><bold>cell 3 with bold child tag</bold></td>\n",
    "<td>cell 4<bold>bold child tag</bold></td>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(myhtml,\"html.parser\")\n",
    "_td=soup.find_all(\"td\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "아래에서 보듯이 ```text```는 child를 포함한 모든 텍스트를 출력하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell 1\n",
      "\n",
      "cell 3 with bold child tag\n",
      "cell 4bold child tag\n"
     ]
    }
   ],
   "source": [
    "for e in _td:\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "반면에 ```string```은 첫째, 세째 줄만 출력하고 있다.\n",
    "\n",
    "td 줄 수 | 설명\n",
    "-----|-----\n",
    "줄 1 | ```<td>cell 1</td>```를 출력한다.\n",
    "줄 2 | 아무 태그도 없으므로 None을 출력\n",
    "줄 3 |<bold>cell 3 with bold child tag</bold>에서 보듯이 child 태그가 하나이므로 그 문자열을 출력하고\n",
    "줄 4 | ```cell 4``` 텍스트와 더불어 ```<bold>bold child tag</bold>``` 자식태그를 가지고 있으므로 출력하지 않고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell 1\n",
      "None\n",
      "cell 3 with bold child tag\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for e in _td:\n",
    "    print e.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-1: python.org 페이지가 가지고 있는 최근 뉴스 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "크롤링하려는 'www.python.org'는 파이썬 홈페이지이다.\n",
    "여기서 이 페이지가 포함하는 '최신 뉴스'를 알아보려고 한다.\n",
    "문제를 풀기 전에 'python.org'를 웹브라우저에서 방문한다.\n",
    "'Latest News'를 찾고 그 아래 뉴스를 읽어본다.\n",
    "\n",
    "### 풀이\n",
    "\n",
    "지난 번에는 문자열 방식으로 찾았는데, 원하는 항목을 잘라내는 시행착오를 여러 번 해야만 했었다.\n",
    "이번에는 BeautifulSoup을 사용하여 html을 DOM으로 파싱하고, 원하는 태그를 찾는다.\n",
    "우선 '소스보기'에서 원하는 태그를 찾아서, 그 태그를 조건으로 넣어야 편리하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "python.org를 방문하여 기능키 F12를 눌러 HTML 소스를 보자.\n",
    "우측 HTML 소스에서 마우스를 움직여 보면서 우리가 원하는 데이터가 하일라이트 되는 부분을 찾는다.\n",
    "```Latest News```가 하일라이트 되는 HTML 소스를 부면 medium-widget과 blog-widget 2개의 클래스가 있다.\n",
    "이중 medium-widget은 여러 개가 해당이 되어 후보로서 부적절하다.\n",
    "클래스 ```.blog-widget```를 찾아보면 1개만 특정할 수 있어 훌륭한 후보가 된다. 이 클래스의 목록 ```li```를 시도해 보자. 그러면 우리가 원하는 5개 항목을 모두 특정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/2_cssPythonOrg.png \"python.org css selector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "page=r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 원하는 태그를 찾으면, class 'blog-widget'이라는 것을 알 수 있다.\n",
    "* class 다음에는 '_'를 넣어 준다. 또는 key-value 형식으로 맞추어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news=soup.find(class_=\"blog-widget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "일단 우리가 찾는 blog-widget 클래스는 찾았다.\n",
    "그 클래스 구조를 보자. 그 안에 li태그가 있고, li태그 안에 time, a태그가 있다.\n",
    "```python\n",
    "<li>\n",
    "    <time></time>\n",
    "    <a></a>\n",
    "</li>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"medium-widget blog-widget\">\n",
      "<div class=\"shrubbery\">\n",
      "<h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-news\"></span>Latest News</h2>\n",
      "<p class=\"give-me-more\"><a href=\"http://blog.python.org\" title=\"More News\">More</a></p>\n",
      "<ul class=\"menu\">\n",
      "<li>\n",
      "<time datetime=\"2018-10-20T18:00:00.000005+00:00\"><span class=\"say-no-more\">2018-</span>10-20</time>\n",
      "<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/YzP__6BA7PI/python-371-and-367-are-now-available.html\">Python 3.7.1 and 3.6.7 are now available. Python 3.7.1 is the first maintenance release of ...</a></li>\n",
      "<li>\n",
      "<time datetime=\"2018-10-13T21:00:00.000005+00:00\"><span class=\"say-no-more\">2018-</span>10-13</time>\n",
      "<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/zVpPtYYRZDE/python-371rc2-and-367rc2-are-now.html\">Python 3.7.1rc2 and 3.6.7rc2 are now available. 3.7.1rc2 is a release preview of the first maintenance ...</a></li>\n",
      "<li>\n",
      "<time datetime=\"2018-09-27T02:00:00.000003+00:00\"><span class=\"say-no-more\">2018-</span>09-27</time>\n",
      "<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/4U66sA2wtWw/python-371rc1-and-367rc1-now-available.html\">Python 3.7.1rc1 and 3.6.7rc1 are now available. 3.7.1rc1 is the release preview of the first maintenance ...</a></li>\n",
      "<li>\n",
      "<time datetime=\"2018-08-02T14:03:00.000003+00:00\"><span class=\"say-no-more\">2018-</span>08-02</time>\n",
      "<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/5EA0ClmtbD8/python-356-and-python-349-are-now.html\">Python 3.5.6 and Python 3.4.9 are now available. You can download ...</a></li>\n",
      "<li>\n",
      "<time datetime=\"2018-06-28T00:00:00.000003+00:00\"><span class=\"say-no-more\">2018-</span>06-28</time>\n",
      "<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/RMqgTQsV720/python-3.html\">Python 3.7.0 is now available (and so is 3.6.6)! On behalf of ...</a></li>\n",
      "</ul>\n",
      "</div><!-- end .shrubbery -->\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-16T21:58:00.000005+00:00\n"
     ]
    }
   ],
   "source": [
    "print news.li.time['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest bugfix release in the Python 2.7 series, Python ...\n"
     ]
    }
   ],
   "source": [
    "print news.li.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>\\n<time datetime=\"2017-09-16T21:58:00.000005+00:00\"><span class=\"say-no-more\">2017-</span>09-16</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/3SUhDRzB1-s/python-2714-released.html\">The latest bugfix release in the Python 2.7 series, Python ...</a></li>, <li>\\n<time datetime=\"2017-09-07T00:13:00.000003+00:00\"><span class=\"say-no-more\">2017-</span>09-07</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/pUndlLcEcKE/python-337rc1-is-now-available-prior-to.html\">Python 3.3.7rc1 is now available, the release candidate of Python ...</a></li>, <li>\\n<time datetime=\"2017-08-27T03:41:00.000006+00:00\"><span class=\"say-no-more\">2017-</span>08-27</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/pe2Ug4MA0Lg/python-2714-release-candidate-1.html\">The first release candidate for Python 2.7.14 is now available ...</a></li>, <li>\\n<time datetime=\"2017-08-09T07:34:00.000002+00:00\"><span class=\"say-no-more\">2017-</span>08-09</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/vY72b719CGk/python-354-and-python-347-are-now.html\">Python 3.5.4 and Python 3.4.7 are now available for download. ...</a></li>, <li>\\n<time datetime=\"2017-07-25T08:40:00.000001+00:00\"><span class=\"say-no-more\">2017-</span>07-25</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/ry7faTWPZiY/python-354rc1-and-python-347rc1-are-now.html\">Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...</a></li>]\n"
     ]
    }
   ],
   "source": [
    "print news.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 지금까지 찾은 항목을 for 문으로 모두 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-16T21:58:00.000005+00:00 The latest bugfix release in the Python 2.7 series, Python ...\n",
      "2017-09-07T00:13:00.000003+00:00 Python 3.3.7rc1 is now available, the release candidate of Python ...\n",
      "2017-08-27T03:41:00.000006+00:00 The first release candidate for Python 2.7.14 is now available ...\n",
      "2017-08-09T07:34:00.000002+00:00 Python 3.5.4 and Python 3.4.7 are now available for download. ...\n",
      "2017-07-25T08:40:00.000001+00:00 Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...\n"
     ]
    }
   ],
   "source": [
    "for e in news.find_all(\"li\"):\n",
    "    print e.time[\"datetime\"], e.a.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "지금까지 프로그램을 파일 버전으로 저장해서 실행해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  49299\n",
      "2018-03-31T11:56:00.000005+00:00 On behalf of the PyPA, I am pleased to announce ...\n",
      "2018-03-30T01:42:00.000004+00:00 Python 3.7.0b3 is the third of four planned beta previews of Python ...\n",
      "2018-03-28T21:59:00.000002+00:00 Python 3.6.5 is now available.  3.6.5 is the fifth maintenance release of ...\n",
      "2018-03-26T20:59:00+00:00 The new Python Package Index at https://pypi.org is now in ...\n",
      "2018-03-14T04:46:00.000002+00:00 Python 3.6.5rc1 is the first release candidate for Python 3.6.5, ...\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_1_readPythonOrgBS.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readLatestNews():\n",
    "    try:\n",
    "        r = requests.get(u'http://python.org/')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    page=r.text\n",
    "    print \"length: \",len(page)\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    news=soup.find(\"div\", class_=\"blog-widget\")\n",
    "    for e in news.find_all(\"li\"):\n",
    "        print e.time[\"datetime\"], e.a.string\n",
    "\n",
    "def main():\n",
    "    readLatestNews()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 추가문제: \"Use Python for..\"를 수집해 보자.\n",
    "\n",
    "구분 | css selector\n",
    "-----|-----\n",
    "Use Python for 본문 | .applications-widget\n",
    "항목 | .applications-widget li\n",
    "태그 | .applications-widget .tag-wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  49279\n",
      "Web Development:\r\n",
      "        Django, Pyramid, Bottle, Tornado, Flask, web2py\n",
      "GUI Development:\r\n",
      "        tkInter, PyGObject, PyQt, PySide, Kivy, wxPython\n",
      "Scientific and Numeric:\r\n",
      "        \n",
      "SciPy, Pandas, IPython\n",
      "Software Development:\r\n",
      "        Buildbot, Trac, Roundup\n",
      "System Administration:\r\n",
      "        Ansible, Salt, OpenStack\n",
      "Django, Pyramid, Bottle, Tornado, Flask, web2py\n",
      "tkInter, PyGObject, PyQt, PySide, Kivy, wxPython\n",
      "\n",
      "SciPy, Pandas, IPython\n",
      "Buildbot, Trac, Roundup\n",
      "Ansible, Salt, OpenStack\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    r = requests.get(u'http://python.org/')\n",
    "    r.raise_for_status()\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print e\n",
    "    sys.exit(1)\n",
    "page=r.text\n",
    "print \"length: \",len(page)\n",
    "soup = BeautifulSoup(page,\"html.parser\")\n",
    "news=soup.find(class_=\"applications-widget\")\n",
    "# print all li\n",
    "lists=news.find_all(\"li\")\n",
    "for li in lists:\n",
    "    print li.text\n",
    "# print all tags\n",
    "tags=news.find_all(class_=\"tag-wrapper\")\n",
    "for tag in tags:\n",
    "    print tag.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.6 regex\n",
    "\n",
    "정규식 regular expression은 문자열로 표현한 정규표현으로, 패턴매칭에 사용한다.\n",
    "정규식으로 표현하면 복잡한 패턴도 간편하게 처리할 수 있다.\n",
    "정규식은 **메타문자**를 사용한다. 역슬래시 ```\\```와 결합하여 특별한 의미를 가진다. 예를 들어 d는 역슬래시와 결합하여 숫자를, s는 공백을 의미한다.\n",
    "\n",
    "정규식 | 설명 | 예\n",
    "-----|-----|-----\n",
    "() | grouping | (\\d{1,2})\n",
    "\\d | any character in the range 0-9 |\n",
    "\\s | any whitespace |\n",
    "\\w | any character in the range 0-9, A-Z, a-z |\n",
    "[] | a signle character | [a-cx-z] = \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\"\n",
    "\\- | range separator | [0123456789] = [0-9]\n",
    "\\* | the preceding element zero or more times | ab*c = \"ac\", \"abc\", \"abbbc\"\n",
    "\\+ | the preceding element one or more times  | ba+ = \"ba\", \"baa\", \"baaa\", and so on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.6.1 문자, 순자 추출해 보기\n",
    "\n",
    "* 정규식을 사용하면 문장에서 숫자, 문자를 편리하게 추출할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자와 문자:  ['Here', 'goes', 'my', 'phone', 'number', '2287', '1111', 'Nice', 'to', 'meet', 'you', 'Merry', 'Christmas']\n",
      "숫자:  ['2287', '1111']\n",
      "대문자를 가진 단어:  ['Here', 'Nice', 'Merry', 'Christmas']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence=\"Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas\"\n",
    "regex1='\\w+'\n",
    "print \"숫자와 문자: \",re.findall(regex1, sentence)\n",
    "regex2='\\d+'\n",
    "print \"숫자: \",re.findall(regex2, sentence)\n",
    "regex3 = '[A-Z]\\w+'\n",
    "print \"대문자를 가진 단어: \",re.findall(regex3, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 정규식을 사용하여 태그를 찾을 수 있다.\n",
    "* a태그의 문자열을 읽어 본다.\n",
    "    * a태그의 패턴을 정하고,\n",
    "    * 그 안의 모든 문자 '.*'를 '()'그룹으로 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tag:  ['foo']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tags='<html><body><div>asdfasdf</div><p><a>foo</a></p></body></html>'\n",
    "regex=\"<a>(.*)</a>\"\n",
    "print \"a tag: \",re.findall(regex, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.6.2 BeautifulSoup과 같이 regex를 사용\n",
    "\n",
    "BeautifulSoup를 사용하면 간편하게 태그, css 등을 검색할 수 있었다.\n",
    "regex는 매우 정교하게 자신의 입맛에 딱 들어맞는 패턴을 정할 수 있다는 장점이 있다. 즉, **태그**뿐만 아니라 **태그 속성**, **태그 텍스트** 가리지 않고 검색패턴이 있다면 매우 정교하게 검색패턴을 찾을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup import BeautifulSoup\n",
    "import re\n",
    "\n",
    "htmlstr = \"\"\"\n",
    "<p>Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas</p>\n",
    "<p>this is text</p2>\n",
    "<a href=\"https://www.example.com\">Visit example.com</a>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(htmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "숫자를 포함한 텍스트 ***```\\d+```***를 출력해 보자.\n",
    "또 그 텍스트를 포함한 부모태그 parent도 출력배 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas\n",
      "tag:  <p>Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas</p>\n"
     ]
    }
   ],
   "source": [
    "for e in soup(text=re.compile(r'\\d+')):\n",
    "    print \"text: \", e\n",
    "    print \"tag: \", e.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BeautifulSoup의 기능을 풍성하게 사용할 수 있다. 즉 ```href```에 ```ex```를 포함한 텍스트를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit example.com\n"
     ]
    }
   ],
   "source": [
    "for e in soup.findAll(href=re.compile(\"ex\")):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.7 xpath\n",
    "\n",
    "xpath는 XML Path Language의 약어로 xml문서를 트리구조로 표현하고, 노드를 선택하기 위해 사용하는 조회언어이다.\n",
    "\n",
    "* xpath 표현\n",
    "\n",
    "Expression | 설명 | 예\n",
    "---------|----------|----------\n",
    "/ | root부터 선택 | ```$x('/html')``` 루트에 있는 html 선택\n",
    "// | 어디에 있는지 상관없이 선택 | ```$x('//div')``` 어디에 있든 div 선택 \n",
    ". | Selects the current node | \n",
    ".. | Selects the parent of the current node | \n",
    "@ | Selects attributes | //@href 속성href를 가진 모든 노드\n",
    "\\* | all |\n",
    "@* | 속성 모두 | //div[@*] 속성을 가지고 있는 모든 div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.1 lxml\n",
    "\n",
    "lxml은:\n",
    "* lxml.etree는 **XML**을 파싱한다. 그러나 HTMLParsor()를 사용하면 html을 파싱할 수 있다.\n",
    "* lxml.html는 **HTML**을 파싱할 경우 사용한다.\n",
    "\n",
    "BeautifulSoup은 xpath를 지원하지 않는다.\n",
    "실행하는 단계는 다른 라이브러리를 사용하는 단계와 다르지 않다.\n",
    "불완전한 태그일 경우 오류가 발생할 수 있다는 점에 주의한다.\n",
    "\n",
    "구분 | 파싱 | 설명 | 읽는 함수\n",
    "-----|-----|-----|-----\n",
    "lxml.etree | XML | c로 구현해서 빠르다. HTMLParsor()파서를 선택하면 HTML을 파싱할 수 있다. | **파일**에서 읽기 parse()<br>**문자열**에서 읽기 fromstring() (단 html은 XML로 인식하기 때문에 HTML()함수를 사용한다.)\n",
    "lxml.html | HTML | Python으로 구현 | 상동\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* lxml.etree에서 HTML을 파싱하려면 HTMLParser()를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "parser=lxml.etree.HTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.2 파일에서 파싱\n",
    "\n",
    "* 파일에서 읽으므로 parse() 함수를 사용한다.\n",
    "* 디렉토리로부터 파일을 읽을 경우, os.path.join()을 사용한다. 앞서 설명한 바와 같이 디렉토리 구분자로 인한 오류를 제거할 수 있다.\n",
    "```<meta>``` 태그는'시작'은 있고, '끝' 태그가 없어 오류가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tree=lxml.etree.parse(os.path.join('src','mypage2.html'),parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* getiterator()는 모든 태그를 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 태그: html -> \n",
      "\n",
      "- 태그: head -> \n",
      "\n",
      "- 태그: meta -> None\n",
      "- 태그: title -> My Home Page\n",
      "- 태그: body -> \n",
      "\n",
      "- 태그: h1 -> 안녕하십니까\n",
      "- 태그: p -> 오늘은 프로그래밍 하는 날...\n",
      "- 태그: p -> Today we do programming...\n"
     ]
    }
   ],
   "source": [
    "for node in tree.getiterator():\n",
    "    print \"- 태그:\", node.tag, \"->\", node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.2 문자열에서 파싱\n",
    "\n",
    "* html 문자열을 파싱한다. 문자열은 파일에서 읽어서 만든다.\n",
    "* 'mypage2.html'은 meta 태그를 포함하고 있어, 오류가 발생한다는 점 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 태그: html {}\n",
      "- 태그: body {}\n",
      "- 태그: h1 {}\n",
      "- 태그: b {}\n",
      "- 태그: <cyfunction Comment at 0x7f6cc97cf590> <lxml.etree._ImmutableMapping object at 0x7f6cc97a1790>\n",
      "- 태그: p {'id': 'p2'}\n",
      "- 태그: script {}\n",
      "- 태그: p {}\n"
     ]
    }
   ],
   "source": [
    "import lxml.etree\n",
    "_html=\"\"\"<html>\n",
    "<body>\n",
    "    <h1>안녕하세요</h1>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "tree=lxml.etree.fromstring(_html)\n",
    "for node in tree.getiterator():\n",
    "    print \"- 태그:\", node.tag, node.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 트리구조로 만드는 작업을 하고 난 후 xpath를 사용할 수 있다.\n",
    "* xpath를 사용하여 h1 태그의 문자열을 읽는다.\n",
    "* unicode값이 반환된다. 또한 배열로 만들어져 있다는 점에 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\uc548\\ub155\\ud558\\uc138\\uc694']\n"
     ]
    }
   ],
   "source": [
    "tree=lxml.etree.fromstring(_html)\n",
    "print tree.xpath('//h1/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요\n"
     ]
    }
   ],
   "source": [
    "print tree.xpath('//h1/text()')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.8 css selectors\n",
    "\n",
    "CSS, Cascading Style Sheets는 html문서의 스타일을 설정하는 규칙을 말한다. 스타일 태그의 선택자 selector를 사용하여, 원하는 태그를 추출할 수 있다. css를 더 배우고 싶으면 [css selectors](http://www.w3schools.com/cssref/css_selectors.asp)를 방문해보자.\n",
    "\n",
    "selector 구분 | css selector 예시 | 설명 | xpath 예시\n",
    "------------|------------|------------|------------\n",
    "[attribute] | $$('input[type=\"email\"]') | 괄호는 속성을 선택할 때 사용한다. 예를 들어 input type이 email을 선택할 때 사용하는 경우 | $x('//input[@type=\"email\"]')\n",
    "type | 'div' 'a' | div 태그, a 태그 | '//div' '//a'\n",
    "class | '.foo' | class 속성이 foo를 선택 | '//*[@class=\"foo\"]'\n",
    "id | '#foo' | id foo (1개만 선택. 클래스는 여러 개 선택) | '//*[@id=\"foo\"]'\n",
    "universal | '*' | all | '//*'\n",
    "descendents | 'div a' | all a's inside div (**여러 세대 떨어져도** 선택) | '//div//a' \n",
    "child | 'div > a' | a's only children to the div (**1세대 다음**) | '//div/a'\n",
    "parents | a ~ b | any parents of b (**여러 세대** 위) |\n",
    "grouped | 'h1, h2' | 'h1 h2' |\n",
    "text | 'a::text' | 선택한 노드, element의 text.<br>javascript console에서는 'innerText' | '//a/text()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.8.1 html에서 css\n",
    "\n",
    "CSS를 사용해서 html문서의 스타일을 설정한다. html 색, 폰트 등 어떻게 보여지는지를 정한다. 아래는 css를 html에 넣어서 태그의 스타일을 설정하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile src/mypage3.html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>My Home Page</title>\n",
    "    <style>\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            color:red;\n",
    "            font-family: 'Droid Sans', sans-serif;\n",
    "        };  \n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>안녕하십니까</h1>\n",
    "    <p>오늘은 프로그래밍 하는 날...</p>\n",
    "    <p>Today we do programming...</p>\n",
    "\n",
    "    <div id=\"divid\">\n",
    "        <h2>Hello h2</h2>\n",
    "        <p>Here we use div id.</p>\n",
    "        <a href=\"https://www.example.com\">Visit example.com</a>\n",
    "    </div>\n",
    "    <div class=\"divclass\">\n",
    "        <h2>Welcome</h2>\n",
    "        <p>Here we use div class.</p>\n",
    "        <ul>\n",
    "            <li>first</li>\n",
    "            <li>second</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "\n",
    "    <form action=\"\">\n",
    "    Email <input type=\"email\" value=\"emailvalue\" name=\"emailname\" id=\"emailid\"\n",
    "        class=\"emailclass\" style=\"background-color: green;\"required>\n",
    "    Zip Code <input type=\"number\" name=\"zipname\" required>\n",
    "    <textarea rows=\"4\" columns=\"50\"></textarea>\n",
    "    <input type=\"submit\" value=\"Submit\">\n",
    "    </form>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.8.2 lxml을 사용해서 하기\n",
    "\n",
    "lxml은 **xml뿐만 아니라 html을 파싱**할 수도 있다.\n",
    "lxml.html은 파이썬으로 만들어져 있어서 파이썬 사용자에게 사용하기에 편리하다.\n",
    "이 라이브러러를 **css와 같이 사용하려면 cssselect 라이브러리가 필요**하다.\n",
    "cssselect 라이브러리가 없는 경우에는 pip를 사용해서 설치한다.\n",
    "\n",
    "```python\n",
    "pip install lxml cssselect\n",
    "```\n",
    "\n",
    "* 리눅스에서는 xml라이브러리가 필요하다.\n",
    "```python\n",
    "sudo apt-get install libxml2-dev libxslt1-dev\n",
    "pip install lxml cssselect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 파싱\n",
    "\n",
    "HTML 태그는 보통 쌍으로 구성되어 있다.\n",
    "몇 태그는 쌍으로 되어 있지 않은데, **시작-끝 태그로 구성되지 않은** meta 태그 등은 문제가 될 수 있다.\n",
    "이와 같은 불완전한 태그 또는 **broken html**도 lxml은 오류 없이 처리할 수 있다.\n",
    "아래 불완전한 meta 태그를 lxml을 사용해서 파싱해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "htmlstr=\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>My Home Page</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>안녕하십니까</h1>\n",
    "<p>Big data programming</p>\n",
    "<p>오늘은 프로그래밍 하는 날...</p>\n",
    "<p>Today we do programming...</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "앞서 HTML 문자열을 파싱하려면 **fromstring()** 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "tree = lxml.html.fromstring(htmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### css select\n",
    "\n",
    "cssselect를 사용해서 ```<body>``` 아래 ```<h1>``` 태그를 가져와 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body h1'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### nth-child\n",
    "\n",
    "```'nth-child'```는 **순서로 특정 항목을 선택**할 경우 사용한다.\n",
    "```'p:nth-child(2)'```는 두 번째 ```<p>```태그를 의미한다.\n",
    "잠깐! **몇 번째**라는 의미는 무엇인지 잠깐 생각해보자.\n",
    "```<p>```태그를 선택하는데 몇 번째 child인지 어떻게 알 수 있을까? 당연히 **부모로부터 세어야** 한다.\n",
    "이렇게 따져보면 **```<p>```태그 부모인 ```<body>```의 2번째 child**를 선택한다는 뜻이다. \n",
    "문법에 유의하면서 살펴보자. **세미콜론 ```:``` 앞에는 찾는 태그를 적는다. 즉 ```<p>```이다.\n",
    "그 부모는 ```<body>```**이다. 거기서부터 **몇 번째 child**인지 따져서 검색하자.\n",
    "\n",
    "문법 | 설명\n",
    "-----|-----\n",
    "p | 검색 태그\n",
    ": | 검색 태그와 순서의 구분자\n",
    "nth-child | 순서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "다음을 실행해 보자.\n",
    "* ```<body>```의 1번째 child는 ```<h1>```\n",
    "* ```<body>```의 2번째 3번째 4번째는 ```<p>``` 태그이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('h1:nth-child(1)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big data programming\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('p:nth-child(2)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘은 프로그래밍 하는 날...\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('p:nth-child(3)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.8.3 BeautifulSoup을 사용해서 하기\n",
    "\n",
    "BeautifulSoup에 lxml 파서를 넣어서 사용할 수도 있다.\n",
    "단지 parser만 교체해서 사용하므로 사용하는 방법, 즉 API는 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(htmlstr,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in soup.select('body h1'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.8.4 테이블을 읽기\n",
    "\n",
    "테이블은 데이터를 행과 열로 표현하는 방식으로, 웹페이지에서 자주 사용되고 있다.\n",
    "\n",
    "아래와 같이 table은 헤더(thead)와 내용(tbody)으로 구분하고 있다.\n",
    "경우에 따라 tbody는 생략할 수 있다. thead가 없는 경우 또는 tbody 다음 첫 줄이 tr인 경우가 그렇다.\n",
    "css selector를 사용하면 행은 'tr', 셀은 'td'로 검색한다.\n",
    "**BeautifulSoup은 'nth-child'는 지원하지 않으므로, 'nth-of-type'을 사용**한다.\n",
    "\n",
    "구분 | css selector\n",
    "-----|-----\n",
    "테이블 행 검색 | tbody tr\n",
    "테이블 첫행 검색 | tbody tr:nth-of-type(1)\n",
    "테이블 셀 검색 | tbody tr td\n",
    "테이블 첫셀 검색 | tbody tr td:nth-of-type(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 파싱\n",
    "\n",
    "테이블 태그를 파싱해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "tableHtml=\"\"\"\n",
    "<table id='thetable'>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Head 1</th>\n",
    "            <th>Head 2</th>\n",
    "            <th>Head 3</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Cell 11</td>\n",
    "            <td>Cell 12</td>\n",
    "            <td>Cell 13</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Cell 21</td>\n",
    "            <td>Cell 22</td>\n",
    "            <td>Cell 23</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "\"\"\"\n",
    "\n",
    "soup=BeautifulSoup(tableHtml,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### nth-of-type\n",
    "\n",
    "좀 여러운 검색이 될 수 있는 nth-of-type을 찾아보자.\n",
    "\"td:nth-of-type(1)\"는 **td태그 부모인 tr의 첫째 자식**인 Cell 11을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "expecting Cell 11 ->  [<td>Cell 11</td>]\n"
     ]
    }
   ],
   "source": [
    "my1=soup.select(\"td:nth-of-type(1)\")\n",
    "print \"\\nexpecting Cell 11 -> \", my1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"tr:nth-of-type(1)\"는 **```<tr>```태그 부모인 ```<tbody>```의 첫째 자식**을 찾고 있다.\n",
    "단 주의할 점은 ```<tbody>```의 첫째 자식부터이다. 즉 ```<thead>```가 아니고 ```<tbody>```서부터 첫째 자식을 찾게 된다. 따라서 Cell 11 12 13을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "expecting Cell 11 12 13 -> \n",
      "result: [<tr>\\n<td>Cell 11</td>\\n<td>Cell 12</td>\\n<td>Cell 13</td>\\n</tr>]\n"
     ]
    }
   ],
   "source": [
    "my2=soup.select(\"#thetable > tbody > tr:nth-of-type(1)\")\n",
    "print \"\\nexpecting Cell 11 12 13 -> \"\n",
    "print \"result:\", my2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "text는 앞서 배운대로 child태그 텍스트를 모두 출력하고 있다. 반면 string은 자신의 텍스트가 없으므로 출력하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cell 11\n",
      "Cell 12\n",
      "Cell 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in my2:\n",
    "    #print e.string -> does not print\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```<tr>```태그는 세 줄이다. 이를 모두 출력하기 위해 select()를 사용한다.\n",
    "**```get_text()```**는 text를 가져오는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Table Rows: 3\n"
     ]
    }
   ],
   "source": [
    "my3=soup.select(\"#thetable tbody tr\")\n",
    "print \"Num Table Rows:\", len(my3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cell 11 Cell 12 Cell 13   Cell 21 Cell 22 Cell 23   \n"
     ]
    }
   ],
   "source": [
    "for e in my3:\n",
    "    row=e.get_text().split('\\n')\n",
    "    for cell in row:\n",
    "        print cell,  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "프로그램으로 완성하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "expecting Cell 11 ->  [<td>Cell 11</td>]\n",
      "\n",
      "expecting Cell 11 12 13 ->  [<tr>\\n<td>Cell 11</td>\\n<td>Cell 12</td>\\n<td>Cell 13</td>\\n</tr>]\n",
      "\n",
      "Cell 11\n",
      "Cell 12\n",
      "Cell 13\n",
      "\n",
      "Num Table Rows: 3\n",
      " Cell 11 Cell 12 Cell 13   Cell 21 Cell 22 Cell 23   \n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_5_testTable.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "tableHtml=\"\"\"\n",
    "<table id='thetable'>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Head 1</th>\n",
    "            <th>Head 2</th>\n",
    "            <th>Head 3</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Cell 11</td>\n",
    "            <td>Cell 12</td>\n",
    "            <td>Cell 13</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Cell 21</td>\n",
    "            <td>Cell 22</td>\n",
    "            <td>Cell 23</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "\"\"\"\n",
    "\n",
    "def do():\n",
    "    soup=BeautifulSoup(tableHtml,\"html.parser\")\n",
    "    my1=soup.select(\"#thetable tbody tr td:nth-of-type(1)\")\n",
    "    print \"\\nexpecting Cell 11 -> \", my1\n",
    "    my2=soup.select(\"#thetable > tbody > tr:nth-of-type(1)\")\n",
    "    print \"\\nexpecting Cell 11 12 13 -> \", my2\n",
    "    for e in my2:\n",
    "        #print e.string -> does not print\n",
    "        print e.text\n",
    "    my3=soup.select(\"#thetable tbody tr\")\n",
    "    print \"Num Table Rows:\", len(my3)\n",
    "    for e in my3:\n",
    "        row=e.get_text().split('\\n')\n",
    "        for cell in row:\n",
    "            print cell,  \n",
    "\n",
    "def main():\n",
    "    do()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-2: python.org 페이지가 가지고 있는 http url 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "파이썬 홈페이지 'www.python.org' 가 포함하는 링크를 찾아 보려고 한다.\n",
    "웹브라우저를 열고 'python.org'라고 입력해 보자.\n",
    "마우스를 가져가면 하이퍼링크가 활성화된다. 이런 링크를 가져오는 것이 문제이다.\n",
    "링크는 문서내의 다른 장소로 이동하거나 다른 웹페이지로 이동하는 기능을 제공한다.\n",
    "다른 페이지로 이동하는 링크만 출력한다.\n",
    "* 전체 링크의 갯수\n",
    "* 다른 페이지로 가는 링크 목록\n",
    "\n",
    "웹브라우저 메뉴에서 소스보기를 클릭하면 html 소스를 볼 수 있다. 하나씩 세어도 답을 할 수 있지만 프로그램으로 하면 시간, 노력, 오류를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 풀이\n",
    "\n",
    "주소창에 url을 입력하고 웹페이지를 요청하는 것과 같이 Python.org페이지를 크롤링해 온다. 다음 방식으로 해 본다.\n",
    "* BeautifulSoup\n",
    "* regex\n",
    "* xpath\n",
    "* css selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "* requests로 url의 페이지를 가져와서, 그 페이지를 BeautifulSoup으로 parsing한다.\n",
    "* 위 예제, p 태그의 처음에 있는 strong 태그 가져오기\n",
    "* 파서 'lxml'을 넣어서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "_html=r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#soup = BeautifulSoup(_html,\"html.parser\")\n",
    "soup=BeautifulSoup(_html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" dir=\"ltr\" lang=\"en\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <link href=\"//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.mi\n"
     ]
    }
   ],
   "source": [
    "print soup.prettify()[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* BeautifulSoup find_all('a') 함수로 'a' 태그를 가져온다.\n",
    "* 'a' 태그가 수 백개가 되므로, 20개만 출력한다. 전체 개수는 맨 마지막 줄에 출력한다.\n",
    "* 'a href'의 출력을 살펴 보자.\n",
    "    * #, javascript 함수, local links, external links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "atags=soup.find_all('a',href=True)\n",
    "print len(atags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 #content\n",
      "1 #python-network\n",
      "2 /\n",
      "3 /psf-landing/\n",
      "4 https://docs.python.org\n",
      "5 https://pypi.python.org/\n",
      "6 /jobs/\n",
      "7 /community/\n",
      "8 #top\n",
      "9 /\n",
      "10 #site-map\n",
      "11 #\n",
      "12 javascript:;\n",
      "13 javascript:;\n",
      "14 javascript:;\n",
      "15 #\n",
      "16 http://plus.google.com/+Python\n",
      "17 http://www.facebook.com/pythonlang?fref=ts\n",
      "18 http://twitter.com/ThePSF\n",
      "19 /community/irc/\n"
     ]
    }
   ],
   "source": [
    "for counter,link in enumerate(atags):\n",
    "    if(counter<20):\n",
    "        print counter,link.get('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "requests 대신 urlopen을 사용할 수 있다. 그 과정은 서로 많은 차이가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /wiki/Wikipedia:Protection_policy#semi\n",
      "1 #mw-head\n",
      "2 #p-search\n",
      "3 /wiki/HTM_(disambiguation)\n",
      "4 /wiki/Help:HTML_in_wikitext\n",
      "5 /wiki/File:HTML.svg\n",
      "6 /wiki/Filename_extension\n",
      "7 /wiki/Media_type\n",
      "8 /wiki/Type_code\n",
      "9 /wiki/World_Wide_Web_Consortium\n",
      "10 /wiki/WHATWG\n",
      "11 /wiki/Software_release_life_cycle\n",
      "12 /wiki/HTML5\n",
      "13 #cite_note-1\n",
      "14 /wiki/Document_file_format\n",
      "15 /wiki/Standard_Generalized_Markup_Language\n",
      "16 /wiki/XHTML\n",
      "17 /wiki/International_standard\n",
      "18 http://www.w3.org/TR/html/\n",
      "19 http://whatwg.org/html\n",
      "Total:  1761\n"
     ]
    }
   ],
   "source": [
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "#_html = urlopen(\"http://en.wikipedia.org/wiki/Kevin_Bacon\")\n",
    "_html = urlopen(\"http://en.wikipedia.org/wiki/HTML\").read()\n",
    "tree = BeautifulSoup(_html, \"lxml\")\n",
    "counter=0\n",
    "for link in tree.findAll(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        if counter<20:\n",
    "            print counter, link.attrs['href']\n",
    "        counter+=1\n",
    "print \"Total: \", counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 파일 버전\n",
    "\n",
    "웹페이지를 읽을 경우, 파일과 같이 **존재하지 않거나**, **열 수 없는** 등 오류가 발생할 수 있다. 이 때 예외처리 **try-except**를 넣어서 처리하는 편이 좋다.\n",
    "아래 프로그램은 href link만 세어서 출력하고 있다. 2018년 4월 205개이다.\n",
    "이 가운데 20개만 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of links: 205\n",
      "0 #content\n",
      "1 #python-network\n",
      "2 /\n",
      "3 /psf-landing/\n",
      "4 https://docs.python.org\n",
      "5 https://pypi.python.org/\n",
      "6 /jobs/\n",
      "7 /community/\n",
      "8 #top\n",
      "9 /\n",
      "10 #site-map\n",
      "11 #\n",
      "12 javascript:;\n",
      "13 javascript:;\n",
      "14 javascript:;\n",
      "15 #\n",
      "16 http://plus.google.com/+Python\n",
      "17 http://www.facebook.com/pythonlang?fref=ts\n",
      "18 http://twitter.com/ThePSF\n",
      "19 /community/irc/\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds2_1_crawlLink.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readPythonOrg():\n",
    "    try:\n",
    "        r = requests.get(u'http://python.org/')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    soup=BeautifulSoup(r.content,\"lxml\")\n",
    "    my=soup.select(\"a\")\n",
    "    #ahref=soup.find_all('a', href=True)\n",
    "    print \"total number of links:\",len(my)\n",
    "    for counter,link in enumerate(soup.find_all('a', href=True)):\n",
    "        if(counter<20):\n",
    "            print counter,link.get('href')\n",
    "\n",
    "def main():\n",
    "    readPythonOrg()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 추가: regex\n",
    "\n",
    "문자열에 포함된 패턴으로 태그 또는 추출할 데이터를 인식할 수 있다.\n",
    "HTML 파서를 사용하여 태그를 추출하는 것에 비해 좀 어려울 수 있지만, 원하는 항목을 \n",
    "'http://' 패턴을 추출하므로 결과가 다를 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http url은 몇 개? 43\n",
      "0 http://www.ie6countdown.com/\n",
      "1 http://browsehappy.com/\n",
      "2 http://www.google.com/chromeframe/?redirect=true\n",
      "3 http://plus.google.com/+Python\n",
      "4 http://www.facebook.com/pythonlang?fref=ts\n",
      "5 http://twitter.com/ThePSF\n",
      "6 http://brochure.getpython.info/\n",
      "7 http://wiki.python.org/moin/Languages\n",
      "8 http://python.org/dev/peps/\n",
      "9 http://planetpython.org/\n",
      "10 http://pyfound.blogspot.com/\n",
      "11 http://pycon.blogspot.com/\n",
      "12 http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
      "13 http://blog.python.org\n",
      "14 http://feedproxy.google.com/~r/PythonInsider/~3/pUndlLcEcKE/python-337rc1-is-now-available-prior-to.html\n",
      "15 http://feedproxy.google.com/~r/PythonInsider/~3/pe2Ug4MA0Lg/python-2714-release-candidate-1.html\n",
      "16 http://feedproxy.google.com/~r/PythonInsider/~3/vY72b719CGk/python-354-and-python-347-are-now.html\n",
      "17 http://feedproxy.google.com/~r/PythonInsider/~3/ry7faTWPZiY/python-354rc1-and-python-347rc1-are-now.html\n",
      "18 http://feedproxy.google.com/~r/PythonInsider/~3/xgmAIcE1Wes/python-362-is-now-available.html\n",
      "19 http://www.djangoproject.com/\n",
      "20 http://www.pylonsproject.org/\n",
      "21 http://bottlepy.org\n",
      "22 http://tornadoweb.org\n",
      "23 http://flask.pocoo.org/\n",
      "24 http://www.web2py.com/\n",
      "25 http://wiki.python.org/moin/TkInter\n",
      "26 http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
      "27 http://www.wxpython.org/\n",
      "28 http://www.scipy.org\n",
      "29 http://pandas.pydata.org/\n",
      "30 http://ipython.org\n",
      "31 http://buildbot.net/\n",
      "32 http://trac.edgewall.org/\n",
      "33 http://roundup.sourceforge.net/\n",
      "34 http://www.ansible.com\n",
      "35 http://www.saltstack.com\n",
      "36 http://brochure.getpython.info/\n",
      "37 http://wiki.python.org/moin/Languages\n",
      "38 http://python.org/dev/peps/\n",
      "39 http://planetpython.org/\n",
      "40 http://pyfound.blogspot.com/\n",
      "41 http://pycon.blogspot.com/\n",
      "42 http://docs.python.org/devguide/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#p=re.compile('http://.+\"')\n",
    "p=re.compile('href=\"(http://.*?)\"')\n",
    "nodes=p.findall(_html)\n",
    "print \"http url은 몇 개?\",len(nodes)\n",
    "for i, node in enumerate(nodes):\n",
    "    print i, node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* regex를 사용해서 h1, p 태그 값을 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Defined\n",
      "Compound Data Types\n",
      "Intuitive Interpretation\n",
      "Quick &amp; Easy to Learn\n",
      "All the Flow You&rsquo;d Expect\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "p=re.compile('<h1>(.*?)</h1>')\n",
    "h1tags=p.findall(_html)\n",
    "for tag in h1tags:\n",
    "    print tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "p=re.compile('<p>(.*?)</p>')\n",
    "ptags=p.findall(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print len(ptags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<strong>Notice:</strong> While Javascript is not essential for this website, your interaction with the content will be limited. Please turn Javascript on for the full experience. \n"
     ]
    }
   ],
   "source": [
    "print ptags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 추가: xpath로 해보기\n",
    "\n",
    "* lxml.etree를 사용해 html을 파싱해서 자료 가져오기 (위에서 읽어온 html 변수를 사용)\n",
    "* xpath\n",
    "```\n",
    "$x('//*[@href]')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print type(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319299\n"
     ]
    }
   ],
   "source": [
    "print len(_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* lxml.etree.HTML()\n",
    "    * lxml.etree는 XML, HTML 모두 파싱할 수 있지만 사용하는 파서를 XMLParser(), HTMLParser()로 사전에 설정해야 오류가 발생하지 않는다.\n",
    "    * lxml.etree 대신 Python으로 만들어진 lxml.html을 사용하여 HTML을 처리할 수도 있다. \n",
    "\n",
    "문자를 읽는 함수 | 설명\n",
    "-----|-----\n",
    "etree.HTML() | html 문자열을 처리하는 경우 사용한다. 이러한 점에서 etree.fromstring()과 비슷하지만 HTMLParser()로 파싱을 하게 된다.\n",
    "etree.fromstring() | etree는 XML을 처리하는 객체. etree.fromstring()은 HTML 태그를 읽으면 오류를 발생하게 된다 (아래 참조).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "etree.fromstring()으로 HTML을 읽으면 오류가 발생한다.\n",
    "etree.HTML()으로 읽어야 한다. 읽고 결과를 tostring()으로 써본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "StartTag: invalid element name, line 1, column 2 (line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m StartTag: invalid element name, line 1, column 2\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "_htmlTree = etree.fromstring(_html)   # error for reading html from lxml.etree\n",
    "result = etree.tostring(_htmlTree, pretty_print=True, method=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "_htmlTree = etree.HTML(_html)\n",
    "result = etree.tostring(_htmlTree, pretty_print=True, method=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'href': '//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js', 'rel': 'prefetch'}\n",
      "1 {'href': '/static/stylesheets/style.css', 'type': 'text/css', 'rel': 'stylesheet', 'title': 'default'}\n",
      "2 {'media': 'not print, braille, embossed, speech, tty', 'href': '/static/stylesheets/mq.css', 'type': 'text/css', 'rel': 'stylesheet'}\n",
      "3 {'href': '/static/favicon.ico', 'type': 'image/x-icon', 'rel': 'icon'}\n",
      "4 {'href': '/static/apple-touch-icon-144x144-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '144x144'}\n",
      "5 {'href': '/static/apple-touch-icon-114x114-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '114x114'}\n",
      "6 {'href': '/static/apple-touch-icon-72x72-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '72x72'}\n",
      "7 {'href': '/static/apple-touch-icon-precomposed.png', 'rel': 'apple-touch-icon-precomposed'}\n",
      "8 {'href': '/static/apple-touch-icon-precomposed.png', 'rel': 'apple-touch-icon'}\n",
      "9 {'href': '/static/humans.txt', 'rel': 'author'}\n",
      "10 {'href': 'https://www.python.org/dev/peps/peps.rss/', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Enhancement Proposals'}\n",
      "11 {'href': 'https://www.python.org/jobs/feed/rss/', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Job Opportunities'}\n",
      "12 {'href': 'https://feeds.feedburner.com/PythonSoftwareFoundationNews', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Software Foundation News'}\n",
      "13 {'href': 'https://feeds.feedburner.com/PythonInsider', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Insider'}\n",
      "14 {'href': '#content', 'title': 'Skip to content'}\n",
      "15 {'href': '#python-network', 'aria-hidden': 'true', 'id': 'close-python-network', 'class': 'jump-link'}\n",
      "16 {'href': '/', 'class': 'current_item selectedcurrent_branch selected', 'title': 'The Python Programming Language'}\n",
      "17 {'href': '/psf-landing/', 'title': 'The Python Software Foundation'}\n",
      "18 {'href': 'https://docs.python.org', 'title': 'Python Documentation'}\n",
      "19 {'href': 'https://pypi.python.org/', 'title': 'Python Package Index'}\n"
     ]
    }
   ],
   "source": [
    "nodes=_htmlTree.xpath('//*[@href]')\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    if i<20:\n",
    "        print i, node.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 추가: css selector\n",
    "\n",
    "* css select\n",
    "```python\n",
    "$$('a[href]')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "\n",
    "html = lxml.html.fromstring(r.text)\n",
    "sel=CSSSelector('a[href]')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "0 #content Skip to content\n",
      "1 #python-network \n",
      "                    \n",
      "2 / Python\n",
      "3 /psf-landing/ PSF\n",
      "4 https://docs.python.org Docs\n",
      "5 https://pypi.python.org/ PyPI\n",
      "6 /jobs/ Jobs\n",
      "7 /community/ Community\n",
      "8 #top \n",
      "                    \n",
      "9 / None\n",
      "10 #site-map None\n",
      "11 # None\n",
      "12 javascript:; Smaller\n",
      "13 javascript:; Larger\n",
      "14 javascript:; Reset\n",
      "15 # Socialize\n",
      "16 http://plus.google.com/+Python None\n",
      "17 http://www.facebook.com/pythonlang?fref=ts None\n",
      "18 http://twitter.com/ThePSF None\n",
      "19 /community/irc/ None\n"
     ]
    }
   ],
   "source": [
    "print len(nodes)\n",
    "for i,node in enumerate(nodes):\n",
    "    #print lxml.html.tostring(item)\n",
    "    if i<20:\n",
    "        print i, node.get('href'), node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-3: 위키페이지에서 'python'을 검색해서 본문을 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "위키피디어 Wikipedia는 많은 사람들이 자발적으로 참여하여 만들어내는 지식, **집단지성**을 대표하는 사이트이다. 이 사이트에서 'Python'을 검색하여 다음을 출력해 보자.\n",
    "* Python 소개글\n",
    "* 그 페이지에서 포함하는 http 링크 목록\n",
    "\n",
    "### 해결\n",
    "\n",
    "* BeautifulSoup, lxml 라이브러리를 사용해 csss selector 첫째 문단과 링크 목록을 출력한다.\n",
    "* HTML 소스보기에서 어떤 태그를 가져올지 선정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 파싱\n",
    "\n",
    "위키에서 검색결과를 가져온다.\n",
    "BeautifulSoup으로 파싱을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(r.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### css selector: 문단 가져오기\n",
    "\n",
    "결과페이지에서 데이터 추출에 필요한 css selector를 정한다.\n",
    "HTML 소스를 열어서 가져오려는 태그의 css selector를 찾는다.\n",
    "```#mw-content-text```를 찾으면 아래 화면에서 보듯이 딱 하나를 특정할 수 있다.\n",
    "```#mw-content-text p```가 우리가 찾는 본문에 해당하는 css selector이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/3_pythonWiki.png \"python wiki css selector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "가져온 문단은 78개, 그 가운데 5개만 출력해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results=soup.select('#mw-content-text p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs:  76\n",
      "\n",
      "Python is an interpreted high-level programming language for general-purpose programming. Created by Guido van Rossum and first released in 1991, Python has a design philosophy that emphasizes code readability, notably using significant whitespace. It provides constructs that enable clear programming on both small and large scales.[27] In July 2018, Van Rossum stepped down as the leader in the language community after 30 years.[28][29]\n",
      "Python features a dynamic type system and automatic memory management. It supports multiple programming paradigms, including object-oriented, imperative, functional and procedural, and has a large and comprehensive standard library.[30]\n",
      "Python interpreters are available for many operating systems. CPython, the reference implementation of Python, is open source software[31] and has a community-based development model, as do nearly all of Python's other implementations. Python and CPython are managed by the non-profit Python Software Foundation.\n",
      "Python was conceived in the late 1980s[32] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC language (itself inspired by SETL)[33], capable of exception handling and interfacing with the Amoeba operating system.[7] Its implementation began in December 1989.[34] Van Rossum's long influence on Python is reflected in the title given to him by the Python community: Benevolent Dictator For Life (BDFL) –  a post from which he gave himself permanent vacation on July 12, 2018.[35]\n"
     ]
    }
   ],
   "source": [
    "print \"Number of paragraphs: \", len(results)\n",
    "for e in results[0:5]:\n",
    "    print e.get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### css selector: 다른 페이지로 가는 http 링크 가져오기\n",
    "\n",
    "* http 링크를 검색한다. css a[href^=\"http\"]를 사용한다. 즉 http로 시작하는 문자열 값을 가진 href를 의미한다.\n",
    "여기서 따옴표를 지키도록 한다. \"a[href^='http']\"는 틀린 문법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links=soup.select('a[href^=\"http\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    }
   ],
   "source": [
    "print len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 추가: 위키에서 lxml css.selector\n",
    "\n",
    "lxml.html.fromstring() 함수로 HTML을 파싱하고, cssselect()로 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "# build the DOM Tree\n",
    "tree = lxml.html.fromstring(r.text)\n",
    "# print the parsed DOM Tree\n",
    "#print lxml.html.tostring(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results=tree.cssselect('div #mw-content-text p') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Python features a <a href=\"/wiki/Dynamic_type\" class=\"mw-redirect\" title=\"Dynamic type\">dynamic type</a> system and automatic <a href=\"/wiki/Memory_management\" title=\"Memory management\">memory management</a>. It supports multiple <a href=\"/wiki/Programming_paradigm\" title=\"Programming paradigm\">programming paradigms</a>, including <a href=\"/wiki/Object-oriented_programming\" title=\"Object-oriented programming\">object-oriented</a>, <a href=\"/wiki/Imperative_programming\" title=\"Imperative programming\">imperative</a>, <a href=\"/wiki/Functional_programming\" title=\"Functional programming\">functional</a> and <a href=\"/wiki/Procedural_programming\" title=\"Procedural programming\">procedural</a>, and has a large and comprehensive <a href=\"/wiki/Standard_library\" title=\"Standard library\">standard library</a>.<sup id=\"cite_ref-About_30-0\" class=\"reference\"><a href=\"#cite_note-About-30\">[30]</a></sup>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "# print the HTML for the first result.\n",
    "match = results[2]\n",
    "print lxml.html.tostring(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python features a \n"
     ]
    }
   ],
   "source": [
    "# print the text of the first result.\n",
    "print match.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 파일 버전\n",
    "\n",
    "* 2018년 4월 81개의 문단을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load src/ds3_3_readWiki.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html\n",
    "#from lxml.cssselect import CSSSelector\n",
    "\n",
    "# build the DOM Tree\n",
    "# print the parsed DOM Tree\n",
    "#print lxml.html.tostring(tree)\n",
    "\n",
    "def readWikiLxml():\n",
    "    try:\n",
    "        r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    tree = lxml.html.fromstring(r.text)\n",
    "    results=tree.cssselect('div #mw-content-text p')\n",
    "    print \"Number of paragraphs: \", len(results)\n",
    "    for e in results:\n",
    "        print e.text\n",
    "\n",
    "def readWikiBS():\n",
    "    try:\n",
    "        r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    soup=BeautifulSoup(r.text,\"lxml\")\n",
    "    results=soup.select('div #mw-content-text p')\n",
    "    print \"Number of paragraphs: \", len(results)\n",
    "    for e in results:\n",
    "        print e.get_text().strip()\n",
    "    links=soup.select('a[href^=\"http\"]')\n",
    "    #links=soup.select(\"a[href^='http']\") -> not working\n",
    "    print \"total links: \",len(links)\n",
    "    for e in links:\n",
    "        print e\n",
    "\n",
    "def main():\n",
    "    #readWikiLxml()\n",
    "    readWikiBS()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-4: 한국 포털사이트에서 노래제목을 검색해서 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "노래는 개인의 선호가 있고 나름 '좋아하는 노래'가 있기 마련이다. 이런 노래를 골라주기 위해 '추천'이란 알고리즘이 사용되기도 한다. 이런 추천기술은 다음에 배우기로 하고, 이번에는 특정 단어가 쓰이는 노래를 검색해 보기로 한다. 포털 노래 사이트에서 '비 오는' 단어를 포함하는 노래를 검색하여 이를 수집하여 보자.\n",
    "주의! 이 예제는 교육을 목적으로 하는 실습이다. 상업용으로 사용할 경우는 저작권을 위반하지 않도록 주의하자.\n",
    "\n",
    "### 해결\n",
    "\n",
    "* 노래 검색 사이트 url을 정한다. 네이버음악 사이트 http://music.naver.com/ 를 사용한다.\n",
    "* 검색어를 정하고, 검색결과를 가져온다.\n",
    "* css selector를 정해서 검색결과로부터 데이터 항목을 추출한다. 각 노래에 대해 제목, 가수, 앨범, 인기도, 가사 항목이 게시판으로 구성되어 있다. 게시판은 pagination이라고 하는 기능이 있어 여러 페이지를 반복해서 가져와야 한다.\n",
    "\n",
    "> pagination은 검색결과가 여러 페이지일 경우 사용하는 기능이다. 검색결과가 150건 일 경우, 10개로 나누어 15페이지가 제공되는 예를 들 수 있다. '더보기', '목록번호', '맨 앞으로 이동', '맨 뒤로 이동' 등의 버튼이 제공되고 이를 사용해서 데이터를 조회할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 음악 검색결과 가져오기\n",
    "\n",
    "'네이버뮤직'에서 제공하는 검색기능을 사용해서 데이터를 가져온다.\n",
    "url은 http://music.naver.com/search/search.nhn, 여기에 검색어를 넣어준다.\n",
    "그 결과 15건의 노래가 검색된다.\n",
    "주소창에 나타나는 url을 참조해서 프로그램에 사용하자. 여기서는 urllib대신, requests를 사용해서 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "p = {\"query\": \"비오는\"}\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn\"\n",
    "r=requests.get(naverUrl,params=p)\n",
    "rainPage = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "rainPage의 전체길이는 140k 정도이다. 이 정도면 상당한 문자가 포함된 것이고 검색이 성공적이 었다고 말할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total length: 143687\n"
     ]
    }
   ],
   "source": [
    "print \"total length:\", len(rainPage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 문자열에서 검색\n",
    "\n",
    "* 검색결과 rainPage의 노래제목이 있는 위치를 알아 본다.\n",
    "* 문자열 찾기 기능 **find()**를 사용해본다.\n",
    "* 30653, 30670 사이 노래제목 1건을 출력하였다. 노래제목은 공백을 포함하여 7자이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30811 and 30818: 비오는 압구정\n"
     ]
    }
   ],
   "source": [
    "pos = rainPage.find(u\"트랙 리스트\")\n",
    "if (pos>0):\n",
    "    pos = rainPage.find(\"_title title NPI=\", pos);\n",
    "    pos = rainPage.find(\"title=\",pos+20)\n",
    "    pos2 = rainPage.find(\"\\\"\", pos+7)\n",
    "    print u\"found {0} and {1}: {2}\".format(pos+7, pos2, rainPage[pos+7:pos2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### css selector\n",
    "\n",
    "* 개발자도구를 열어서, HTML 소스를 펼친 후 노래목록이 출력된 부분의 css selector를 선정한다. 노래제목이 출력된 부분의 문자패턴을 집어낸다.\n",
    "* 웹브라우저 자바스크립트 창을 열어서 css selector를 살펴본다.\n",
    "* table '트랙 리스트'에 검색결과가 출력되어 있다.\n",
    "\n",
    "CSS selectors | 설명\n",
    "----------|----------\n",
    "#content | id가 content인 element를 선택\n",
    "#content > div:nth-child(4)' | 상위 #content의 4번째 div를 선택\n",
    "div._tracklist_mytrack | div아래 _tracklist_mytrack 클래스를 선택\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 이번에는 css selector를 정리하여 사용해 본다. 자바스크립트 창에서 테스트를 해보면서 정리하는 것이 쉽다.\n",
    "\n",
    "CSS selectors | 설명 | 의미\n",
    "----------|----------|----------\n",
    "._tracklist_move | 테이블 행을 선택 (table '트랙 리스트' tbody에 있는) | 'track' 목록\n",
    ".name > a.title | 클래스 .name에 있는 a link의 title을 선택 | 노래제목\n",
    ".artist | 클래스 .artist | 아티스트 (가수)\n",
    "-album | 클래스 .album | 앨범"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](figures/3_naverMusic.png \"python naver music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 페이지 파싱\n",
    "\n",
    "BeautifulSoup객체를 생성하여 DOM을 생성하자. lxml 파서를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(rainPage,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 제목 출력하기\n",
    "\n",
    "페이지에서 css selector를 넣어서 노래제목, 아티스트, 앨범 등을 가져온다.\n",
    "제목은 css selector를 알아내어 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비오는 압구정\n",
      "비 오는 거리\n",
      "비 오는 거리\n",
      "비오는 날 수채화\n",
      "비오는 압구정\n",
      "비오는 수요일\n",
      "비오는 금요일\n",
      "비오는 거리\n",
      "비오는 거리\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비 오는 밤이니까요\n",
      "비 오는 날\n",
      "비 오는 이런 날에\n",
      "비오는 날엔\n",
      "비오는 날엔 파전 (Feat. Wonny)\n"
     ]
    }
   ],
   "source": [
    "for title in soup.select('._tracklist_move > .name > a.title'):\n",
    "    print title.get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 제목을 저장하기\n",
    "\n",
    "* 'for문'은 **title.get_text()** 함수를 사용하여 제목을 추출하고, **append()** 함수로 리스트에 추가하고 있다.\n",
    "* 검색결과를 출력하면 '\\u'를 볼 수 있다. 이는 유니코드 문자를 의미하는 것이며 오류가 아니다. print문이 유니코드 출력을 지원하면 한글이 성공적으로 출력된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44\\uc624\\ub294 \\ub0a0 \\uc218\\ucc44\\ud654', u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44 \\uc624\\ub294 \\uc774\\ub7f0 \\ub0a0\\uc5d0', u'\\ube44\\uc624\\ub294 \\uae08\\uc694\\uc77c', u'\\ube44\\uc624\\ub294 \\uc555\\uad6c\\uc815', u'\\ube44\\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac  (Feat. \\ud56b\\ud3a0\\ud2b8)', u'\\ube44\\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44 \\uc624\\ub294 \\ub0a0', u'\\ube44\\uc624\\ub294 \\ub0a0\\uc5d4', u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac\\uc5d0\\uc11c', u'\\ube44\\uc624\\ub294 \\uc555\\uad6c\\uc815', u'\\ube44\\uc624\\ub294 \\ub0a0, \\uc0b0\\ucc45', u'\\ube44 \\uc624\\ub294 \\ub0a0']\n"
     ]
    }
   ],
   "source": [
    "_selName=list()\n",
    "for title in soup.select('._tracklist_move > .name > a.title'):\n",
    "    _selName.append(title.get_text().strip())\n",
    "print _selName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "위 'for문'에서 제목을 추출해서 리스트로 만드는 3줄을 1줄로 단축할 수 있다. Python의 특징을 잘 보여주고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 제목, 아티스트, 앨범제목을 저장하기\n",
    "\n",
    "제목, 아티스트, 앨범제목의 css selector를 찾아서 넣어주자.\n",
    "\n",
    "구분 | css selector\n",
    "-----|-----\n",
    "제목 | '._tracklist_move > .name > a.title'\n",
    "아티스트 | '._artist.artist'\n",
    "앨범 | '.album > a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 15\n",
      "{ARTIST} --- 비 오는 거리 --- 앨범\n",
      "이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n"
     ]
    }
   ],
   "source": [
    "_selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "_selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "_selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "print \"total number of items:\",len(_selName) \n",
    "for i in range(len(_selName)):\n",
    "    print _selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 여러 페이지 가져오기\n",
    "\n",
    "목록에서 '곡 더보기'를 찾아서 버튼을 눌러 본다. 주소창의 url과 params이 어떻게 변경되었는지 주의한다.\n",
    "url의 params에 페이지번호가 첨부되어 다음 페이지를 요청하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "r = requests.get(naverUrl,params=p)\n",
    "soup=BeautifulSoup(r.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 50\n",
      "{ARTIST} --- 비오는 압구정 --- 앨범\n",
      "윤건 --- 비 오는 거리 --- 비오는 압구정\n",
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "소울스타 (SoulstaR) --- 비오는 날 수채화 --- 비 오는 거리\n",
      "강인원 --- 비오는 압구정 --- 비오는 날 수채화 1 OST\n",
      "브라운 아이즈 --- 비오는 수요일 --- 2집 Reason 4 Breathing?\n",
      "한승희 --- 비오는 금요일 --- 이야기 Part 3 - 비오는 수요일\n",
      "비오는 금요일 --- 비오는 거리 --- 비오는 금요일\n",
      "유리상자 --- 비오는 거리 --- 유ㄹish.1 - 비오는 거리\n",
      "서영은 --- 비 오는 거리  (Feat. 핫펠트) --- 1집 Romantic 1\n",
      "베이빌론(Babylon) --- 비 오는 밤이니까요 --- BETWEEN US\n",
      "nokdu(녹두) --- 비 오는 날 --- 비 오는 밤이니까요\n",
      "오소연 --- 비 오는 이런 날에 --- 비 오는 날\n",
      "은가은 --- 비오는 날엔 --- 비 오는 이런 날에\n",
      "소심한 오빠들 --- 비오는 날엔 파전 (Feat. Wonny) --- 비오는 날엔\n",
      "비트코인(BEATCOIN) --- 비오는 압구정 --- 비오는 날엔 파전\n",
      "브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes 'Take A Favorite'\n",
      "모모캣츠(Momocats) --- 비 오는 날의 수채화 --- 비오는 날, 산책\n",
      "가을로 가는 기차 --- 비 오는 거리 너와 나 --- 비 오는 날의 수채화\n",
      "강민경 --- 비오는 카페에서 --- Suits OST Part 4\n",
      "Book Café --- 비오는 밤 --- Rainy Cafe\n",
      "샤플라 --- 비오는 날 --- ShaFLA NO.1\n",
      "루싸이트 토끼 --- Rainy Day (비오는 날) --- 1집 Twinkle Twinkle\n",
      "김광민 --- 비오는 꿈 (Rainy Dream) --- 1집 Letter From The Earth\n",
      "잠비(Zambi) --- 비오는 압구정 (라이브) --- 장마 (Rainy Season)\n",
      "윤건 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- 비긴어게인2 윤건 스페셜 에디션\n",
      "럼블 피쉬 --- 비오는 압구정 --- Memory For You\n",
      "서영은 --- 비오는 날 --- Unforgettable No.2\n",
      "오소연 --- 비 오는 날의 수채화 --- 나쁜아이\n",
      "SG 워너비 --- 비 오는 날 --- Classic Odyssey\n",
      "김봄 --- 비 오는 거리 --- 비 오는 날\n",
      "서영은 --- 비 오는 거리에서 --- 서영은 리메이크 베스트 모음집\n",
      "이승철 --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- 12집 시간 참 빠르다\n",
      "노블레스 --- 비오는 날의 수채화 --- 7집 Growing Pains\n",
      "박정현 --- 비오는 아침 --- 서바이벌 나는 가수다 경연 1 '80년대 명곡 부르기\n",
      "재주소년 --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- 1집 재주소년 (才洲少年)\n",
      "Flower Singers --- 비 오는 거리 --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "SG 워너비 --- 비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가) --- Classic Odyssey\n",
      "백색소음 --- 비오는날 --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "꼬모팝 --- 비 오는 날 카페에 앉아 --- 율동동요 꼬모팝 4집\n",
      "디오티마 --- 비 오는 숲 소리 (백색소음 화이트 노이즈 자장가) --- 비 오는 날 카페에 앉아\n",
      "백색소음 --- 비오는 소리 (백색소음,ASMR) --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "백색소음(ASMR) --- 비오는 날 --- 백색소음 모음(ASMR,자장가,화이트노이즈,집중력,힐링,수면,명상)\n",
      "거북이 --- 비 오는 계곡 물소리 자장가 (힐링 백색소음 화이트노이즈) --- 1집 Go! Boogie!\n",
      "빗소리 --- 비 오는 날 풀벌레 소리 (백색소음 화이트 노이즈 자장가) --- 빗소리 (힐링,마음이 답답할 때 듣기 좋은 수면 명상 자장가,백색소음,집중력 높이는 법,화이트노이즈)\n",
      "백색소음 --- 비 오는 거리에서 --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "Mr. 페페 --- 비오는 날의 수채화 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "권인하 --- 비 오는 숲소리 자장가 (힐링 백색소음 화이트노이즈) --- 첫사랑\n",
      "빗소리 --- 비오는 날 --- 빗소리 (힐링,마음이 답답할 때 듣기 좋은 수면 명상 자장가,백색소음,집중력 높이는 법,화이트노이즈)\n",
      "오은영 --- 비 오는 밤 풀벌레 소리 자장가 (힐링 백색소음 화이트노이즈) --- 비오는 날\n"
     ]
    }
   ],
   "source": [
    "_selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "_selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "_selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "print \"total number of items:\",len(_selName) \n",
    "for i in range(len(_selName)):\n",
    "    print _selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 연속으로 실행해서 여러 페이지 가져오기\n",
    "    * params에 track, pageNo를 추가하기\n",
    "    https://www.url-encode-decode.com/에서 encode, decode기능을 제공\n",
    "    * naver의 url을 관찰하면 p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "    '%27%eb%b9%84%ec%98%a4%eb%8a%94%27'는 '비오는'이라는 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "urllib.urlencode({'query':u'비오는'.encode('utf-8')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 50\n",
      "0 --- {ARTIST} --- 비 오는 거리 --- 앨범\n",
      "0 --- 이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "0 --- 강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "0 --- 소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "0 --- 은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "0 --- 비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "0 --- 브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "0 --- 유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "0 --- 베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "0 --- 서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "0 --- 오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "0 --- 소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "0 --- 아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "0 --- 브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "0 --- 모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n",
      "0 --- 김봄 --- 비오는 아침 --- 비 오는 날\n",
      "0 --- 재주소년 --- 비오는 압구정 --- 1집 재주소년 (才洲少年)\n",
      "0 --- 서영은 --- 비오는 날 --- Unforgettable No.2\n",
      "0 --- 루싸이트 토끼 --- 비 오는 거리에서 --- 1집 Twinkle Twinkle\n",
      "0 --- 이승철 --- 비오는 날엔 파전 (Feat. Wonny) --- 시간 참 빠르다\n",
      "0 --- 비트코인(BEATCOIN) --- 비오는 날 --- 비오는 날엔 파전\n",
      "0 --- 오은영 --- 비오는 날은 푸르다 --- 비오는 날\n",
      "0 --- 하이니(Hi.ni) --- 비 오는 날의 수채화 --- 비오는 날은 푸르다\n",
      "0 --- SG 워너비 --- 비오는 거리 --- Classic Odyssey\n",
      "0 --- 이금성 --- 비 오는 거리 --- 비오는 거리\n",
      "0 --- SG 워너비 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Classic Odyssey\n",
      "0 --- 럼블 피쉬 --- 비오는 날엔 막걸리 (Feat. 신승열) --- Memory For You\n",
      "0 --- 레미 --- 비오는 이른 새벽 자장가 --- 비오는 날엔 막걸리\n",
      "0 --- 롤러코스터 --- 비 오는 경리단길 (Feat. 양은선) --- 1집 내게로 와\n",
      "0 --- 로만티코(Romantico) --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Diminished Part 1\n",
      "0 --- Flower Singers --- 비오는 밤 --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "0 --- 도나웨일(Donawhale) --- 비오는 날의 수채화 --- 1집 Donawhale\n",
      "0 --- 박정현 --- 비오는 밤 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "0 --- 서효린 --- 비오는 밤 --- 가을동화\n",
      "0 --- 최설아 --- Rainy Day (비오는 날) --- 비오는 밤\n",
      "0 --- 김광민 --- 비 오는 밤 --- 1집 Letter From The Earth\n",
      "0 --- 어프로그레시브 피아노 --- 드뷔시 - 비 오는 정원 --- One Day\n",
      "0 --- Various Artists --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- Rain Piano : 비오는 날, 듣기 좋은 피아노\n",
      "0 --- 노블레스 --- 자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기... --- 7집 Growing Pains\n",
      "0 --- 자장가 --- 비오는 날의 수채화 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "0 --- 권인하 --- 비 오는 날 --- 첫사랑\n",
      "0 --- 민티 --- 비오는 골목 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "0 --- 김윤아 --- 비오는 일요일 --- 비오는 골목\n",
      "0 --- 온음 --- 자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가) --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "0 --- 자장가 --- 비 오는 날 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "0 --- 명상피아노 --- 비 오는 날 카페에 앉아 --- 비 오는 날\n",
      "0 --- 디오티마 --- 비오는 거리 (빗속에서) --- 비 오는 날 카페에 앉아\n",
      "0 --- 레드 페이스(Red Face) --- 자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가) --- 喜入合 (희입합)\n",
      "0 --- 자장가 --- 자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "0 --- 자장가 --- 비 오는 거리에서 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "total number of items: 50\n",
      "1 --- {ARTIST} --- 비 오는 거리 --- 앨범\n",
      "1 --- 이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "1 --- 강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "1 --- 소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "1 --- 은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "1 --- 비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "1 --- 브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "1 --- 유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "1 --- 베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "1 --- 서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "1 --- 오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "1 --- 소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "1 --- 아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "1 --- 브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "1 --- 모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n",
      "1 --- 김봄 --- 비오는 아침 --- 비 오는 날\n",
      "1 --- 재주소년 --- 비오는 압구정 --- 1집 재주소년 (才洲少年)\n",
      "1 --- 서영은 --- 비오는 날 --- Unforgettable No.2\n",
      "1 --- 루싸이트 토끼 --- 비 오는 거리에서 --- 1집 Twinkle Twinkle\n",
      "1 --- 이승철 --- 비오는 날엔 파전 (Feat. Wonny) --- 시간 참 빠르다\n",
      "1 --- 비트코인(BEATCOIN) --- 비오는 날 --- 비오는 날엔 파전\n",
      "1 --- 오은영 --- 비오는 날은 푸르다 --- 비오는 날\n",
      "1 --- 하이니(Hi.ni) --- 비 오는 날의 수채화 --- 비오는 날은 푸르다\n",
      "1 --- SG 워너비 --- 비오는 거리 --- Classic Odyssey\n",
      "1 --- 이금성 --- 비 오는 거리 --- 비오는 거리\n",
      "1 --- SG 워너비 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Classic Odyssey\n",
      "1 --- 럼블 피쉬 --- 비오는 날엔 막걸리 (Feat. 신승열) --- Memory For You\n",
      "1 --- 레미 --- 비오는 이른 새벽 자장가 --- 비오는 날엔 막걸리\n",
      "1 --- 롤러코스터 --- 비 오는 경리단길 (Feat. 양은선) --- 1집 내게로 와\n",
      "1 --- 로만티코(Romantico) --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Diminished Part 1\n",
      "1 --- Flower Singers --- 비오는 밤 --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "1 --- 도나웨일(Donawhale) --- 비오는 날의 수채화 --- 1집 Donawhale\n",
      "1 --- 박정현 --- 비오는 밤 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "1 --- 서효린 --- 비오는 밤 --- 가을동화\n",
      "1 --- 최설아 --- Rainy Day (비오는 날) --- 비오는 밤\n",
      "1 --- 김광민 --- 비 오는 밤 --- 1집 Letter From The Earth\n",
      "1 --- 어프로그레시브 피아노 --- 드뷔시 - 비 오는 정원 --- One Day\n",
      "1 --- Various Artists --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- Rain Piano : 비오는 날, 듣기 좋은 피아노\n",
      "1 --- 노블레스 --- 자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기... --- 7집 Growing Pains\n",
      "1 --- 자장가 --- 비오는 날의 수채화 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "1 --- 권인하 --- 비 오는 날 --- 첫사랑\n",
      "1 --- 민티 --- 비오는 골목 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "1 --- 김윤아 --- 비오는 일요일 --- 비오는 골목\n",
      "1 --- 온음 --- 자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가) --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "1 --- 자장가 --- 비 오는 날 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "1 --- 명상피아노 --- 비 오는 날 카페에 앉아 --- 비 오는 날\n",
      "1 --- 디오티마 --- 비오는 거리 (빗속에서) --- 비 오는 날 카페에 앉아\n",
      "1 --- 레드 페이스(Red Face) --- 자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가) --- 喜入合 (희입합)\n",
      "1 --- 자장가 --- 자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "1 --- 자장가 --- 비 오는 거리에서 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "for pageNo in range(2):\n",
    "    p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "    r = requests.get(naverUrl,params=p)\n",
    "    soup=BeautifulSoup(r.text,\"lxml\")\n",
    "    _selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "    _selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "    _selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "    print \"total number of items:\",len(_selName) \n",
    "    for i in range(len(_selName)):\n",
    "        print pageNo,'---',_selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 추가: lxml로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = lxml.html.fromstring(r.text)\n",
    "nodes=html.cssselect('._tracklist_move > .name > a.title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비오는 날 수채화\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 금요일\n",
      "비오는 압구정\n",
      "비오는 거리\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 거리\n",
      "비 오는 날\n",
      "비오는 날엔\n",
      "비 오는 거리에서\n",
      "비오는 압구정\n",
      "비오는 날, 산책\n",
      "비 오는 날\n"
     ]
    }
   ],
   "source": [
    "for e in nodes:\n",
    "    print e.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import requests\n",
    "\n",
    "#p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\"}\n",
    "r = requests.get(naverUrl,params=p)\n",
    "_html = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* html을 보려면\n",
    "    * r.text로 보거나\n",
    "    * lxml.html.tostring(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lxml.html.tostring(_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes=_html.cssselect('._tracklist_move > .name > a.title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* item.text()는 한글 문자 출력 오류\n",
    "* item.text_content()를 사용해서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 압구정\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 날 수채화\n",
      "비오는 거리\n",
      "비오는 거리\n",
      "비오는 압구정\n",
      "비 오는 날\n",
      "비오는 아침\n",
      "비오는 날엔\n",
      "비오는 날\n",
      "비 오는 거리에서\n",
      "비 오는 거리에서\n",
      "비오는 날, 산책\n",
      "비 오는 날\n",
      "비 오는 경리단길 (Feat. 양은선)\n",
      "비오는 압구정\n",
      "비오는 날\n",
      "7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기)\n",
      "비오는날의 수채화 (Feat. 정혜민, Misty)\n",
      "비오는 밤\n",
      "비오는 날의 수채화\n",
      "비 오는 날의 수채화\n",
      "비 오는 거리\n",
      "비오는 날은 푸르다\n",
      "비오는 이른 새벽 자장가\n",
      "Rainy Day (비오는 날)\n",
      "비오는 금요일\n",
      "I'd Love You To Want Me (CF '코업레지던스', 영화...\n",
      "Rhythm Of The Rain (빗줄기의 리듬 : CF 'LG 정유...\n",
      "자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가)\n",
      "자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기...\n",
      "비오는 거리\n",
      "비오는 날엔 (Feat. 어쿠스틱 콜라보)\n",
      "Rain (호세 펠라치아노의 대표곡 : 레인)\n",
      "House Of The Rising Sun (해뜨는 집, 드라마 '올인' OST)\n",
      "California Dreamin' (캘리포니아 드림 - 영화...\n",
      "비 오는 밤\n",
      "자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가)\n",
      "비오는 일요일\n",
      "자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가)\n",
      "비오는 날엔\n",
      "비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가)\n",
      "자장가 (비오는 소리와 함께하는 모차르트 아기 자장가)\n",
      "비오는 날의 수채화\n",
      "비오는 날엔 막걸리 (Feat. 신승열)\n",
      "Evergreen\n",
      "자장가 (비오는 소리와 함께하는 위안 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    print node.text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 곡명, 아티스트, 앨범 모두 가져오기\n",
    "    * html이 정형적이지 않아서 어렵다.\n",
    "    * 2단계 작업.\n",
    "        * 곡명, 아티스트, 앨범 항목을 가지고 있는 상위 태그를 먼저 선정하고, 그 안의 개별 항목을 선정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr class=\"_tracklist_move {TRACK_TYPE}\" style=\"display:none;\" trackdata=\"{TRACK_DATA}\">\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"chk\"><input type=\"checkbox\" title=\"&#49440;&#53469;\" class=\"_chkbox_item input_chk {TRACK_CHECK_NCLICKS}\"> </td>\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"order\">{TRACK_NUM}</td>\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"name\">\r\n",
      "\r\n",
      "\t\t\t\t\t\t\t\t{PLAY_TOGGLE}\r\n",
      "\t\t\t\t\t\t\t\t{ADD_TOGGLE}\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\t\t\t\t\t<span class=\"_ico_title ico_title\"><img height=\"18\" width=\"23\" alt=\"TITLE\" src=\"http://static.naver.net/nmusic/201\n"
     ]
    }
   ],
   "source": [
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "sel = CSSSelector('._tracklist_move')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)\n",
    "print lxml.html.tostring(nodes[0])[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 개별 항목의 선정\n",
    "* 우선 1개씩 해 본다.\n",
    "    * results[0]은 제목행이므로, 그 다음을 처리한다.\n",
    "    * 태그가 정형적이지 않으므로, selector가 일정하지 않다는 점에 주의한다.\n",
    "        * Chrome console창을 이용해서 하나씩 작업하므로, selector를 정의하는데 노력이 수반된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "_name=_selName(nodes[1])\n",
    "_artist=_selArtist(nodes[1])\n",
    "_album=_selAlbum(nodes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "이승훈\n",
      "1집 비오는 거리\n"
     ]
    }
   ],
   "source": [
    "print _name[0].text_content()\n",
    "print _artist[0].text_content().strip()\n",
    "print _album[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 반복문을 이용하여 모든 노래를 출력한다.\n",
    "    * if문은 노래제목이 없는 경우 제거한다 (제목 행을 제거하는 효과)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "강인원 --- 비오는 날 수채화 --- 비오는 날 수채화 1 OST\n",
      "오소연 --- 비 오는 날 --- 비 오는 날\n",
      "동요시대 --- 비오는날 (동요) (멜로디 MR) --- 동요 MR반주 5\n",
      "서영은 --- 비오는 거리 --- 1집 Romantic 1\n",
      "루드 페이퍼(Rude Paper) --- 비오는 밤에 --- 1집 Paper Spectrum\n",
      "김민우 --- 비오는 날 (Inst.) --- 비오는 날\n",
      "조영순 --- 비오는 남산 --- 무진장 트롯트 골든 1＆2\n",
      "베이빌론(Babylon) --- 비 오는 거리  (Feat. 핫펠트) --- BETWEEN US\n",
      "브라운 아이즈 --- 비오는 압구정 --- 2집 Reason 4 Breathing?\n",
      "하이니(Hi.ni) --- 비오는 날은 푸르다 --- 비오는 날은 푸르다\n",
      "Richard Marx --- One More Time --- 김현주의 비오는 거리\n",
      "SG 워너비 --- 비 오는 날의 수채화 --- Classic Odyssey\n",
      "Romantisch Jazzkapelle --- Yesterday (비틀즈 예스터 데이 : CF `시몬스침대`) --- 뉴에이지 연가 : 비 오는 날의 거리, 추억, 그리고 아름다운 재즈 피아노(Pop 올드 팝, 클래식, 영화 OST 베스트 연주 음악)\n",
      "강윤식 --- 비오는날 수채화 (발라드 Ver.) (With 김명상, 강윤식) --- 1980-2010 리뉴얼 - 내 노래 다시 부르기\n"
     ]
    }
   ],
   "source": [
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    _name=_selName(node)\n",
    "    _artist=_selArtist(node)\n",
    "    _album=_selAlbum(node)\n",
    "    if _name:\n",
    "        print _artist[0].text_content().strip(),\n",
    "        print \"---\",\n",
    "        print _name[0].text_content(),\n",
    "        print \"---\",\n",
    "        print _album[0].text_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "강인원 --- 비오는 날 수채화 --- 비오는 날 수채화 1 OST\n",
      "소울스타 (SoulstaR) --- 비 오는 거리 --- 비 오는 거리\n",
      "브라운 아이즈 --- 비오는 압구정 --- 2집 Reason 4 Breathing?\n",
      "은가은 --- 비 오는 이런 날에 --- 비 오는 이런 날에\n",
      "비트코인(BEATCOIN) --- 비오는 날엔 파전 (Feat. Wonny) --- 비오는 날엔 파전\n",
      "유리상자 --- 비오는 거리 --- 유ㄹish.1 - 비오는 거리\n",
      "서영은 --- 비오는 거리 --- 1집 Romantic 1\n",
      "오소연 --- 비 오는 날 --- 비 오는 날\n",
      "베이빌론(Babylon) --- 비 오는 거리  (Feat. 핫펠트) --- BETWEEN US\n",
      "소심한 오빠들 --- 비오는 날엔 --- 비오는 날엔\n",
      "비오는 금요일 --- 비오는 금요일 --- 비오는 금요일\n",
      "아스트로피아노 --- 비 오는 거리에서 --- 비 오는 거리에서\n",
      "브라운 아이즈 --- 비오는 압구정 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "김광민 --- Rainy Day (비오는 날) --- 1집 Letter From The Earth\n",
      "김봄 --- 비 오는 날 --- 비 오는 날\n",
      "오은영 --- 비오는 날 --- 비오는 날\n",
      "모모캣츠(Momocats) --- 비오는 날, 산책 --- 비오는 날, 산책\n",
      "럼블 피쉬 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Memory For You\n",
      "하이니(Hi.ni) --- 비오는 날은 푸르다 --- 비오는 날은 푸르다\n",
      "재주소년 --- 비오는 아침 --- 1집 재주소년 (才洲少年)\n",
      "루싸이트 토끼 --- 비오는 날 --- 1집 Twinkle Twinkle\n",
      "이승철 --- 비 오는 거리에서 --- 시간 참 빠르다\n",
      "이금성 --- 비오는 거리 --- 비오는 거리\n",
      "SG 워너비 --- 비 오는 날의 수채화 --- Classic Odyssey\n",
      "포레스트 엘(Forest L) --- 비 오는 날 (Rainy Day) --- 비 오는 날 (Rainy Day)\n",
      "김윤아 --- 비오는 골목 --- 비오는 골목\n",
      "디오티마 --- 비 오는 날 카페에 앉아 --- 비 오는 날 카페에 앉아\n",
      "노블레스 --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- 7집 Growing Pains\n",
      "SG 워너비 --- 비 오는 거리 --- Classic Odyssey\n",
      "서영은 --- 비오는 압구정 --- Unforgettable No.2\n",
      "Flower Singers --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "서효린 --- 비오는 밤 --- 가을동화\n",
      "백색소음 --- 비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가) --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "박정현 --- 비오는 날의 수채화 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "백색소음 --- 비 오는 숲 소리 (백색소음 화이트 노이즈 자장가) --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "민티 --- 비 오는 날 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "Mr. 페페 --- 비 오는 거리에서 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "모니카(Monica) --- 비 오는 창가에서 --- 명상음악 아이를 위한 태교 Part 8\n",
      "어프로그레시브 피아노 --- 비 오는 밤 --- One Day\n",
      "권언정 --- 비오는 날마다 (Piano 조은진) --- 비오는 날마다\n",
      "롤러코스터 --- 비오는 이른 새벽 자장가 --- 1집 내게로 와\n",
      "거북이 --- 비오는 날 --- 1집 Go! Boogie!\n",
      "서영은 --- 비 오는 거리 --- 서영은 리메이크 베스트 모음집\n",
      "로만티코(Romantico) --- 비 오는 경리단길 (Feat. 양은선) --- Diminished Part 1\n",
      "레드 페이스(Red Face) --- 비오는 거리 (빗속에서) --- 喜入合 (희입합)\n",
      "권인하 --- 비오는 날의 수채화 --- 첫사랑\n",
      "도나웨일(Donawhale) --- 비오는 밤 --- 1집 Donawhale\n",
      "줄라이(July) --- 비오는 날 (Piano ver.) --- Ending Song (Digital Single)\n",
      "남예지 --- 비오는 저녁 --- 2집 Terra Incognita\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import lxml.html\n",
    "import requests\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\"}\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "r = requests.get(naverUrl,params=p)\n",
    "_html = lxml.html.fromstring(r.text)\n",
    "\n",
    "sel = CSSSelector('table[summary] > tbody > ._tracklist_move')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)\n",
    "\n",
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    _name=_selName(node)\n",
    "    _artist=_selArtist(node)\n",
    "    _album=_selAlbum(node)\n",
    "    if _name:\n",
    "        print _artist[0].text_content().strip(),\n",
    "        print \"---\",\n",
    "        print _name[0].text_content(),\n",
    "        print \"---\",\n",
    "        print _album[0].text_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load src/ds3_4_naverMusic.py\n",
    "#!\n",
    "import lxml.html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#keyword='비오는'\n",
    "#p = {'query': '비오는', '&x': 0, '&y':0}\n",
    "pageNo=1\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "#r = requests.get(\"http://music.naver.com/search/search.nhn?query=\"+keyword+\"&x=0&y=0\")\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "def readMusicLxml():\n",
    "    try:\n",
    "        r = requests.get(naverUrl,params=p)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    _html = lxml.html.fromstring(r.text)\n",
    "    #sel = CSSSelector('table[summary] > tbody > ._tracklist_move')\n",
    "    sel = CSSSelector('._tracklist_move')\n",
    "    # Apply the selector to the DOM tree.\n",
    "    nodes = sel(_html)\n",
    "    _selName = CSSSelector('.name > a.title')\n",
    "    _selArtist = CSSSelector('._artist.artist')\n",
    "    _selAlbum= CSSSelector('.album > a')\n",
    "    for node in nodes:\n",
    "        #print lxml.html.tostring(item)\n",
    "        _name=_selName(node)\n",
    "        _artist=_selArtist(node)\n",
    "        _album=_selAlbum(node)\n",
    "        if _name:\n",
    "            print _artist[0].text_content().strip(),\n",
    "            print \"---\",\n",
    "            print _name[0].text_content(),\n",
    "            print \"---\",\n",
    "            print _album[0].text_content()\n",
    "\n",
    "def readMusicBS():\n",
    "    try:\n",
    "        #pageNo=1\n",
    "        for pageNo in range(10):\n",
    "            p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "            r = requests.get(naverUrl,params=p)\n",
    "            #if r.text is not '':\n",
    "            soup=BeautifulSoup(r.text,\"lxml\")\n",
    "            _selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "            _selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "            _selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "            print \"total number of items:\",len(_selName)\n",
    "            for i in range(len(_selName)):\n",
    "                print pageNo,'---',_selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n",
    "            #pageNo+=1\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "\n",
    "def main():\n",
    "    readMusicLxml()\n",
    "    readMusicBS() #bug - print header and no last line \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds3_4_naverMusic.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* 노래목록을 보면 가사를 조회할 수 있도록 되어 있다. '가사' 아이콘을 클릭하면 새로운 팝업 창을 뛰우고 해당 노래의 가사를 띄우고 있다. 이 가사를 가져와 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-5 : 국제학회 목록을 가져오기\n",
    "\n",
    "매년 많은 국제학회가 개최되고 있는데, 그 목록을 웹에서 찾을 수 있다.\n",
    "국제학회의 명칭, 일시, 장소, 주제 등을 가져와 보자.\n",
    "IEEE 페이지는 매년 갱신이 되고 있다.\n",
    "처음에는 정적페이지로 구축되어서 스크레이핑이 잘 되었으나, 매년 페이지가 갱신되고 있고 2018년 4월 현재 **Selenium을 사용해야** 한다.\n",
    "내년에는 현재 작성된 프로그램이 그대로 실행될지 의문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### IEEE 학회 url 찾기\n",
    "\n",
    "해당 페이지로 가면 url이 상당히 복잡하다.\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "q | 검색창 조회어\n",
    "date | 일자\n",
    "from | 시작 일자\n",
    "to | 마지막 일자\n",
    "pos | 페이지 번호\n",
    "\n",
    "* 원래 주소창에 뜨는 url\n",
    "```python\n",
    "https://conferences.ieee.org/conferences_events/conferences/search?q=*&subsequent_q=&date=all&from=2018-01-01&to=2018-12-31&region=all&country=all&pos=0&sortorder=asc&sponsor=&sponsor_type=all&state=all&field_of_interest=all&sortfield=dates\n",
    "```\n",
    "\n",
    "* 위를 정리한 후 우리 프로그램에서 사용할 url (페이지 번호 pos를 임의로 3으로 했슴)\n",
    "```python\n",
    "https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31&pos=3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### url에서 데이터 가져오기\n",
    "\n",
    "Selenium을 사용해서 데이터를 가져오고 있다.\n",
    "동적페이지라서 requests로 가져오면 학회목록을 가져올 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "ieeeUrl='https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31&pos=3'\n",
    "driver.get(ieeeUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### css selector 찾기\n",
    "\n",
    "* 크롬 브라우저 > 보기 > 개발자 정보 > javascript console\n",
    "    * Elements 창에서 검색을 하면 원하는 문자열을 찾을 수 있다.\n",
    "    * css로 태그를 찾아 본다.\n",
    "\n",
    "```python\n",
    "'div.conference-item'\n",
    "```\n",
    "\n",
    "아래는 일단 class name인 ```.conference-item```으로 찾아본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=driver.find_elements_by_class_name('conference-item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "text로 태그의 텍스트를 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "•••\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "•••\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "•••\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "•••\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "•••\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "•••\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "•••\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "•••\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "•••\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "•••\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n"
     ]
    }
   ],
   "source": [
    "for e in res:\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이번에는 css selector, `div.conference-item`를 사용해서 가져와 보자.\n",
    "소스보기를 하면, 학회 내용을 가져올 수 있는 css 클래스를 확인할 수 있다.\n",
    "\n",
    "학회 내용을 가져오는 css 클래스 명 | 설명\n",
    "-----|-----\n",
    "item-title | 제목\n",
    "item-date | 일시, 장소\n",
    "item-details | 상세\n",
    "item-about | 주제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=driver.find_elements_by_css_selector('div.conference-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "-----\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "-----\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "-----\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "-----\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "-----\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "-----\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "-----\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "-----\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "-----\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for e in res:\n",
    "    print e.find_element_by_class_name('item-title').text\n",
    "    print e.find_element_by_class_name('item-date').text\n",
    "    print e.find_element_by_class_name('item-details').text\n",
    "    print e.find_element_by_class_name('item-about').text\n",
    "    print \"-----\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이제 여러 페이지를 가져와 보자. 뒤에 페이지 번호를 첨부하면 된다. '&pos='+str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&page=0\n",
      "&page=1\n",
      "&page=2\n",
      "&page=3\n",
      "&page=4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print \"&page=\"+str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "단 주의! driver.implicitly_wait(10) 로 일정 시간 기다리는 명령문을 넣지 않으면 데이터를 모두 가져오지 못할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- pos  0 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n",
      "--- pos  1 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print '--- pos ',i,'---'\n",
    "    ieeeUrl='https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31&pos='+str(i)\n",
    "    driver.get(ieeeUrl)\n",
    "    driver.implicitly_wait(10)\n",
    "    res=driver.find_elements_by_css_selector('div.conference-item')\n",
    "    for e in res:\n",
    "        print e.find_element_by_class_name('item-title').text\n",
    "        print e.find_element_by_class_name('item-date').text\n",
    "        print e.find_element_by_class_name('item-details').text\n",
    "        print e.find_element_by_class_name('item-about').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```\n",
    "\n",
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds_web_crawl_ieee.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ds3_5_readIEEE.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_5_readIEEE.py\n",
    "#!\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readIEEE():\n",
    "    driver = webdriver.PhantomJS()\n",
    "    for i in range(5):\n",
    "        print '--- pos ',i,'---'\n",
    "        ieeeUrl='https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31https://conferences.ieee.org/conferences_events/conferences/search?q=*&date=all&from=2018-01-01&to=2018-12-31&pos='+str(i)\n",
    "        driver.get(ieeeUrl)\n",
    "        driver.implicitly_wait(10)\n",
    "        res=driver.find_elements_by_css_selector('div.conference-item')\n",
    "        for e in res:\n",
    "            print e.find_element_by_class_name('item-title').text\n",
    "            print e.find_element_by_class_name('item-date').text\n",
    "            print e.find_element_by_class_name('item-details').text\n",
    "            print e.find_element_by_class_name('item-about').text\n",
    "\n",
    "def main():\n",
    "    readIEEE()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- pos  0 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n",
      "--- pos  1 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n",
      "--- pos  2 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n",
      "--- pos  3 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n",
      "--- pos  4 ---\n",
      "2018 10th International Conference on Communication Systems & Networks (COMSNETS)\n",
      "3 - 7 January 2018  |  Bengaluru, India\n",
      "Sponsors: COMSNETS Association; IEEE Communications Society\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies\n",
      "2018 IEEE 8th International Nanoelectronics Conferences (INEC)\n",
      "3 - 5 January 2018  |  Kuala Lumpur, Malaysia\n",
      "Sponsors: Singapore Section NANO Chapter; Singapore Section R/EP/ED Jt Chapter\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics\n",
      "2018 Conference on Signal Processing And Communication Engineering Systems (SPACES)\n",
      "4 - 5 January 2018  |  Vijayawada, India\n",
      "Sponsors: Guntur Subsection; IEEE Hyderabad Section; KLEF (Koneru Lakshmaiah Education Foundation)\n",
      "Field of Interest: Aerospace; Communication, Networking and Broadcast Technologies; Computing and Processing; Fields, Waves and Electromagnetics; Signal Processing and Analysis\n",
      "2018 International Conference on Computer Communication and Informatics (ICCCI)\n",
      "4 - 6 January 2018  |  Coimbatore, Tamilnadu, India\n",
      "Sponsors: Madras Section; Sri Shakthi Institute of Engineering & Technology\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 Indian Control Conference (ICC)\n",
      "4 - 6 January 2018  |  Kanpur, India\n",
      "Sponsors: IEEE Control Systems Society; Indian Institute of Technology Kanpur\n",
      "Field of Interest: Aerospace; Bioengineering; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)\n",
      "4 - 7 January 2018  |  Boulder, Colorado, USA\n",
      "Sponsors: IEEE Antennas and Propagation Society; US National Committee for URSI\n",
      "Field of Interest: Aerospace; Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Engineered Materials, Dielectrics and Plasmas; Fields, Waves and Electromagnetics; Geoscience; Photonics and Electrooptics; Signal Processing and Analysis\n",
      "2018 International Conference on Smart City and Emerging Technology (ICSCET)\n",
      "5 January 2018  |  Mumbai, India\n",
      "Sponsors: Bombay Section; Universal College of Engineering, Vasai\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing; Engineering Profession; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis; Transportation\n",
      "2018 International Conference on Power, Signals, Control and Computation (EPSCICON)\n",
      "6 - 10 January 2018  |  Thrissur, India\n",
      "Sponsors: Association of Electrical and Electronics Engineering - Vidya Academy of Science and Technology; IEEE Power & Energy Society; Kerala Section; Vidya International Charitable Trust\n",
      "Field of Interest: Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Fields, Waves and Electromagnetics; Photonics and Electrooptics; Power, Energy and Industry Applications; Robotics and Control Systems; Signal Processing and Analysis\n",
      "2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)\n",
      "6 - 10 January 2018  |  Pune, India\n",
      "Sponsors: IEEE Circuits and Systems Society; IEEE Computer Society; IEEE Council on Electronic Design Automation; VLSI Society of India\n",
      "Field of Interest: Bioengineering; Communication, Networking and Broadcast Technologies; Components, Circuits, Devices and Systems; Computing and Processing\n",
      "2018 Magnetics and Optics Research International Symposium (MORIS)\n",
      "7 - 10 January 2018  |  Queens, New York, USA\n",
      "Sponsors: IEEE Magnetics Society; Queens College of the City University of New York\n",
      "Field of Interest: Components, Circuits, Devices and Systems; Computing and Processing; Engineered Materials, Dielectrics and Plasmas; Photonics and Electrooptics; Power, Energy and Industry Applications\n"
     ]
    }
   ],
   "source": [
    "!python src/ds3_5_readIEEE.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* 학회를 검색하는 폼에 입력하면, 검색문자열을 생성한다. 다음은 검색문자열이 포함된 url이다. 검색을 하는 경우 크롤링을 해본다.\n",
    "* 학회명, 학회일시, 학회장소를 구분해서 저장해 본다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-6: 한국 프로야구 팀 순위 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "최근 스포츠에 과학기법을 많이 활용하고 있다. 세밀한 차이가 승패를 좌우하는 까닭에 실시간으로 데이터를 분석해 보다 과학적으로 순간 순간의 결정에 활용하고 있다. 야구가 좋은 예이다. 많은 데이터를 가지고, 특정 투수에 대한 선수의 약점, 선수에 대한 필드의 배치를 결정하기도 한다.\n",
    "한국 프로야구 팀의 순위를 가져오기로 한다.\n",
    "\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지로 가서 소스보기를 해본다. \n",
    "기록이 테이블 형식으로 구성되어 있다.\n",
    "야구선수 또는 팀은 한글이다. 검색하려면 unicode로 패턴 찾는다. 한글 앞에 unicode를 의미하는 u'타자'라고 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kbreport.com/leader/main?rows=20&order=oWAR&orderType=DESC&teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import requests\n",
    "urlbase=\"http://www.kbreport.com/leader/main?\"\n",
    "url1=\"rows=20&order=oWAR&orderType=DESC&\"\n",
    "url2=\"teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\"\n",
    "urlbaseball=urlbase+url1+url2\n",
    "print urlbaseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선수검색</li></a>\r\n",
      "\t\t\t\t\t<a href=\"/history/main\"><li>역대기록</li></a>\r\n",
      "\t\t\t\t\t<a href=\"/statDic/main\"><li id=\"nav4\">STAT Dic</li></a>\r\n",
      "\t\t\t\t\t<a href=\"/event/hitProbabilityPerGame\"><li>투수 VS 타자</li></a>\r\n",
      "\t\t\t\t\t<!-- \r\n",
      "\t\t\t\t\t<a href=\"score.html\"><li id=\"nav1\">경기결과</li></a>\r\n",
      "\t\t\t\t\t<a href=\"/statBuzz/main\"><li id=\"nav2\">STAT BUZZ</li></a>\r\n",
      "\t\t\t\t\t<a href=\"depth.html\"><li>팀구성도</li></a>\r\n",
      "\t\t\t\t\t<a href=\"trade.html\"><li>선수이동내역</li></a>\r\n",
      "\t\t\t\t\t<a href=\"/leader/main\"><li>개인순위</li></a>\r\n",
      "\t\t\t\t\t<a href=\"team.html\"><li>팀순위</li><\n"
     ]
    }
   ],
   "source": [
    "data=requests.get(urlbaseball).text\n",
    "print data[6000:6500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6825\n",
      "8838\n"
     ]
    }
   ],
   "source": [
    "print data.find('top-score-top')\n",
    "print data.find('top-score end')\n",
    "\n",
    "#import re\n",
    "#p=re.compile('NC\\w+')\n",
    "#res=re.search('<title>', data)\n",
    "#res=re.search(u'타자.+', data)\n",
    "#res=re.search(u'야구.통계.+', data)\n",
    "#print res.group()\n",
    "\n",
    "#data.encode('utf-8')\n",
    "#print data\n",
    "#from BeautifulSoup import BeautifulSoup\n",
    "#BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r']\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n"
     ]
    }
   ],
   "source": [
    "mydata=data[6340:8353+len('top-score end')]\n",
    "import re\n",
    "p=re.compile(u'.승.+')\n",
    "#p=re.compile(u'.두산.')\n",
    "#res=p.search(data)\n",
    "found=p.findall(mydata)\n",
    "print found\n",
    "for item in found:\n",
    "    print item\n",
    "#print res.group()\n",
    "#findall?\n",
    "#print res.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## xpath\n",
    "\n",
    "* url\n",
    "http://www.kbreport.com/main\n",
    "\n",
    "* 경기결과의 표 구성: 11줄 (표 제목 포함)\n",
    "    * 표 제목 (table header) th\n",
    "    * 표 행 (table row ) tr\n",
    "    * 표 셀 (table cell) td\n",
    "\n",
    "순위 | 팀명 | 승 | 무 |  |  |  |  |  |  | 연속\n",
    "----|-----|---|---|--|--|--|--|--|--|--\n",
    "1   |     |   |   |  |  |  |  |  |  | 2승\n",
    "2   |     |   |   |  |  |  |  |  |  | 2패\n",
    "\n",
    "* selector\n",
    "\n",
    "xpath | 결과\n",
    "-----|-----\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")``` | 표 11줄\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td\")``` | 100개\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td[@class='center']\")``` | 20개\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td//a\")``` | 팀명 10개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* requests를 사용해서 url을 읽어온다.\n",
    "* 전체 길이를 len()을 사용해서 알 수 있다.\n",
    "* lxml을 사용해서 tree 구조를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://www.kbreport.com/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50602"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "_htmlTree = lxml.etree.HTML(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* tree에서 전체 행 11개를 가져온다.\n",
    "* 행의 셀이 서로 구조가 다르다. 잘 읽어 오는지 확인한다.\n",
    "    * 팀명은 a href로 구성되어 있고, 결과는 배열이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 [] [] Next Row\n",
      "1 [u'\\ub450\\uc0b0'] [] Next Row\n",
      "2 ['SK'] [] Next Row\n",
      "3 ['KIA'] [] Next Row\n",
      "3 ['NC'] [] Next Row\n",
      "5 ['kt'] [] Next Row\n",
      "6 [u'\\ub125\\uc13c'] [] Next Row\n",
      "7 [u'\\ud55c\\ud654'] [] Next Row\n",
      "8 [u'\\uc0bc\\uc131'] [] Next Row\n",
      "8 ['LG'] [] Next Row\n",
      "10 [u'\\ub86f\\ub370'] [] Next Row\n"
     ]
    }
   ],
   "source": [
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    print teams[0].text, teams[1].xpath('.//a/text()'), teams[2].xpath('.//a/text()'),\n",
    "    print \"Next Row\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* nodes는 결과가 여러 개 목록이므로 배열\n",
    "* 배열 nodes의 개별 요소 teams는 '_Element'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'lxml.etree._Element'>\n"
     ]
    }
   ],
   "source": [
    "print type(nodes)\n",
    "print type(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0번째 행:  tr\n",
      "-- 1번째 행, 태그: [<Element th at 0x7fbe8504b368>, <Element th at 0x7fbe84facf80>, <Element th at 0x7fbe84fac908>, <Element th at 0x7fbe84fac9e0>, <Element th at 0x7fbe84fac950>, <Element th at 0x7fbe84fac878>, <Element th at 0x7fbe84faca28>, <Element th at 0x7fbe84facdd0>, <Element th at 0x7fbe84facb00>, <Element th at 0x7fbe84facb48>]\n",
      "-- 2번째 행, 태그 2번째 (팀명): 두산\n",
      "-- 2번째 행, 태그 3번째 문자열: 93\n",
      "-- 2번째 행, 태그 3번째 태그: td\n"
     ]
    }
   ],
   "source": [
    "print \"-- 0번째 행: \", nodes[0].tag\n",
    "print \"-- 1번째 행, 태그:\", nodes[0].getchildren()\n",
    "print \"-- 2번째 행, 태그 2번째 (팀명):\", nodes[1].getchildren()[1].xpath(\".//a\")[0].text\n",
    "print \"-- 2번째 행, 태그 3번째 문자열:\", nodes[1].getchildren()[2].text\n",
    "print \"-- 2번째 행, 태그 3번째 태그:\", nodes[1].getchildren()[2].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 연습 후, if문으로 a link와 아닌 경우로 나누어 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\n",
      "1 두산 9 0 3 0.750 0.0 69 67 4승\n",
      "2 SK 8 0 4 0.667 1.0 85 58 1패\n",
      "3 KIA 8 0 5 0.615 1.5 87 55 4승\n",
      "3 NC 8 0 5 0.615 1.5 67 54 3패\n",
      "5 kt 7 0 6 0.538 2.5 87 79 1패\n",
      "6 넥센 7 0 7 0.500 3.0 67 72 3패\n",
      "7 한화 5 0 7 0.417 4.0 64 90 1승\n",
      "8 삼성 5 0 8 0.385 4.5 55 68 1승\n",
      "8 LG 5 0 8 0.385 4.5 62 67 1승\n",
      "10 롯데 2 0 11 0.154 7.5 56 89 1패\n"
     ]
    }
   ],
   "source": [
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    for cols in teams:\n",
    "        if cols.xpath('.//a/text()'):\n",
    "            print cols.xpath('.//a/text()')[0],\n",
    "        else:\n",
    "            print cols.text.strip(),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```\n",
    "\n",
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds_web_crawl_kbaseball.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\n",
      "1 두산 9 0 3 0.750 0.0 69 67 4승\n",
      "2 SK 8 0 4 0.667 1.0 85 58 1패\n",
      "3 KIA 8 0 5 0.615 1.5 87 55 4승\n",
      "3 NC 8 0 5 0.615 1.5 67 54 3패\n",
      "5 kt 7 0 6 0.538 2.5 87 79 1패\n",
      "6 넥센 7 0 7 0.500 3.0 67 72 3패\n",
      "7 한화 5 0 7 0.417 4.0 64 90 1승\n",
      "8 삼성 5 0 8 0.385 4.5 55 68 1승\n",
      "8 LG 5 0 8 0.385 4.5 62 67 1승\n",
      "10 롯데 2 0 11 0.154 7.5 56 89 1패\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lxml.etree\n",
    "\n",
    "r = requests.get('http://www.kbreport.com/main')\n",
    "_htmlTree = lxml.etree.HTML(r.text)\n",
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    for cols in teams:\n",
    "        if cols.xpath('.//a/text()'):\n",
    "            print cols.xpath('.//a/text()')[0],\n",
    "        else:\n",
    "            print cols.text.strip(),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 구조를 만들어 프로그램으로 만든다.\n",
    "    * 라이브러로 만들거나,\n",
    "    * 테스트하거나,\n",
    "    * 시작 점을 분명하게 할 수 있다.\n",
    "* main() 함수\n",
    "    * ```if __name__ == \"__main__\"```는 명령창에서 실행할 경우, 처음 실행되는 main()함수 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ds_web_crawl_kbaseball.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds_web_crawl_kbaseball.py\n",
    "# coding: utf-8\n",
    "import requests\n",
    "import lxml.etree\n",
    "\n",
    "def getkb():\n",
    "    r = requests.get('http://www.kbreport.com/main')\n",
    "    _htmlTree = lxml.etree.HTML(r.text)\n",
    "    nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "    print \"테이블 행 갯수: \", len(nodes)\n",
    "    counter=0\n",
    "    for teams in nodes:\n",
    "        for cols in teams:\n",
    "            if cols.xpath('.//a/text()'):\n",
    "                print cols.xpath('.//a/text()')[0],\n",
    "            else:\n",
    "                print cols.text.strip(),\n",
    "        print\n",
    "\n",
    "def main():\n",
    "    getkb()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\r\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\r\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\r\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\r\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\r\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\r\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\r\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\r\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\r\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\r\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\r\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\r\n"
     ]
    }
   ],
   "source": [
    "!python src/ds_web_crawl_kbaseball.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.9 동적 페이지에서 데이터 수집\n",
    "\n",
    "### 1.9.1 동적 페이지\n",
    "\n",
    "HTML은 정적페이지, Static Web Page이다. 웹페이지가 열리면, 단순히 읽을 수 있기만 가능하다. 열린 페이지는 내용이 변경되지 않는다.\n",
    "\n",
    "동적페이지는 사용자의 요청, 상황에 따라 내용이 변경된다. 클라이언트측 또는 서버측에서 그 페이지를 갱신할 수 있다.\n",
    "클라이언트측에서는 예를 들면 자바스크립트를 사용하여 사용자가 요청하면 내용이 새로 생성되어 웹페이지 변경된다.\n",
    "서버측에서도 내용을 변경하여 클라이언트로 전송할 수 있다. JSP, PHP를 사용하는 것이 좋은 예다.\n",
    "특히 자바스크립트가 포함된 페이지는 추출하려는 내용이 동적으로 생성되기 때문에 문제가 된다. HTML 파서는 정적페이지에서 정보를 추출하기 때문이다. 동적페이지는 자바스크립트를 실행하면서 데이터를 추출해야 한다.\n",
    "\n",
    "구분 | 설명 | 언어\n",
    "-----|-----|-----\n",
    "클라이언트 측 스크립트 | 클라이언트 측에서 내용이 변경된다. 사용자가 웹페이지에서 마우스 클릭 또는 키보드 입력을 하면 클라이언트에서 내용이 생성되어 페이지를 변경한다. | Javascript, Flash\n",
    "서버 측 스크립트 | 서버측에서 내용을 생성하여 전송된다. 웹페이지를 변경하려면 서버로 전송, 처리 결과를 받아서 변경한다.  | JSP, PHP, ASP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.9.2 Selenium\n",
    "\n",
    "Selenium은 **화면에서 테스트를 자동으로 실행**하기 위해 만들어진 라이브러리이다.\n",
    "사용자가 화면에서 필드에 입력하거나, 선택을 하거나, 버튼을 누르거나 하는 **화면동작을 자동으로 실행**하면서 원하는 결과를 출력되는지 **프로그램으로 조작**할 수 있다. \n",
    "웹브라우저에서도 **WebDriver**를 사용하여 사용자의 화면 동작을 자동으로 실행하여 테스트하거나 스크레이핑에 활용할 수 있다.\n",
    "Python, Java, Javascript, Perl, PHP, C# 등 많은 언어를 지원한다.\n",
    "\n",
    "#### Selenium 설치\n",
    "\n",
    "Python에서 Selenium을 사용하게 된다. pip를 사용하여 설치한다.\n",
    "\n",
    "```python\n",
    "pip install selenium\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### webdriver 설치\n",
    "\n",
    "웹드라이버는 **웹브라우저를 프로그램에서 호출하여 사용**하기 위해 설치한다.\n",
    "설치하고 올바르게 설정하면 selenium에서 웹브라우저가 뜨게 된다.\n",
    "Chrome, FireFox, Internet Explorer 등을 지원한다.\n",
    "\n",
    "* 윈도우에서 **크롬드라이버** 설치 예\n",
    "\n",
    "해당 사이트로 가서 실행파일을 내려받아 설치한다.\n",
    "크롬을 설치해 보자.\n",
    "해당 사이트 [Chrome](http://chromedriver.storage.googleapis.com/index.html)에서 'chromedriver_win32.zip'을 내려받는다.\n",
    "zip을 풀어 놓고, 그 **경로에서 호출**한다.\n",
    "\n",
    "```python\n",
    "from selenium import webdriver\n",
    "webdriver.Chrome(\"path/to/chromedriver\") # exe를 뒤에 안붙여도 된다.\n",
    "```\n",
    "\n",
    "* 리눅스에서 **크롬드라이버** 설치 예\n",
    "\n",
    "```python\n",
    "sudo port install ChromeDriver # osx\n",
    "pip install chrome-driver # Ubuntu\n",
    "```\n",
    "\n",
    "경로가 설정되지 않으면 Python에서 경로오류가 발생한다.설치하고 나면 쉘에서 버전을 확인할 수 있다.\n",
    "Python에서 사용하려면, 'webdriver.chrome.driver'를 사전에 설정한다.\n",
    "\n",
    "```python\n",
    "os.environ[\"webdriver.chrome.driver\"]=\"/usr/local/bin/chromedriver\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### PhantomJS 설치\n",
    "\n",
    "**웹브라우저 없이** 프로그램에서 driver를 사용할 경우에는 PhantomJS를 사용한다. 이를 **headless browser**라고 한다.\n",
    "\n",
    "* 윈도우에서 설치\n",
    "http://phantomjs.org/download.html phantomjs-x.x.x-windows.zip을 다운로드, unzip한 후 bin에 있는 실행파일을 사용한다.\n",
    "\n",
    "```python\n",
    "from selenium import webdriver\n",
    "webdriver.Chrome(\"path/to/phantomjs\") # exe를 뒤에 안붙여도 된다.\n",
    "```\n",
    "\n",
    "* 리눅스에서 설치\n",
    "\n",
    "아래 패키지를 설치한다. 우분투 apt는 일부 기능만을 설치하므로, npm으로 설치한다.\n",
    "\n",
    "```python\n",
    "npm install -g phantomjs(o)\n",
    "apt install phantomjs (x, 부분설치)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "설치가 되었는지 확인하려면 버전을 확인해본다.\n",
    "아래는 경로설정이 되어있는 경우 실행한 결과이다.\n",
    "\n",
    "> 알아두기\n",
    "> **버전**\n",
    ">\n",
    "> selenium 버전이 지원하는 chromdriver version을 사용하지 않으면 오류가 발생한다.\n",
    "> selenium의 버전을 확인하려면:\n",
    "```python\n",
    "pip freeze\n",
    "```\n",
    "> chromedriver 버전이 적합한지 확인해야 한다.\n",
    "> 윈도우는 명령창에서 버전을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromeDriver 2.26.436382 (70eb799287ce4c2208441fc057053a5b07ceabac)\r\n"
     ]
    }
   ],
   "source": [
    "!chromedriver -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.9.3 간단한 명령어\n",
    "\n",
    "\n",
    "#### driver 명령어\n",
    "\n",
    "```python\n",
    "driver.page_source          #페이지 소스를 읽는다.\n",
    "driver.implicitly_wait(30)  #페이지를 일정 시간 기다리게 한다.\n",
    "driver.close() or quit()    #driver를 종료할 경우\n",
    "```\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "driver.close() | focus가 있는 웹브라우저 닫기\n",
    "driver.quit() | driver.dispose()를 호출해서, 브라우저 모두 닫고 WebDriver session 끝냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### form 명령어\n",
    "\n",
    "```python\n",
    "send_keys() # 키보드 입력을 전송\n",
    "click()     # a link 또는 button을 선택하여 mouse click\n",
    "submit()    # form을 click()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### finding elements 명령어\n",
    "\n",
    "WebElement는 size, tag_name, text를 검색할 수 있다. 복수일 경우 elements를 사용한다.\n",
    "아래는 함수의 예이다.\n",
    "\n",
    "```python\n",
    "finding_element_by_id()\n",
    "finding_element_by_name()\n",
    "finding_element_by_class_name()\n",
    "finding_element_by_tag_name()\n",
    "finding_element_by_css_selector()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python.org에서 검색어를 프로그램에서 정해서 실행을 요청해 보자.\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "find_element_by_name(\"q\") | 'name'이 \"q\"인 태그를 찾는다.\n",
    "send_keys(\"pycon\") | 키보드 입력을 대신한다. \"pycon\"을 입력한다는 의미이다.\n",
    "send_keys(Keys.RETURN) | 'Keys.RETURN' 키보드 엔터를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#driver = webdriver.Chrome()\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "#assert \"No results found.\" not in driver.page_source\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyCon CZ 2018\n",
      "PyCon India 2018\n",
      "PyCon Ireland 2016\n",
      "PyCon Australia 2013\n",
      "PyCon Ireland 2012\n",
      "PyCon UK 2013\n",
      "PyCon Italia 5\n",
      "PyCon CZ 2017\n",
      "PyCon Nigeria 2017\n",
      "PyCon Pakistan\n",
      "PyCon Uruguay 2013\n",
      "PyCon US 2014\n",
      "PyCon Ukraine 2016\n",
      "Kiwi PyCon 2016\n",
      "PyCon US 2019\n",
      "PyCon Canada 2017\n",
      "PyCon Canada 2012\n",
      "PyCon Ukraine 2012\n",
      "Florida PyCon\n",
      "PyCon Colombia 2018\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "_html=driver.page_source\n",
    "soup=BeautifulSoup(_html,\"lxml\")\n",
    "for e in soup.select(\"h3 a\"):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-7: 로그인이 필요한 사이버강의실에서 강의계획서를 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "사이버강의실은 강의관련 공지, 강의계획서, 강의슬라이드와 같은 자료를 제공한다. 학교의 사이버강의실은 보통 개방되어 있지 않고 사용자의 로그인이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 해결\n",
    "\n",
    "* 사용자이름, 비밀번호를 넣을 수 있는 서식을 찾는다.\n",
    "* 이름, 비밀번호에 값을 넣는다.\n",
    "* 서버요청 버튼을 찾아서 클릭한다.\n",
    "* 여러 교과목 가운데 수강과목을 찾아 클릭한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://ecampus.smu.ac.kr/\")\n",
    "username=driver.find_element_by_id(\"input-username\")\n",
    "username.send_keys(\"myuserid\")\n",
    "password=driver.find_element_by_id(\"input-password\")\n",
    "password.send_keys(\"mypassword\")\n",
    "loginButton=driver.find_element_by_name(\"loginbutton\")\n",
    "loginButton.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* My Page로 가면 교과목 목록을 볼 수 있다.\n",
    "* 교과목 목록에서 \"컴퓨팅사고\" 과목을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mypage=driver.find_element_by_link_text(\"My Page\")\n",
    "mypage.click()\n",
    "mypage=driver.find_element_by_partial_link_text(\"컴퓨팅사고\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/ds3_7_ecampus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_7_ecampus.py\n",
    "from selenium import webdriver\n",
    "\n",
    "def readEcampus():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://ecampus.smu.ac.kr/\")\n",
    "    username=driver.find_element_by_id(\"input-username\")\n",
    "    username.send_keys(\"myuserid\")\n",
    "    password=driver.find_element_by_id(\"input-password\")\n",
    "    password.send_keys(\"mypassword\")\n",
    "    loginButton=driver.find_element_by_name(\"loginbutton\")\n",
    "    loginButton.click()\n",
    "\n",
    "    mypage=driver.find_element_by_link_text(\"My Page\")\n",
    "    mypage.click()\n",
    "    mypage=driver.find_element_by_partial_link_text(\"컴퓨팅사고\")\n",
    "\n",
    "def main():\n",
    "    #readWikiLxml()\n",
    "    readWikiBS()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-8: 한국 프로야구 선수 기록 크롤링하기 (1)\n",
    "\n",
    "### 문제\n",
    "\n",
    "앞서 팀순위를 가져오는 프로그램을 만들었다. 선수기록을 가져와보자. 이전에 했던 방식으로 하면 가져올 수 없다는 것을 알게 된다.\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지로 가서 소스보기를 해본다. \n",
    "선수기록은 동적인 페이지로 구성되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 자바스크립트가 포함된 페이지\n",
    "\n",
    "* 야구데이터는 검색엔진을 이용하며, 검색결과가 정적인 HTML로 반환되지 않고 있다. 그래서 자세한 검색에 대한 결과를 스크레이핑 하려면 이 문제를 해결해야 한다.\n",
    "* 동적페이지, javascript가 페이지를 생성하면 크롤링을 할 수 없다.\n",
    "클래스 \".ltb-table\"는 테이블 조회결과이다. 개발자도구 콘솔에서 자바스크립트로 보면 그결과를 볼 수 있지만, BeautifulSoup에서는 불가능하다.\n",
    "\n",
    "http://www.kbreport.com/leader/main페이지를 살펴보면, '#/{{page}}'과 같이 내부 href를 생성하고 있다.\n",
    "\n",
    "```\n",
    "\t$(document).ready(function(){\n",
    "\t\tpaging.action({\n",
    "\t\t\tid : \"paging\"\n",
    "\t\t\t, totalCount : setNumber('284')\n",
    "\t\t\t, page : setNumber('1')\n",
    "\t\t\t, rows : setNumber('20')\n",
    "\t\t\t, allView : true\n",
    "\t\t\t, pageGroup : 5\n",
    "\t\t\t, link : \"#/{{page}}\"\n",
    "\t\t});\n",
    "\t\tswitched=false;\n",
    "\t\tupdateTables();\n",
    "\t});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* '더보기 >>' 버튼의 크롤링\n",
    "* css 크롤링\n",
    "* 검색조건을 넣어서 크롤링\n",
    "    * url 검색 'http://www.kbreport.com/player/list?key=이대호'\n",
    "\n",
    "    * javascript console 창\n",
    "```\n",
    "> $$('.dca-cb-table1 td')[0].innerText\n",
    "\"이대호\"\n",
    "> $$('.dca-cb-table1 td')[1].innerText\n",
    "\"1982-06-21\"\n",
    "> $$('.dca-cb-table1 td')[2].innerText\n",
    "\"2017\"\n",
    "> $$('.dca-cb-table1 td')[3].innerText\n",
    "\"롯데\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-9: 한국 프로야구 선수 기록 크롤링하기 (2)\n",
    "\n",
    "### 문제\n",
    "\n",
    "다른 사이트 www.koreabaseball.com를 스크레이핑해보자.\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지를 가져온다.\n",
    "데이터를 추출한다.\n",
    "단, paging에 javascript이 있어서 추가 작업이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "urlkorbase='http://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx'\n",
    "data=requests.get(urlkorbase).text\n",
    "#print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-10: 다음에서 환율 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "다음에 게시되고 있는 환율을 추출해 보자.\n",
    "자바스크립트가 포함되어 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "미국 (USD)달러1069.00▲9.001087.701050.301079.401058.603.751.00\n",
      "일본 (JPY100)엔996.97▲6.691014.41979.531006.74987.201.930.93\n",
      "중국 (CNY)위안169.31▲0.89177.77160.85171.00167.625.920.16\n",
      "유로 (EUR)유로1309.04▲9.851335.081283.001322.131295.951.571.22\n",
      "영국 (GBP)파운드1499.86▲13.581529.401470.321514.851484.872.491.40\n",
      "스위스 (CHF)프랑1109.96▲8.831131.821088.101121.051098.871.181.04\n",
      "캐나다 (CAD)달러838.66▲9.24855.18822.14847.04830.283.520.78\n",
      "뉴질랜드 (NZD)달러775.67▲1.50790.95760.39783.42767.924.470.73\n",
      "홍콩 (HKD)달러136.20▲1.16138.88133.52137.56134.843.060.13\n",
      "브라질 (BRL)레알318.81▼2.01351.32293.310.00314.997.160.30\n",
      "멕시코 (MXN)페소58.55▼0.0160.8952.1159.1357.979.680.05\n",
      "아랍에미리트 (AED)디르함291.04▲2.45302.68270.96293.95288.134.040.27\n",
      "쿠웨이트 (KWD)디나르3561.20▲29.043703.643276.313596.813525.593.733.33\n",
      "바레인 (BHD)디나르2834.94▲23.872948.332608.152863.282806.604.672.65\n",
      "인도 (INR)루피16.46▲0.130.000.000.000.008.220.02\n",
      "사우디아라비아 (SAR)리얄285.05▲2.41296.45265.39287.90282.204.010.27\n",
      "노르웨이 (NOK)크로네136.61▲1.13139.95133.27137.97135.253.020.13\n",
      "덴마크 (DKK)크로나175.78▲1.33180.08171.48177.53174.031.650.16\n",
      "말레이지아 (MYR)링키트276.23▲2.08290.04259.660.00273.475.410.26\n",
      "방글라데시 (BDT)타카12.88▲0.2213.3911.340.000.009.280.01\n",
      "파키스탄 (PKR)루피9.23▲0.079.598.130.000.007.880.01\n",
      "인도네시아 (IDR100)루피아7.78▲0.068.327.017.857.716.970.01\n",
      "대만 (TWD)달러36.51▲0.2339.7933.960.000.002.500.03\n",
      "필리핀 (PHP)페소20.54▲0.1922.3819.7220.7420.345.860.02\n",
      "스웨덴 (SEK)크로나127.15▲1.21130.26124.04128.42125.881.500.12\n",
      "호주 (AUD)달러821.90▲6.81838.09805.71830.11813.694.130.77\n",
      "싱가포르 (SGD)달러811.20▲4.93827.34795.06819.31803.093.520.76\n",
      "태국 (THB)바트34.19▲0.2935.8932.1434.5333.853.480.03\n",
      "이집트 (EGP)파운드60.45▲0.560.000.000.000.007.220.06\n",
      "브루나이 (BND)달러809.60▲8.09841.98761.030.000.003.520.76\n",
      "이스라엘 (ILS)쉐캐림302.71▲2.99314.81278.500.000.002.130.28\n",
      "요르단 (JOD)디나르1506.69▲12.681566.951386.160.000.006.931.41\n",
      "베트남 (VND100)동4.69▲0.045.244.144.734.653.670.00\n",
      "러시아 (RUB)루블18.50▲0.1119.7916.4718.6818.329.300.02\n",
      "헝가리 (HUF)포린트4.19▲0.014.523.864.234.152.230.00\n",
      "폴란드 (PLN)줄러티311.98▲2.94336.93287.03315.41308.553.850.29\n",
      "남아프리카공화국 (ZAR)자르88.85▼0.0294.1881.7589.9187.799.530.08\n",
      "몽골 (MNT)투그릭0.45▲0.010.530.370.000.0015.530.00\n",
      "체코 (CZK)코루나51.63▲0.3455.2446.9952.1951.072.770.05\n",
      "카자흐스탄 (KZT)텡게3.34▲0.023.702.980.000.0012.220.00\n",
      "카타르 (QAR)리얄293.60▲2.450.000.000.000.004.110.27\n",
      "터키 (TRY)리라264.80▲2.26285.98243.62267.71261.8914.970.25\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get('http://finance.daum.net/exchange/exchangeMain.daum')\n",
    "soup=BeautifulSoup(driver.page_source, \"lxml\")\n",
    "exchange=soup.select(\"#exchangeTB tbody tr.trData\")\n",
    "print len(exchange)\n",
    "for e in exchange:\n",
    "    print e.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get('http://finance.daum.net/exchange/exchangeMain.daum')\n",
    "soup=BeautifulSoup(driver.page_source, \"lxml\")\n",
    "exchange=soup.select(\"#exchangeTB tbody tr.trData\")\n",
    "print len(exchange)\n",
    "for e in exchange:\n",
    "    print e.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습\n",
    "\n",
    "* 크롤링은 수집하는 데이터가 비구조적이라 쉽지 않다.\n",
    "* 관심있는 웹 사이트를 대상으로 크롤링을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-1: UC Irvine 기계학습 데이터\n",
    "\n",
    "* UC Irvine 기계학습 데이터 banknote authentication Data Set를 프로그래밍으로 가져와서 \n",
    "클래스별로 'entropy of image'의 평균을 구하시오\n",
    "* http://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-2: 기상청 도별 날씨 가져오기\n",
    "\n",
    "### 문제\n",
    "날씨는 다양하게 소비되고 있다. 농사, 스포츠, 야외행사, 그날의 의상 등 많은 경우에 날씨가 적지 않게 영향을 미치고 있다. 날씨는 API를 직접 사용하거나, 웹페이지에서 추출할 수 있다. 기상청 웹페이지에 게시되고 있는 날씨를 가져와 보자.\n",
    "\n",
    "* 기상청 http://www.kma.go.kr/index.jsp의 날씨\n",
    "* css selector\n",
    "    ```\n",
    "    $$('.region_weather_e')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load /home/jsl/Code/git/bb/smu/exam/2017s1/mid/big/201311207/p2.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get('http://www.kma.go.kr/weather/observation/currentweather.jsp')\n",
    "bs = BeautifulSoup(r.text, 'lxml')\n",
    "weather = bs.select('.table_develop3 > tbody > tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print len(weather)\n",
    "print type(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 서울 약한비계속 13.6 10 6 4.3 1.1 42 0.1 80 북동 2.6 1012.1 \n",
      " 백령도 구름많음 19.8 8 8 5.3 1.7 44 0.0 78 동북동 7.9 1010.0 \n",
      " 인천 약한비단속 10.5 10 9 6.6 -0.1 47 0.0 62 동 3.6 1011.6 \n",
      " 수원 흐림 20 이상 10 6 7.9 -1.9 49  50 동북동 3.4 1011.6 \n",
      " 동두천  0.9   0.9 -2.6 37 1.3 77 북북동 1.4 1013.9 \n",
      " 파주  0.9   0.0 -0.4 32 2.0 97 북동 2.8 1013.7 \n",
      " 강화  1.7   0.9 -1.0 35 0.5 87 북동 4.9 1013.1 \n",
      " 양평  13.0   4.4 -0.6 43 0.3 70 동 1.6 1013.1 \n",
      " 이천  19.3   6.4 -2.7 47  52 북북동 3.2 1012.2 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 북춘천 약진눈깨비 8.0 10 8 2.0 -1.2 38 0.5 79 북동 1.3 1014.4 \n",
      " 북강릉 흐림 20 이상 10 10 6.7 -0.5 47 0.0 60 서북서 1.6 1012.6 \n",
      " 울릉도 흐림 20 이상 10 3 6.1 -3.8 47 0.0 49 남남서 4.5 1014.5 \n",
      " 속초  20 이상   4.5 -0.7 43 0.0 69 북북서 1.6 1013.4 \n",
      " 철원  1.2   0.4 -1.5 35 2.2 87 북 1.8 1014.6 \n",
      " 대관령  19.7   -0.3 -3.5 35 0.5 79 서 4.6 1013.6 \n",
      " 춘천  7.3   2.5 0.7 38 0.6 88 동북동 1.6 1014.5 \n",
      " 강릉  5.0   7.2 -2.2 48  51 북북서 1.6 1012.9 \n",
      " 동해  20 이상   8.6 -1.5 50  49 북 1.5 1012.8 \n",
      " 원주  19.9   6.8 -4.6 48  44 북동 2.9 1012.6 \n",
      " 영월  20 이상   10.2 -5.7 53  32 정온 0.0 1011.3 \n",
      " 인제  10.2   1.1 -0.3 35 3.0 90 정온 0.2 1015.0 \n",
      " 홍천  20 이상   3.2 0.0 40 0.0 80 북북동 1.2 1014.0 \n",
      " 태백  20 이상   6.8 -8.3 49  33 남남서 4.9 1010.3 \n",
      " 정선군  8.0   6.3 -4.4 48  46 남동 0.9 1012.5 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 서산  20 이상   10.3 1.8 52  56 남서 7.0 1011.7 \n",
      " 청주 흐림 20 이상 9 3 13.1 -2.4 56  34 서남서 4.1 1010.7 \n",
      " 대전 흐림 20 이상 9 3 13.3 0.6 57  42 남남서 4.5 1011.5 \n",
      " 충주  19.9   11.6 -3.7 55  34 서 2.1 1011.6 \n",
      " 추풍령  20 이상   12.4 -4.7 56  30 남서 5.7 1011.2 \n",
      " 홍성 흐림 20 이상 10 10 11.7 -0.1 55  44 남서 4.8 1011.4 \n",
      " 제천  20 이상   9.8 -6.9 53  30 남서 4.8 1010.8 \n",
      " 보은  20 이상   12.7 -2.0 56  36 서남서 2.4 1011.4 \n",
      " 천안  20 이상   12.4 -5.1 56  29 남남서 5.8 1010.9 \n",
      " 보령  19.8   11.0 5.7 53  70 남남서 10.9 1011.1 \n",
      " 부여  19.1   13.2 -0.1 56  40 남서 6.8 1011.8 \n",
      " 금산  20 이상   13.0 -3.3 56  32 남서 2.6 1011.2 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 전주 구름조금 20 이상 5 5 14.7 -0.2 58 0.0 36 남서 4.8 1012.1 \n",
      " 광주 맑음 17.3 0 0 13.8 -1.8 57 0.0 34 남남서 8.6 1013.5 \n",
      " 목포 맑음 19.9 0 0 13.8 4.9 57  55 남서 9.0 1014.3 \n",
      " 여수 맑음 20 이상 0 0 12.6 4.2 55  57 남서 10.9 1014.7 \n",
      " 흑산도 맑음 15.8 0 0 11.2 8.2 53  82 남 15.3 1012.0 \n",
      " 군산  19.5   13.5 2.3 57  47 남동 8.1 1012.2 \n",
      " 완도  15.8   14.0 5.0 57  55 남서 2.3 1015.4 \n",
      " 고창  19.0   13.1 1.1 56 0.2 44 남서 10.2 1013.3 \n",
      " 순천  12.6   12.3 2.1 55  50 남 3.4 1013.8 \n",
      " 진도(첨찰산)     9.5 3.2 51  65 북북서 6.2 1014.6 \n",
      " 부안  20 이상   13.8 0.4 57 0.5 40 남남서 7.3 1012.6 \n",
      " 임실  12.8   12.5 -2.5 56 0.5 35 남남서 4.5 1012.6 \n",
      " 정읍  20 이상   14.4 -2.5 58 0.2 31 남서 6.8 1012.4 \n",
      " 남원  20 이상   14.2 -5.0 58 1.1 26 남서 5.6 1012.2 \n",
      " 장수  19.3   11.0 -2.4 54 1.0 39 남남서 4.6 1012.0 \n",
      " 고창군  20 이상   13.3 -4.3 57 0.4 29 남서 6.2 1012.7 \n",
      " 영광군  11.1   12.8 0.1 56 0.1 42 북서 7.6 1013.5 \n",
      " 순창군  20 이상   13.4 -3.4 57 0.5 31 서남서 4.9 1013.4 \n",
      " 보성군  20 이상   13.2 1.8 56  46 남서 4.4 1015.1 \n",
      " 강진군  13.5   13.4 2.5 57  48 남서 6.4 1015.5 \n",
      " 장흥  20 이상   13.6 1.5 57  44 남서 5.5 1014.5 \n",
      " 해남  18.8   12.6 3.7 56 0.1 55 남서 8.7 1015.1 \n",
      " 고흥  18.9   12.7 2.8 56  51 남서 3.1 1014.9 \n",
      " 광양시  6.0   13.5 1.7 57 0.0 45 서남서 5.4 1014.4 \n",
      " 진도군  17.5   13.0 4.6 56  57 남서 7.0 1014.1 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 제주 맑음 20 이상 0 0 14.9 0.3 59  37 남서 7.1 1014.4 \n",
      " 고산     12.4 5.7 55  64 남남서 12.4 1016.6 \n",
      " 성산  20 이상   13.4 2.8 57  49 남서 8.0 1016.7 \n",
      " 서귀포  20 이상   13.2 4.8 56  57 남서 4.3 1017.6 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 안동 구름많음 20 이상 7 7 12.3 -7.2 56  25 남 2.4 1011.6 \n",
      " 포항 맑음 20 이상 0 0 14.4 -4.3 58  27 남서 3.8 1012.7 \n",
      " 대구 맑음 20 이상 0 0 13.0 -2.9 56  33 남 4.5 1012.7 \n",
      " 울산 맑음 20 이상 2 2 12.1 -1.8 55  38 남남서 5.8 1013.7 \n",
      " 창원 구름조금 20 이상 3 3 11.5 3.0 54 0.0 56 남남동 3.8 1014.3 \n",
      " 부산 맑음 20 이상 2 2 11.5 3.0 54  56 남서 6.7 1015.4 \n",
      " 울진  19.8   11.0 1.7 53  53 동북동 2.7 1012.3 \n",
      " 상주  7.3   13.4 -4.7 57  28 남서 2.3 1011.3 \n",
      " 통영  18.5   12.4 4.1 55 0.0 57 남남서 5.1 1015.7 \n",
      " 진주  19.4   12.6 1.8 56 0.0 48 남남동 3.3 1014.1 \n",
      " 김해시  12.4   11.5 3.2 54  57 서남서 4.8 1015.9 \n",
      " 북창원  20 이상   11.7 3.1 54  56 남 3.3 1014.7 \n",
      " 양산시  6.2   12.6 3.5 56  54 서남서 6.6 1016.2 \n",
      " 의령군  13.5   13.5 2.0 57 0.0 46 남서 5.2 1013.8 \n",
      " 함양군  20 이상   13.6 0.5 57 0.5 41 서남서 2.9 1012.2 \n",
      " 봉화  20 이상   10.0 -10.2 53 0.0 23 남남서 2.7 1011.6 \n",
      " 영주  20 이상   11.6 -6.8 55  27 남남서 1.8 1011.1 \n",
      " 문경  20 이상   12.3 -7.2 56  25 서 2.6 1011.2 \n",
      " 청송군  5.9   11.5 -6.4 55  28 서 0.7 1011.8 \n",
      " 영덕  20 이상   13.6 -9.6 57  19 서남서 3.4 1011.9 \n",
      " 의성  20 이상   13.6 -7.7 57  22 남서 1.9 1011.7 \n",
      " 구미  20 이상   13.5 -2.9 57  32 남서 2.6 1011.5 \n",
      " 영천  20 이상   12.8 -4.8 56  29 남서 4.1 1012.8 \n",
      " 경주시  20 이상   13.2 -2.3 57  34 남서 6.8 1013.1 \n",
      " 거창  20 이상   13.0 -1.3 56 0.8 37 남서 3.9 1010.7 \n",
      " 합천  19.9   13.3 -1.1 57 0.2 37 남남서 5.1 1012.9 \n",
      " 밀양  20 이상   12.4 -1.1 56 0.0 39 남 4.1 1014.1 \n",
      " 산청  20 이상   12.8 0.5 56 0.0 43 북북동 2.1 1012.6 \n",
      " 거제  19.5   12.4 4.8 55  60 동 3.7 1015.0 \n",
      " 남해  19.8   13.7 1.9 57 0.0 45 남남서 1.6 1015.0 \n"
     ]
    }
   ],
   "source": [
    "data=list()\n",
    "for row in weather: \n",
    "    rowList=row.get_text().split('\\n')\n",
    "    data.append(rowList)\n",
    "    for cell in rowList:\n",
    "        print cell,\n",
    "    print \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/ds3_x2_kmaWeather.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_x2_kmaWeather.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readWeather():\n",
    "    try:\n",
    "        r = requests.get('http://www.kma.go.kr/weather/observation/currentweather.jsp')\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    bs = BeautifulSoup(r.text, 'lxml')\n",
    "    weather = bs.select('.table_develop3 > tbody > tr')\n",
    "    data=list()\n",
    "    for row in weather:\n",
    "        rowList=row.get_text().split('\\n')\n",
    "        data.append(rowList)\n",
    "        for cell in rowList:\n",
    "            print cell,\n",
    "        print\n",
    "\n",
    "def main():\n",
    "    readWeather()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-3: 국가통계 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "http://kosis.kr/index/index.jsp\n",
    "kosis='http://kosis.kr/statisticsList/statisticsList_01List.jsp?vwcd=MT_ZTITLE&parentId=A#SubCont'\n",
    "data=requests.get(urlkorbase).text\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-4: 신문 기사 및 댓글 스크레이핑 해보기\n",
    "\n",
    "\n",
    "우리나라 한국은행이 빅데이터를 활용해 경제정책에 반영하는 방안을 마련하고 있다. 세계 여러 나라가 웹에서 수집한 데이터를 활용해 물가, 소비, 경제심리와 관련한 통계 및 분석에 활용하는 추세에 발맞추어 가는 것으로 보인다. 한국은행은 빅데이터 업무를 담당할 '빅데이터통계연구반'을 설치하고 2017년 8월 활동을 시작했다고 한다.\n",
    "SNS, 경제기사에 대한 댓글, 경제관련 기사를 분석하여 경제정책에 반영할 계획으로 알려졌다.\n",
    "* [BIG KINDS-Pro](http://www.bigkinds.or.kr/)\n",
    "    * 2016년 개편 후, 데이터분석 기능을 제공\n",
    "    * 스크레이핑의 params이 검색에 문자열로 붙지 않는 문제가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-5: 영화 리뷰의 분석\n",
    "\n",
    "### 문제\n",
    "\n",
    "'어떤 영화를 볼까?'라고 질문에 댓글을 읽어보고 결정하는 사람들이 꽤 있다.\n",
    "온라인 상에는 상영하고 있는 영화에 댓글을 다는 기능이 있다.\n",
    "댓글에서 의미있는 데이터를 추출하여 영화에 대해 긍정적, 부정적 의견이 어떠한지 분류할 수 있다.\n",
    "댓글을 분석하여 해당 영화의 매출을 예측하기도 한다.\n",
    "영화 리뷰를 분석하여 의미있는 정보를 추출하는 관련 학술 논문이 많다.\n",
    "\n",
    "* http://movielens.org\n",
    "* Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. \"Thumbs up?: sentiment classification using machine learning techniques.\" Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10. Association for Computational Linguistics, 2002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습 웹데이터-6: 댓글\n",
    "\n",
    "### 문제\n",
    "\n",
    "경향신문, \"사라지는 촌지·접대에 '찬성 89%'..업계는 여전히 '3·5·10' 규정 반발\"\n",
    "다음 포털의 댓글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get('http://v.media.daum.net/v/20170926225302536')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 더보기를 클릭하는 수만큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morelink=driver.find_element_by_css_selector(\"a[href='#more']\")\n",
    "morelink.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments=driver.find_element_by_css_selector('.cmt_box .list_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 부정 부패, 청탁 없이는 생존할 수 없는 업종이라면 없어지는게 맞겠지.\n",
      "1 김영란법 찬성! 학교촌지는 예전부터 사라졌었고 학교에서 명절되면 교장교감에게 선물하던 관행없어져 너무 좋다!  월급도 많이 받는 상사들이 왜 아랫사람들에게 선물 받는걸 당연시 여겼던 건지\n",
      "2 기레기들아 받던거 못받으니까 미쳐돌겠지?\n",
      "3 부정부패 때문에 성업하는 사업이 있다면 \n",
      "\n",
      "망해도 지금 망하는게 훗날\n",
      "\n",
      "더 크게 안망하는 법이다.\n",
      "\n",
      "선물 보다 정말 말한마디, 행동하나 정성을 다해봅시다.\n",
      "\n",
      "말 한마디가 천냥빛도 갚는 다 잖아요\n",
      "4 이런 것이 바로 한국이 얼마나 후진적이며, 부정부패에 절어 있는지를 그대로 보여주는 척도 아니겠는가? 저희들 먹고 살겠다고 국가 전체를 썩게 만들어도 상관없다는 ... ㅉㅉㅉ! 부끄러운 줄도 모르고 ...\n",
      "5 식사 1만원, 선물 1만원, 경조사비  5만원(1·1·5규정)\n",
      "로 바꾸자\n",
      "6 반드시 지켜야한다\n",
      "7 국회의원도 참여해라\n",
      "8 우리 모두 청탁없는 깨끗한 사회 만듭시다. 3/5/10도   2/3/5으로 줄입시다.\n",
      "9 받은개들 전부 쏴주겨라\n",
      "10 학교가 깨끗해지고 있다.\n",
      "\n",
      "이젠 학생들이 주는 커피나 음료 절대 안 받는다.\n",
      "\n",
      "예전엔 성의라고 받아 주었으나 이젠 안받아도 될 김영란법이 있어서 좋다.\n",
      "\n",
      "계속 이렇게 가자! 너무 좋다.\n",
      "11 위에서 아래로주는건 선물\n",
      "아래서 위로주는건  뇌물\n",
      "12 김영란법이후로 학부모 상담 갈때 부담이 사라졌습니다. 예의상 뇌물이 아닌 선물로  쿠키 한상자라도 들고 가야하나 늘 마음이 불편했습니다. 전 직장인으로써도 좋습니다. 정이라고 자꾸 들어오는 커피.빵..간식들 부담스러웠네요..이제 시작인데 없어지면 안됩니다\n"
     ]
    }
   ],
   "source": [
    "txt=comments.find_elements_by_class_name('desc_txt')\n",
    "for count,e in enumerate(txt):\n",
    "    print count,e.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup으로 가져와서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(driver.page_source,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commentInfo=soup.select('.list_comment .cmt_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두기2017.09.26. 22:58부정 부패, 청탁 없이는 생존할 수 없는 업종이라면 없어지는게 맞겠지.답글쓰기댓글 찬성하기593댓글 비추천하기5 느티나무2017.09.26. 23:01김영란법 찬성! 학교촌지는 예전부터 사라졌었고 학교에서 명절되면 교장교감에게 선물하던 관행없어져 너무 좋다!  월급도 많이 받는 상사들이 왜 아랫사람들에게 선물 받는걸 당연시 여겼던 건지답글쓰기댓글 찬성하기512댓글 비추천하기7 가오리2017.09.26. 23:00기레기들아 받던거 못받으니까 미쳐돌겠지?답글 2댓글 찬성하기190댓글 비추천하기4 21212017.09.26. 23:03부정부패 때문에 성업하는 사업이 있다면 \n",
      "\n",
      "망해도 지금 망하는게 훗날\n",
      "\n",
      "더 크게 안망하는 법이다.\n",
      "\n",
      "선물 보다 정말 말한마디, 행동하나 정성을 다해봅시다.\n",
      "\n",
      "말 한마디가 천냥빛도 갚는 다 잖아요답글쓰기댓글 찬성하기160댓글 비추천하기3 밝은하늘2017.09.26. 23:04이런 것이 바로 한국이 얼마나 후진적이며, 부정부패에 절어 있는지를 그대로 보여주는 척도 아니겠는가? 저희들 먹고 살겠다고 국가 전체를 썩게 만들어도 상관없다는 ... ㅉㅉㅉ! 부끄러운 줄도 모르고 ...답글 2댓글 찬성하기146댓글 비추천하기2 후아아2017.09.26. 23:01식사 1만원, 선물 1만원, 경조사비  5만원(1·1·5규정)\n",
      "로 바꾸자답글 1댓글 찬성하기147댓글 비추천하기4 HugaGage2017.09.26. 23:01반드시 지켜야한다답글쓰기댓글 찬성하기145댓글 비추천하기5 구라왕2017.09.26. 23:04국회의원도 참여해라답글쓰기댓글 찬성하기138댓글 비추천하기2 happywon2017.09.26. 23:04우리 모두 청탁없는 깨끗한 사회 만듭시다. 3/5/10도   2/3/5으로 줄입시다.답글쓰기댓글 찬성하기112댓글 비추천하기3 하림2017.09.26. 23:02받은개들 전부 쏴주겨라답글쓰기댓글 찬성하기76댓글 비추천하기4 SimonRyu2017.09.26. 23:10학교가 깨끗해지고 있다.\n",
      "\n",
      "이젠 학생들이 주는 커피나 음료 절대 안 받는다.\n",
      "\n",
      "예전엔 성의라고 받아 주었으나 이젠 안받아도 될 김영란법이 있어서 좋다.\n",
      "\n",
      "계속 이렇게 가자! 너무 좋다.답글쓰기댓글 찬성하기52댓글 비추천하기2 다중이2017.09.26. 23:09위에서 아래로주는건 선물\n",
      "아래서 위로주는건  뇌물답글쓰기댓글 찬성하기44댓글 비추천하기2 iyoulike2017.09.26. 23:06김영란법이후로 학부모 상담 갈때 부담이 사라졌습니다. 예의상 뇌물이 아닌 선물로  쿠키 한상자라도 들고 가야하나 늘 마음이 불편했습니다. 전 직장인으로써도 좋습니다. 정이라고 자꾸 들어오는 커피.빵..간식들 부담스러웠네요..이제 시작인데 없어지면 안됩니다답글 1댓글 찬성하기42댓글 비추천하기2\n"
     ]
    }
   ],
   "source": [
    "for e in commentInfo:\n",
    "    print e.text,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "두기\n",
      "2017.09.26. 22:58\n",
      "부정 부패, 청탁 없이는 생존할 수 없는 업종이라면 없어지는게 맞겠지.\n",
      "댓글 찬성하기593\n",
      "댓글 비추천하기5\n",
      "-----\n",
      "느티나무\n",
      "2017.09.26. 23:01\n",
      "김영란법 찬성! 학교촌지는 예전부터 사라졌었고 학교에서 명절되면 교장교감에게 선물하던 관행없어져 너무 좋다!  월급도 많이 받는 상사들이 왜 아랫사람들에게 선물 받는걸 당연시 여겼던 건지\n",
      "댓글 찬성하기512\n",
      "댓글 비추천하기7\n",
      "-----\n",
      "가오리\n",
      "2017.09.26. 23:00\n",
      "기레기들아 받던거 못받으니까 미쳐돌겠지?\n",
      "댓글 찬성하기190\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "2121\n",
      "2017.09.26. 23:03\n",
      "부정부패 때문에 성업하는 사업이 있다면 \n",
      "\n",
      "망해도 지금 망하는게 훗날\n",
      "\n",
      "더 크게 안망하는 법이다.\n",
      "\n",
      "선물 보다 정말 말한마디, 행동하나 정성을 다해봅시다.\n",
      "\n",
      "말 한마디가 천냥빛도 갚는 다 잖아요\n",
      "댓글 찬성하기160\n",
      "댓글 비추천하기3\n",
      "-----\n",
      "밝은하늘\n",
      "2017.09.26. 23:04\n",
      "이런 것이 바로 한국이 얼마나 후진적이며, 부정부패에 절어 있는지를 그대로 보여주는 척도 아니겠는가? 저희들 먹고 살겠다고 국가 전체를 썩게 만들어도 상관없다는 ... ㅉㅉㅉ! 부끄러운 줄도 모르고 ...\n",
      "댓글 찬성하기146\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "후아아\n",
      "2017.09.26. 23:01\n",
      "식사 1만원, 선물 1만원, 경조사비  5만원(1·1·5규정)\n",
      "로 바꾸자\n",
      "댓글 찬성하기147\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "HugaGage\n",
      "2017.09.26. 23:01\n",
      "반드시 지켜야한다\n",
      "댓글 찬성하기145\n",
      "댓글 비추천하기5\n",
      "-----\n",
      "구라왕\n",
      "2017.09.26. 23:04\n",
      "국회의원도 참여해라\n",
      "댓글 찬성하기138\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "happywon\n",
      "2017.09.26. 23:04\n",
      "우리 모두 청탁없는 깨끗한 사회 만듭시다. 3/5/10도   2/3/5으로 줄입시다.\n",
      "댓글 찬성하기112\n",
      "댓글 비추천하기3\n",
      "-----\n",
      "하림\n",
      "2017.09.26. 23:02\n",
      "받은개들 전부 쏴주겨라\n",
      "댓글 찬성하기76\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "SimonRyu\n",
      "2017.09.26. 23:10\n",
      "학교가 깨끗해지고 있다.\n",
      "\n",
      "이젠 학생들이 주는 커피나 음료 절대 안 받는다.\n",
      "\n",
      "예전엔 성의라고 받아 주었으나 이젠 안받아도 될 김영란법이 있어서 좋다.\n",
      "\n",
      "계속 이렇게 가자! 너무 좋다.\n",
      "댓글 찬성하기52\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "다중이\n",
      "2017.09.26. 23:09\n",
      "위에서 아래로주는건 선물\n",
      "아래서 위로주는건  뇌물\n",
      "댓글 찬성하기44\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "iyoulike\n",
      "2017.09.26. 23:06\n",
      "김영란법이후로 학부모 상담 갈때 부담이 사라졌습니다. 예의상 뇌물이 아닌 선물로  쿠키 한상자라도 들고 가야하나 늘 마음이 불편했습니다. 전 직장인으로써도 좋습니다. 정이라고 자꾸 들어오는 커피.빵..간식들 부담스러웠네요..이제 시작인데 없어지면 안됩니다\n",
      "댓글 찬성하기42\n",
      "댓글 비추천하기2\n"
     ]
    }
   ],
   "source": [
    "for e in commentInfo:\n",
    "    print \"-----\"\n",
    "    print e.find(\"a\",{\"class\":\"link_nick clickable\"}).text\n",
    "    print e.find(\"span\",{\"class\":\"txt_date\"}).text\n",
    "    print e.find(\"p\",{\"class\":\"desc_txt\"}).text\n",
    "    print e.find(\"button\",{\"class\":\"#like\"}).text\n",
    "    print e.find(\"button\",{\"class\":\"#dislike\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
