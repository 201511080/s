{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 웹 데이터 추출\n",
    "\n",
    "* Last updated: 20170917 20170401 20161004\n",
    "\n",
    "## 1.1 학습내용\n",
    "\n",
    "### 1.1.1 목표\n",
    "\n",
    "* 웹에서 가져온 페이지를 파싱할 수 있다.\n",
    "* 웹페이지에서 xpath, css selector를 사용하여 데이터를 추출할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.2 목차\n",
    "\n",
    "* 1.2 Parsing\n",
    "* 1.3 javascript console\n",
    "* 1.3.1 브라우저에서 Javascript concole 창 열기\n",
    "* 1.3.2 Console 창에서 selector 찾기¶ \n",
    "* 1.3.3 Elements 창에서 selector 찾기\n",
    "* 1.4 dom \n",
    "* 1.5 BeautifulSoup\n",
    "* 1.5.1 설치\n",
    "* 1.5.2 BeautifulSoup 객체\n",
    "* 1.5.3 태그 객체\n",
    "* 1.5.4 문자열 객체\n",
    "* 1.5.5 Comment 객체\n",
    "* 1.5.6 찾기\n",
    "* 1.6 regex\n",
    "* 1.6.1 문자, 순자 추출해 보기\n",
    "* 1.6.2 BeautifulSoup과 같이 regex를 사용\n",
    "* --- \n",
    "* 1.7 xpath\n",
    "* 1.7.1 lxml\n",
    "* 1.7.2 파일에서 파싱\n",
    "* 1.7.2 문자열에서 파싱\n",
    "* 1.8 css selectors\n",
    "* 1.8.1 html에서 css \n",
    "* 1.8.2 lxml을 사용해서 하기\n",
    "* 1.8.3 BeautifulSoup을 사용해서 하기\n",
    "* 1.8.4 테이블을 읽기\n",
    "* 1.9 동적 페이지에서 데이터 수집\n",
    "* 1.9.1 동적 페이지\n",
    "* 1.9.2 Selenium\n",
    "* 1.9.3 간단한 명령어\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.3 문제\n",
    "\n",
    "* 문제 웹데이터-1: python.org 페이지가 가지고 있는 최근 뉴스 출력하기\n",
    "* 문제 웹데이터-2: python.org 페이지를 크롤링해서 http url를 출력하기\n",
    "    * BeautifulSoup, regex, xpath, css selector\n",
    "* 문제 웹데이터-3: 위키에서 'python'을 검색해서 http url을 출력하기\n",
    "    * 위키에서 검색하기, 위키에서 css selector\n",
    "* 문제 웹데이터-4: 한국 포털사이트에서 노래 제목을 검색해서 가져오기\n",
    "    * regex, lxml css selector - 노래제목, 아티스트, 앨범 출력\n",
    "* 문제 웹데이터-5: 국제학회 목록을 가져오기\n",
    "    * lxml css.selector, Scrapy에서 연속 추출\n",
    "* 문제 웹데이터-6: 한국 프로야구 팀순위 가져오기\n",
    "    * kbreport.com, regex 단순 문자열 검색, xpath\n",
    "* 문제 웹데이터-7: 로그인이 필요한 사이버강의실에서 강의계획서를 가져오기\n",
    "* 문제 웹데이터-8: 한국 프로야구 선수 기록 크롤링하기 (1)\n",
    "* 문제 웹데이터-9: 한국 프로야구 선수 기록 크롤링하기 (2)\n",
    "* 문제 웹데이터-10: 다음에서 환율 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.4 연습\n",
    "\n",
    "* 연습 웹데이터-1: UC Irvine 기계학습 데이터\n",
    "* 연습 웹데이터-2: 기상청 도별 날씨 가져오기기\n",
    "* 연습 웹데이터-3: 국가통계 가져오기\n",
    "* 연습 웹데이터-4: 신문 크롤링 해보기\n",
    "* 연습 웹데이터-5: 영화 리뷰의 분석\n",
    "* 한글 https://wiki.python.org/moin/PrintFails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Parsing\n",
    "\n",
    "파싱은 입력데이터를 자료구조로 변환하는 것을 말한다. 우리가 말하는 문장은 주어, 목적어, 동사와 같은 문법구조로 파싱할 수 있다. 웹데이터도 자료구조, 보통 '트리' 구조로 변환해서 원하는 항목을 추출할 수 있다.\n",
    "\n",
    "* 웹데이터는 '문자'이다. 앞 서 설명한 바와 같이 '숫자'도 문자로 인식된다.\n",
    "* 파싱을 하지 않으면, 태그를 추출하기 위해서는 문자 하나 하나씩 처리해야 하기 때문에 많은 노력이 필요하다.\n",
    "* 예를 들어 ```<h1>...</h1>```은 부등호문자,h,1과 같은 문자로 구성된 것으로 간주한다.\n",
    "* 따라서 시작태그, 끝태그를 찾으려면 꽤 복잡한 처리과정이 필요하다.\n",
    "* 요약하면, 웹데이터는 문자로 만들어져 있고 태그구조를 가지고 있지만, 태그를 처리하기 용이한 tree구조를 만들어야 한다는 점에 유의한다.\n",
    "* 파싱을 하면, 이런 태그 요소를 분리하고, tree구조로 만들어 분석을 용이하게 할 수 있다.\n",
    "* HTML DOM, XML, json은 tree 구조를 가지고, 특정 요소를 선택할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 프로그램에서 하는 일을 단계 별로 살펴보자. 우선 파서를 선택하고, html을 읽어서 tree구조로 변환한 후, 필요한 데이터항목을 추출하는 다음 과정을 실행한다.\n",
    "\n",
    "단계 | 작업절차 | BeautifulSoup 예 | lxml 예\n",
    "-----|-----|-----|-----\n",
    "단계 1 | 사용하려는 파서 선택 | from bs4 import BeautifulSoup | import lxml.etree\n",
    "단계 2 | 페이지를 파싱하고, 트리를 생성한다 | soup=BeautifulSoup('my.html') | tree=lxml.etree.parse('my.html')\n",
    "단계 3 | 트리에서 필요한 요소를 정한다. | 태그, 클래스... | 좌동\n",
    "단계 4 | 필요한 요소를 가져온다. | soup.select() | tree.xpath() 또는 tree.css()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"465px\" style=\"width:303px;height:465px;\" version=\"1.1\" viewBox=\"0 0 303 465\" width=\"303px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><filter height=\"300%\" id=\"f1\" width=\"300%\" x=\"-1\" y=\"-1\"><feGaussianBlur result=\"blurOut\" stdDeviation=\"2.0\"/><feColorMatrix in=\"blurOut\" result=\"blurOut2\" type=\"matrix\" values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0\"/><feOffset dx=\"4.0\" dy=\"4.0\" in=\"blurOut2\" result=\"blurOut3\"/><feBlend in=\"SourceGraphic\" in2=\"blurOut3\" mode=\"normal\"/></filter></defs><g><ellipse cx=\"150\" cy=\"18\" fill=\"#000000\" filter=\"url(#f1)\" rx=\"10\" ry=\"10\" style=\"stroke: none; stroke-width: 1.0;\"/><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"158\" x=\"71\" y=\"68\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"138\" x=\"81\" y=\"89.1387\">stage 1: import library</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"175\" x=\"62.5\" y=\"142\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"155\" x=\"72.5\" y=\"163.1387\">stage 2: get html strings</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"243\" x=\"28.5\" y=\"216\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"223\" x=\"38.5\" y=\"237.1387\">stage 3: transform strings to a tree</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"182\" x=\"59\" y=\"290\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"162\" x=\"69\" y=\"311.1387\">stage 4: define a selector</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"288\" x=\"6\" y=\"364\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"268\" x=\"16\" y=\"385.1387\">stage 5: get selected elements of the tree</text><ellipse cx=\"150\" cy=\"448\" fill=\"none\" filter=\"url(#f1)\" rx=\"10\" ry=\"10\" style=\"stroke: #000000; stroke-width: 1.0;\"/><ellipse cx=\"150.5\" cy=\"448.5\" fill=\"#000000\" rx=\"6\" ry=\"6\" style=\"stroke: none; stroke-width: 1.0;\"/><path d=\"M150,28.038 C150,36.932 150,50.844 150,62.572 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,67.781,154,58.781,150,62.781,146,58.781,150,67.781\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,102.338 C150,112.464 150,125.584 150,136.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,141.727,154,132.727,150,136.727,146,132.727,150,141.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,176.338 C150,186.464 150,199.584 150,210.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,215.727,154,206.727,150,210.727,146,206.727,150,215.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,250.338 C150,260.464 150,273.584 150,284.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,289.727,154,280.727,150,284.727,146,280.727,150,289.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,324.338 C150,334.464 150,347.584 150,358.5432 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,363.7267,154,354.7267,150,358.7267,146,354.7267,150,363.7267\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,398.0674 C150,408.5986 150,422.2536 150,432.4618 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,437.7367,154,428.7367,150,432.7367,146,428.7367,150,437.7367\" style=\"stroke: #A80036; stroke-width: 1.0;\"/></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%plantuml\n",
    "@startuml\n",
    "(*)--> \"stage 1: import library\"\n",
    "--> \"stage 2: transform web page string to a tree\"\n",
    "--> \"stage 3: define a selector\"\n",
    "--> \"stage 4: get selected elements of the tree\"\n",
    "-->(*)\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* parsing 관련 라이브러리\n",
    "    * HTMLParser - Python에서 기본으로 제공\n",
    "    * BeautifulSoup - lxml을 사용해서 구현된 parser (css는 지원하지만 XPath 지원하지 않는다.)\n",
    "    * lxml - C로 구현되어서 빠르다. 단독 또는 BeautifulSoup에서 사용할 수 있다. xml, html 파싱을 할 수 있다.\n",
    "    * regex - tree를 만들지 않는다. 패턴으로 parsing.\n",
    "    * pyquery - jquery와 같은 기능의 라이브러리\n",
    "    * scrapy - 프레임워크로 대규모 프로젝트에 적합하다. 파이프라인pipelines을 사용하므로 빠르다.\n",
    "\n",
    "구분 | 라이브러리 | 설명\n",
    "-----|-----|-----\n",
    "웹데이터 수집 | urllib, requests, curl | 웹페이지 열고, http request(s), http response(s)\n",
    "웹데이터 파싱 | HTMLParser, BeautifulSoup, lxml, regex | 문자열 또는 xml, json을 파싱\n",
    "프레임워크 | scrapy (java nutch, crawler4j) | 큰 프로젝트에 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3 Javascript console\n",
    "\n",
    "파싱을 하려면 HTML 소스를 펼쳐 놓고, '요소' 즉 element를 찾아야 편리하다. Chrome 개발자 도구를 이용하면 찾기 편리하다. 구글 사이트에 사용법이 자세하게 설명되어 있다 https://developers.google.com/web/tools/chrome-devtools/console/. 이 창에서 css selector를 테스트하고 프로그램에 넣으면 편리하다.\n",
    "\n",
    "### 1.3.1 브라우저에서 Javascript concole 창 열기\n",
    "\n",
    "브라우저 | 콘솔창\n",
    "-----|-----\n",
    "Chrome | 브라우저 우측 상단 메뉴 > More tools > Developer Tools 또는 F12\n",
    "Internet Explorer | F12\n",
    "Firefox | Tools > Web Developer > Inspector\n",
    "Safari | advanced preferences > enable Develop menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3.2 Javascript console 창에서 selector 찾기\n",
    "\n",
    "콘솔창에서 javascript를 사용하여 selector를 추출할 수 있다.\n",
    "xpath는 ```$x()```, css selecotr는 ```$()```를 사용한다.\n",
    "\n",
    "단축키 | 설명\n",
    "-----|-----\n",
    "\\$x('xpath') | XPath와 일치하는 요소의 배열을 반환\n",
    "\\$('selector') | CSS 선택기와 일치하는 첫 번째 요소를 반환, document.querySelector()의 단축\n",
    "\\$$('selector all') | CSS 선택기와 일치하는 모든 요소의 배열을 반환, document.querySelectorAll()의 단축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* HTML title을 xpath, css로 추출하는 예이다. selector 텍스트를 추출하려면 'innerText'를 사용한다.\n",
    "\n",
    "선택 | xpath | css\n",
    "-----|-----|-----\n",
    "title태그 선택 | ```$x('//head/title') 또는 $x('//title')``` | ```$$('title')```\n",
    "선택의 결과가 복수인 경우, 배열을 반환 | ```$x('//head/title')[0]``` | ```$$('title')[0]```\n",
    "태그의 문자열을 추출 | ```$x('//head/title')[0].innerText``` | ```$$('title')[0].innerText```\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3.3 Elements 창에서 selector 찾기\n",
    "\n",
    "'Elements' 메뉴에서 xpath 또는 selector를 사용할 수 있다.\n",
    "\n",
    "* html소스에서\n",
    "    * html tag를 누르면 맨 앞 '...'가 생김\n",
    "    * 이것을 누르면 팝업메뉴가 뜬다. 그리고 copy > xpath(또는 selector)를 선택하여 복사\n",
    "* 또는 단축키 ```<ctrl-f>```로 '검색'창을 열고 검색 문자열, xpath, selector를 입력한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4 dom\n",
    "\n",
    "* HTML을 파싱해서 tree구조로 변환할 수 있다.\n",
    "* 이러한 html tree구조를 DOM, Document Object Model이라고 한다.\n",
    "* DOM의 각 노드는 html의 태그가 되고, 이를 읽어오고 쓰는 기능 API를 제공한다.\n",
    "* DOM에서 특정 노드를 선택해 몇 가지 쉬운 기능을 사용해보자.\n",
    "* document.querySelector()를 사용해 '.my'라는 클래스를 선택한다. 앞의 점이 class를 의미한다.\n",
    "    * h2태그의 배경색을 파란색으로 변경하는 기능이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h2 class=\"my\">Turn this into blue</h2>\n",
       "<button onclick=\"myFunction()\">Click</button>\n",
       "<script>\n",
       "    function myFunction() {\n",
       "        document.querySelector(\".my\").style.backgroundColor = \"blue\";\n",
       "    }\n",
       "</script>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<body>\n",
    "<h2 class=\"my\">Turn this into blue</h2>\n",
    "<button onclick=\"myFunction()\">Click</button>\n",
    "<script>\n",
    "    function myFunction() {\n",
    "        document.querySelector(\".my\").style.backgroundColor = \"blue\";\n",
    "    }\n",
    "</script>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* document.getElementById()를 사용해 p2라는 명칭을 선택한다. \n",
    "    * id가 p2인 ```<p>```태그를 빨간새으로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
       "    <p id=\"p2\">Hello World!</p>\n",
       "    <script>\n",
       "        document.getElementById(\"p2\").style.color = \"RED\";\n",
       "    </script>\n",
       "    <p>Hello World turned into RED!</p>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<body>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.5 BeautifulSoup\n",
    "\n",
    "BeautifulSoup은 Python에서 사용하는 html, xml 파서이다. Java로 만들어진 jsoup도 유사한 기능을 가지고 있다. 이전 버전은 더 이상 지원되지 않으므로, 버전은 4로 한다.\n",
    "\n",
    "### 1.5.1 설치\n",
    "\n",
    "명령창에서 pip로 설치한다. 'sudo'는 관리자 권한이다. 윈도우 Anaconda는 기본 설치되어 있다.\n",
    "```\n",
    "pip install beautifulsoup4 (beautifulsoup은 버전3을 설치한다)\n",
    "```\n",
    "\n",
    "Linux Ubuntu에서 apt를 사용하여 설치할 수 있다.\n",
    "```\n",
    "apt install python-bs4 (Python 2을 사용하는 경우)\n",
    "apt install python3-bs4 (Python 3을 사용하는 경우)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파서를 넣어주지 않으면 기본 파서를 사용한다.\n",
    "\n",
    "파서 | 설치 | 설정\n",
    "-----|-----\n",
    "html.parser | Python에 내장 | BeautifulSoup(markup, \"html.parser\")\n",
    "lxml parser | C로 만든 파서, 별도 설치가 필요 | BeautifulSoup(markup, \"lxml\")\n",
    "\n",
    "* Linux Ubuntu에서 'lxml' 설치\n",
    "```\n",
    "apt-get install python-lxml\n",
    "```\n",
    "\n",
    "* 파이썬 패키지 저장소에서 'lxml' 설치\n",
    "```\n",
    "pip install lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* BeautifulSoup은 html을 DOM으로 변환하여, 다음 4가지 객체를 생성하여 활용한다.\n",
    "\n",
    "객체 | 설명\n",
    "-----|-----\n",
    "BeautifulSoup | html을 DOM으로 변환한 문서 전체를 말한다. 아래 'soup' 이다.\n",
    "Tag | html 태그이다. 태그명, 태그속성, 태그의 텍스트를 가지고 있다.\n",
    "NavigableString | Python에서 사용하는 unicode 문자열과 유사하지만, 몇 가지 추가되는 기능을 제공한다.\n",
    "Comment | html comment, 도움말을 뜻한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.2 BeautifulSoup 객체\n",
    "\n",
    "* BeautifulSoup 라이브러리를 from ... import ... 호출방식으로 사용한다.\n",
    "* 예를 들어 my.py에서 x.py를 호출한다고 하자.\n",
    "    * (1) x.py가 import y를 가지고 있다고 하자.\n",
    "    * (2) my.py에서 x.py는 import mylib.x라고 불러 사용할 수 있다.\n",
    "    * (3) 그러면 x.py에서 가지고 있는 import y는 오류가 된다. 즉, 상대호출이라서 from mylib import y로 변경해 주어야 맞다.\n",
    "\n",
    "```\n",
    "my.py      # (2) 여기서 x.py를 호출하려면 import mylib.x는 오류(x) \n",
    "mylib\\\n",
    "      x.py   # (1) 여기 import y를 가지고 있다고 하자. (3) import y -> from mylib import y (o)\n",
    "      y.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_html=\"\"\"<html>\n",
    "<body>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(_html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[document]'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <b>\n",
      "   <!--This page is to show how to use BeautifulSoup-->\n",
      "  </b>\n",
      "  <p id=\"p2\">\n",
      "   Hello World!\n",
      "  </p>\n",
      "  <script>\n",
      "   document.getElementById(\"p2\").style.color = \"RED\";\n",
      "  </script>\n",
      "  <p>\n",
      "   Hello World turned into RED!\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.3 태그 객체\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "soup.p | dot 연산자를 사용해 태그를 읽을 수 있다. 태그 자체를 읽으며 여러 개가 있더라도 처음 태그를 읽어 온다.\n",
    "soup.p.attrs | 태그의 속성을 dictionary 구조로 읽는다.\n",
    "soup.p['id'] | 태그의 속성을 dictionary 구조로 []괄호를 사용하여 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n",
      "{u'id': u'p2'}\n",
      "p2\n"
     ]
    }
   ],
   "source": [
    "print soup.p\n",
    "print soup.p.attrs\n",
    "print soup.p['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<b><!--This page is to show how to use BeautifulSoup--></b>\n",
      "<p id=\"p2\">Hello World!</p>\n",
      "<script>\n",
      "        document.getElementById(\"p2\").style.color = \"RED\";\n",
      "    </script>\n",
      "<p>Hello World turned into RED!</p>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "print soup.p.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.4 문자열 객체\n",
    "\n",
    "* 태그의 텍스트를 '.string'으로 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup.p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print soup.p.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.5 Comment 객체\n",
    "\n",
    "html 문서에 도움말을 넣을 경우, <!–– 도움말 ––> 태그를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Comment'>\n",
      "This page is to show how to use BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "print type(soup.b.string)\n",
    "print soup.b.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.6 찾기\n",
    "\n",
    "find() 또는 find_all() 함수를 사용한다.\n",
    "조건은 함수 인자에 적는다. 태그명, 태그속성을 '=' 또는 dictionary 형식으로 적는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n"
     ]
    }
   ],
   "source": [
    "print soup.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n"
     ]
    }
   ],
   "source": [
    "print soup.find(\"p\",id=\"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "Hello World!\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "p2tag=soup.find(\"p\", {\"id\":\"p2\"})\n",
    "print type(p2tag)\n",
    "print p2tag.text\n",
    "print p2tag.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-1: python.org 페이지가 가지고 있는 최근 뉴스 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "크롤링하려는 'www.python.org'는 파이썬 언어에서 운영하는 홈페이지이므로 자주 방문한게 된다.\n",
    "여기서 이 페이지가 포함하는 '최신 뉴스'를 알아보려고 한다.\n",
    "문제를 풀기 전에 'python.org'를 웹브라우저에서 방문한다.\n",
    "'Latest News'를 찾고 그 아래 뉴스를 읽어본다.\n",
    "\n",
    "### 풀이\n",
    "\n",
    "BeautifulSoup을 사용하여 html을 DOM으로 파싱하고, 원하는 태그를 찾는다.\n",
    "우선 '소스보기'에서 원하는 태그를 찾아서, 그 태그를 조건으로 넣어야 편리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "page=r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 원하는 태그를 찾으면, class 'blog-widget'이라는 것을 알 수 있다.\n",
    "* class 다음에는 _를 넣어 준다. 또는 key-value 형식으로 맞추어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news=soup.find(\"div\", class_=\"blog-widget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-16T21:58:00.000005+00:00\n"
     ]
    }
   ],
   "source": [
    "print news.li.time['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest bugfix release in the Python 2.7 series, Python ...\n"
     ]
    }
   ],
   "source": [
    "print news.li.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>\\n<time datetime=\"2017-09-16T21:58:00.000005+00:00\"><span class=\"say-no-more\">2017-</span>09-16</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/3SUhDRzB1-s/python-2714-released.html\">The latest bugfix release in the Python 2.7 series, Python ...</a></li>, <li>\\n<time datetime=\"2017-09-07T00:13:00.000003+00:00\"><span class=\"say-no-more\">2017-</span>09-07</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/pUndlLcEcKE/python-337rc1-is-now-available-prior-to.html\">Python 3.3.7rc1 is now available, the release candidate of Python ...</a></li>, <li>\\n<time datetime=\"2017-08-27T03:41:00.000006+00:00\"><span class=\"say-no-more\">2017-</span>08-27</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/pe2Ug4MA0Lg/python-2714-release-candidate-1.html\">The first release candidate for Python 2.7.14 is now available ...</a></li>, <li>\\n<time datetime=\"2017-08-09T07:34:00.000002+00:00\"><span class=\"say-no-more\">2017-</span>08-09</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/vY72b719CGk/python-354-and-python-347-are-now.html\">Python 3.5.4 and Python 3.4.7 are now available for download. ...</a></li>, <li>\\n<time datetime=\"2017-07-25T08:40:00.000001+00:00\"><span class=\"say-no-more\">2017-</span>07-25</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/ry7faTWPZiY/python-354rc1-and-python-347rc1-are-now.html\">Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...</a></li>]\n"
     ]
    }
   ],
   "source": [
    "print news.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 지금까지 찾은 항목을 for 문으로 모두 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-16T21:58:00.000005+00:00 The latest bugfix release in the Python 2.7 series, Python ...\n",
      "2017-09-07T00:13:00.000003+00:00 Python 3.3.7rc1 is now available, the release candidate of Python ...\n",
      "2017-08-27T03:41:00.000006+00:00 The first release candidate for Python 2.7.14 is now available ...\n",
      "2017-08-09T07:34:00.000002+00:00 Python 3.5.4 and Python 3.4.7 are now available for download. ...\n",
      "2017-07-25T08:40:00.000001+00:00 Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...\n"
     ]
    }
   ],
   "source": [
    "for e in news.find_all(\"li\"):\n",
    "    print e.time[\"datetime\"], e.a.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  48768\n",
      "2017-09-16T21:58:00.000005+00:00 The latest bugfix release in the Python 2.7 series, Python ...\n",
      "2017-09-07T00:13:00.000003+00:00 Python 3.3.7rc1 is now available, the release candidate of Python ...\n",
      "2017-08-27T03:41:00.000006+00:00 The first release candidate for Python 2.7.14 is now available ...\n",
      "2017-08-09T07:34:00.000002+00:00 Python 3.5.4 and Python 3.4.7 are now available for download. ...\n",
      "2017-07-25T08:40:00.000001+00:00 Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_1_readPythonOrgBS.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readLatestNews():\n",
    "    try:\n",
    "        r = requests.get(u'http://python.org/')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    page=r.text\n",
    "    print \"length: \",len(page)\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    news=soup.find(\"div\", class_=\"blog-widget\")\n",
    "    for e in news.find_all(\"li\"):\n",
    "\tprint e.time[\"datetime\"], e.a.string\n",
    "\n",
    "def main():\n",
    "    readLatestNews()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 추가문제: \"Use Python for..\"를 수집해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.6 regex\n",
    "\n",
    "* 정규식 regular expression은 문자열로 표현한 정규표현으로, 패턴매칭에 사용한다.\n",
    "* 정규식을 사용하면 복잡한 패턴을 단순하게 처리할 수 있다.\n",
    "* 정규식은 메타문자를 사용한다. 역슬래시와 결합하여 특별한 의미를 가진다. 예를 들어, d는 역슬래시와 결합하여 숫자를, s는 공백을 의미한다.\n",
    "\n",
    "정규식 | 설명 | 예\n",
    "-----|-----|-----\n",
    "() | grouping | (\\d{1,2})\n",
    "\\d | any character in the range 0-9 |\n",
    "\\s | any whitespace |\n",
    "\\w | any character in the range 0-9, A-Z, a-z |\n",
    "[] | a signle character | [a-cx-z] = \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\"\n",
    "\\- | range separator | [0123456789] = [0-9]\n",
    "\\* | the preceding element zero or more times | ab*c = \"ac\", \"abc\", \"abbbc\"\n",
    "\\+ | the preceding element one or more times  | ba+ = \"ba\", \"baa\", \"baaa\", and so on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.6.1 문자, 순자 추출해 보기\n",
    "\n",
    "* 정규식을 사용하면 문장에서 숫자, 문자를 편리하게 추출할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자와 문자:  ['Here', 'goes', 'my', 'phone', 'number', '2287', '1111', 'Nice', 'to', 'meet', 'you', 'Merry', 'Christmas']\n",
      "숫자:  ['2287', '1111']\n",
      "대문자를 가진 단어:  ['Here', 'Nice', 'Merry', 'Christmas']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence=\"Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas\"\n",
    "regex1='\\w+'\n",
    "print \"숫자와 문자: \",re.findall(regex1, sentence)\n",
    "regex2='\\d+'\n",
    "print \"숫자: \",re.findall(regex2, sentence)\n",
    "regex3 = '[A-Z]\\w+'\n",
    "print \"대문자를 가진 단어: \",re.findall(regex3, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 정규식을 사용하여 태그를 찾을 수 있다.\n",
    "* a태그의 문자열을 읽어 본다.\n",
    "    * a태그의 패턴을 정하고,\n",
    "    * 그 안의 모든 문자 '.*'를 '()'그룹으로 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tag:  ['foo']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tags='<html><body><div>asdfasdf</div><p><a>foo</a></p></body></html>'\n",
    "regex=\"<a>(.*)</a>\"\n",
    "print \"a tag: \",re.findall(regex, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.6.2 BeautifulSoup과 같이 regex를 사용\n",
    "\n",
    "* 패턴을 가지고 있는 태그의 문자열을 찾을 수 있다.\n",
    "* 패턴을 가지고 있는 태그, 속성을 검색할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup import BeautifulSoup\n",
    "import re\n",
    "\n",
    "htmlstr = \"\"\"\n",
    "<p>Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas</p>\n",
    "<p>this is text</p2>\n",
    "<a href=\"https://www.example.com\">Visit example.com</a>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(htmlstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tag:  <p>Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas</p>\n",
      "text:  Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas\n"
     ]
    }
   ],
   "source": [
    "for e in soup(text=re.compile(r'\\d+')):\n",
    "    print \"tag: \", e.parent\n",
    "    print \"text: \", e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit example.com\n"
     ]
    }
   ],
   "source": [
    "for e in soup.findAll(href=re.compile(\"ex\")):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.7 xpath\n",
    "\n",
    "xpath는 XML Path Language의 약어로 xml문서를 트리구조로 표현하고, 노드를 선택하기 위해 사용하는 조회언어이다.\n",
    "\n",
    "* xpath 표현\n",
    "\n",
    "Expression | 설명 | 예\n",
    "---------|----------|----------\n",
    "/ | root부터 선택 | ```$x('/html')``` 루트에 있는 html 선택\n",
    "// | 어디에 있는지 상관없이 선택 | ```$x('//div')``` 어디에 있든 div 선택 \n",
    ". | Selects the current node | \n",
    ".. | Selects the parent of the current node | \n",
    "@ | Selects attributes | //@href 속성href를 가진 모든 노드\n",
    "\\* | all |\n",
    "@* | 속성 모두 | //div[@*] 속성을 가지고 있는 모든 div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.1 lxml\n",
    "\n",
    "lxml은:\n",
    "* lxml.etree는 XML을 파싱한다. 그러나 HTMLParsor()를 사용하면 html을 파싱할 수 있다.\n",
    "* lxml.html는 HTML을 파싱할 경우 사용한다.\n",
    "\n",
    "BeautifulSoup은 xpath를 지원하지 않는다.\n",
    "실행하는 단계는 다른 라이브러리를 사용하는 단계와 다르지 않다.\n",
    "불완전한 태그일 경우 오류가 발생할 수 있다는 점에 주의한다.\n",
    "\n",
    "구분 | 파싱 | 설명 | 읽는 함수\n",
    "-----|-----|-----|-----\n",
    "lxml.etree | XML | c로 구현해서 빠르다. HTMLParsor()파서를 선택하면 HTML을 파싱할 수 있다. | 파일에서 읽기 parse()<br>문자열에서 읽기 fromstring() (단 html은 XML로 인식하기 때문에 HTML()함수를 사용한다.)\n",
    "lxml.html | HTML | Python으로 구현 | 상동\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* lxml.etree에서 HTML을 파싱하려면 HTMLParser()를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "parser=lxml.etree.HTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.2 파일에서 파싱\n",
    "\n",
    "* 파일에서 읽으므로 parse() 함수를 사용한다.\n",
    "* 디렉토리로부터 파일을 읽을 경우, os.path.join()을 사용한다. 앞서 설명한 바와 같이 디렉토리 구분자로 인한 오류를 제거할 수 있다.\n",
    "```<meta>``` 태그는'시작'은 있고, '끝' 태그가 없어 오류가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tree=lxml.etree.parse(os.path.join('src','mypage2.html'),parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* getiterator()는 모든 태그를 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 태그: html -> \n",
      "\n",
      "- 태그: head -> \n",
      "\n",
      "- 태그: meta -> None\n",
      "- 태그: title -> My Home Page\n",
      "- 태그: body -> \n",
      "\n",
      "- 태그: h1 -> 안녕하십니까\n",
      "- 태그: p -> 오늘은 프로그래밍 하는 날...\n",
      "- 태그: p -> Today we do programming...\n"
     ]
    }
   ],
   "source": [
    "for node in tree.getiterator():\n",
    "    print \"- 태그:\", node.tag, \"->\", node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.2 문자열에서 파싱\n",
    "\n",
    "* html 문자열을 파싱한다. 문자열은 파일에서 읽어서 만든다.\n",
    "* 'mypage2.html'은 meta 태그를 포함하고 있어, 오류가 발생한다는 점 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 태그: html {}\n",
      "- 태그: body {}\n",
      "- 태그: h1 {}\n",
      "- 태그: b {}\n",
      "- 태그: <cyfunction Comment at 0x7f6cc97cf590> <lxml.etree._ImmutableMapping object at 0x7f6cc97a1790>\n",
      "- 태그: p {'id': 'p2'}\n",
      "- 태그: script {}\n",
      "- 태그: p {}\n"
     ]
    }
   ],
   "source": [
    "import lxml.etree\n",
    "_html=\"\"\"<html>\n",
    "<body>\n",
    "    <h1>안녕하세요</h1>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "tree=lxml.etree.fromstring(_html)\n",
    "for node in tree.getiterator():\n",
    "    print \"- 태그:\", node.tag, node.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 트리구조로 만드는 작업을 하고 난 후 xpath를 사용할 수 있다.\n",
    "* xpath를 사용하여 h1 태그의 문자열을 읽는다.\n",
    "* unicode값이 반환된다. 또한 배열로 만들어져 있다는 점에 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\uc548\\ub155\\ud558\\uc138\\uc694']\n"
     ]
    }
   ],
   "source": [
    "tree=lxml.etree.fromstring(_html)\n",
    "print tree.xpath('//h1/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요\n"
     ]
    }
   ],
   "source": [
    "print tree.xpath('//h1/text()')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.8 css selectors\n",
    "\n",
    "CSS는 html의 스타일을 정하는 규칙을 가지고 있다. 스타일 태그의 선택자 selector를 사용하여, 원하는 태그를 추출할 수 있다.\n",
    "\n",
    "* [css selectors](http://www.w3schools.com/cssref/css_selectors.asp)\n",
    "\n",
    "selector | css | 설명 | xpath\n",
    "------------|------------|------------|------------\n",
    "[attribute] | $$('input[type=\"email\"]') | input type을 선택 | $x('//input[@type=\"email\"]')\n",
    "type | 'div' 'a' | div 태그, a 태그 | '//div' '//a'\n",
    "class | '.foo' | class 속성이 foo를 선택 | '//*[@class=\"foo\"]'\n",
    "id | '#foo' | id foo (1개만 선택. 클래스는 여러 개 선택) | '//*[@id=\"foo\"]'\n",
    "universal | '*' | all | '//*'\n",
    "descendents | 'div a' | all a's inside div (여러 세대 떨어져도 선택) | '//div//a' \n",
    "child | 'div > a' | a's only children to the div (1세대 다음) | '//div/a'\n",
    "parents | a ~ b | any parents of b (여러 세대 위) |\n",
    "grouped | 'h1, h2' | 'h1 h2' |\n",
    "text | 'a::text' | 선택한 노드, element의 text.<br>javascript console에서는 'innerText' | '//a/text()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.8.1 html에서 css\n",
    "\n",
    "css는 Cascading Style Sheets, html문서의 스타일을 설정한다. html 색, 폰트 등 어떻게 보여지는지를 정한다. 아래는 css를 html에 넣어서 태그의 스타일을 설정하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/mypage3.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/mypage3.html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>My Home Page</title>\n",
    "    <style>\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            color:red;\n",
    "            font-family: 'Droid Sans', sans-serif;\n",
    "        };  \n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>안녕하십니까</h1>\n",
    "    <p>오늘은 프로그래밍 하는 날...</p>\n",
    "    <p>Today we do programming...</p>\n",
    "\n",
    "    <div id=\"divid\">\n",
    "        <h2>Hello h2</h2>\n",
    "        <p>Here we use div id.</p>\n",
    "        <a href=\"https://www.example.com\">Visit example.com</a>\n",
    "    </div>\n",
    "    <div class=\"divclass\">\n",
    "        <h2>Welcome</h2>\n",
    "        <p>Here we use div class.</p>\n",
    "        <ul>\n",
    "            <li>first</li>\n",
    "            <li>second</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "\n",
    "    <form action=\"\">\n",
    "    Email <input type=\"email\" value=\"emailvalue\" name=\"emailname\" id=\"emailid\"\n",
    "        class=\"emailclass\" style=\"background-color: green;\"required>\n",
    "    Zip Code <input type=\"number\" name=\"zipname\" required>\n",
    "    <textarea rows=\"4\" columns=\"50\"></textarea>\n",
    "    <input type=\"submit\" value=\"Submit\">\n",
    "    </form>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.8.2 lxml을 사용해서 하기\n",
    "\n",
    "* lxml.html을 사용한다. lxml.html은 파이썬으로 만들어졌다.\n",
    "* cssselect 라이브러리가 없는 경우에는 pip를 사용해서 설치한다.\n",
    "```\n",
    "pip install lxml cssselect\n",
    "```\n",
    "\n",
    "* 리눅스에서는 xml라이브러리가 필요하다.\n",
    "```\n",
    "sudo apt-get install libxml2-dev libxslt1-dev\n",
    "pip install lxml cssselect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* lxml은 broken html을 처리할 수 있다. 시작-끝 태그로 구성되지 않은 meta 태그가 오류 없이 처리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "htmlstr=\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>My Home Page</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>안녕하십니까</h1>\n",
    "<p>오늘은 프로그래밍 하는 날...</p>\n",
    "<p>Today we do programming...</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "tree = lxml.html.fromstring(htmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* nth-child(2)는 부모의 2번째 child를 선택한다. 부모 body의 2번째 p 태그이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body :nth-child(1)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘은 프로그래밍 하는 날...\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body :nth-child(2)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body h1'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.8.3 BeautifulSoup을 사용해서 하기\n",
    "\n",
    "BeautifulSoup도 css selector를 지원한다. 사용하는 방법은 lxml과 유사하다. 같이 비교하면서 사용해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(htmlstr,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in soup.select('body h1'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.8.4 테이블을 읽기\n",
    "\n",
    "테이블은 데이터를 행과 열로 표현하는 방식으로, 웹페이지에서 자주 사용되고 있다.\n",
    "\n",
    "아래와 같이 table은 헤더(thead)와 내용(tbody)으로 구분하고 있다.\n",
    "경우에 따라 tbody는 생략할 수 있다. thead가 없는 경우 또는 tbody 다음 첫 줄이 tr인 경우가 그렇다.\n",
    "css selector를 사용하면 행은 'tr', 셀은 'td'로 검색한다.\n",
    "특정 항목을 선택할 때는 BeautifulSoup은 'nth-child'는 지원하지 않으므로, 'nth-of-type'을 사용한다.\n",
    "\n",
    "구분 | css selector\n",
    "-----|-----\n",
    "테이블 행 검색 | tbody tr\n",
    "테이블 첫행 검색 | tbody tr:nth-of-type(1)\n",
    "테이블 셀 검색 | tbody tr td\n",
    "테이블 첫셀 검색 | tbody tr td:nth-of-type(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "expecting Cell 11 ->  [<td>Cell 11</td>]\n",
      "\n",
      "expecting Cell 11 12 13 ->  [<tr>\\n<td>Cell 11</td>\\n<td>Cell 12</td>\\n<td>Cell 13</td>\\n</tr>]\n",
      "\n",
      "Cell 11\n",
      "Cell 12\n",
      "Cell 13\n",
      "\n",
      "Num Table Rows: 3\n",
      " Cell 11 Cell 12 Cell 13   Cell 21 Cell 22 Cell 23   \n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_5_testTable.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "tableHtml=\"\"\"\n",
    "<table id='thetable'>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Head 1</th>\n",
    "            <th>Head 2</th>\n",
    "            <th>Head 3</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Cell 11</td>\n",
    "            <td>Cell 12</td>\n",
    "            <td>Cell 13</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Cell 21</td>\n",
    "            <td>Cell 22</td>\n",
    "            <td>Cell 23</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "\"\"\"\n",
    "\n",
    "def do():\n",
    "    soup=BeautifulSoup(tableHtml,\"html.parser\")\n",
    "    my1=soup.select(\"#thetable tbody tr td:nth-of-type(1)\")\n",
    "    print \"\\nexpecting Cell 11 -> \", my1\n",
    "    my2=soup.select(\"#thetable > tbody > tr:nth-of-type(1)\")\n",
    "    print \"\\nexpecting Cell 11 12 13 -> \", my2\n",
    "    for e in my2:\n",
    "        #print e.string -> does not print\n",
    "        print e.text\n",
    "    my3=soup.select(\"#thetable tbody tr\")\n",
    "    print \"Num Table Rows:\", len(my3)\n",
    "    for e in my3:\n",
    "        row=e.get_text().split('\\n')\n",
    "        for cell in row:\n",
    "            print cell,  \n",
    "\n",
    "def main():\n",
    "    do()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-2: python.org 페이지가 가지고 있는 http url 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "파이썬 홈페이지 'www.python.org' 가 포함하는 링크를 찾아 보려고 한다.\n",
    "웹브라우저를 열고 'python.org'라고 입력해 보자.\n",
    "마우스를 가져가면 하이퍼링크가 활성화된다. 이런 링크를 가져오는 것이 문제이다.\n",
    "링크는 문서내의 다른 장소로 이동하거나 다른 웹페이지로 이동하는 기능을 제공한다.\n",
    "다른 페이지로 이동하는 링크만 출력한다.\n",
    "* 전체 링크의 갯수\n",
    "* 다른 페이지로 가는 링크 목록\n",
    "\n",
    "웹브라우저 메뉴에서 소스보기를 클릭하면 html 소스를 볼 수 있다. 하나씩 세어도 답을 할 수 있지만 프로그램으로 하면 시간, 노력, 오류를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 풀이\n",
    "\n",
    "\n",
    "주소창에 url을 입력하고 웹페이지를 요청하는 것과 같이 Python.org페이지를 크롤링해 온다.\n",
    "* 다음 방식으로 해 본다.\n",
    "    * BeautifulSoup\n",
    "    * regex\n",
    "    * xpath\n",
    "    * css selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "* requests로 url의 페이지를 가져와서, 그 페이지를 BeautifulSoup으로 parsing한다.\n",
    "* 위 예제, p 태그의 처음에 있는 strong 태그 가져오기\n",
    "* 파서 lxml을 넣어서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "_html=r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#soup = BeautifulSoup(_html,\"html.parser\")\n",
    "soup=BeautifulSoup(_html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print soup.prettify()[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* urllib을 사용해서, html을 가져온다.\n",
    "* 20개만 출력한다. 전체 개수는 맨 마지막 줄에 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for counter,link in enumerate(soup.find_all('a')):\n",
    "    if(counter<20):\n",
    "        print counter,link.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /wiki/Wikipedia:Protection_policy#semi\n",
      "1 #mw-head\n",
      "2 #p-search\n",
      "3 /wiki/HTM_(disambiguation)\n",
      "4 /wiki/Help:HTML_in_wikitext\n",
      "5 /wiki/File:HTML.svg\n",
      "6 /wiki/Filename_extension\n",
      "7 /wiki/Media_type\n",
      "8 /wiki/Type_code\n",
      "9 /wiki/World_Wide_Web_Consortium\n",
      "10 /wiki/WHATWG\n",
      "11 /wiki/Software_release_life_cycle\n",
      "12 /wiki/HTML5\n",
      "13 #cite_note-1\n",
      "14 /wiki/Document_file_format\n",
      "15 /wiki/Standard_Generalized_Markup_Language\n",
      "16 /wiki/XHTML\n",
      "17 /wiki/International_standard\n",
      "18 http://www.w3.org/TR/html/\n",
      "19 http://whatwg.org/html\n",
      "Total:  1761\n"
     ]
    }
   ],
   "source": [
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "#_html = urlopen(\"http://en.wikipedia.org/wiki/Kevin_Bacon\")\n",
    "_html = urlopen(\"http://en.wikipedia.org/wiki/HTML\").read()\n",
    "tree = BeautifulSoup(_html, \"lxml\")\n",
    "counter=0\n",
    "for link in tree.findAll(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        if counter<20:\n",
    "            print counter, link.attrs['href']\n",
    "        counter+=1\n",
    "print \"Total: \", counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 파일 버전\n",
    "\n",
    "* r.text는 unicode, r.content는 bytes로 Response를 받아온다.\n",
    "* 페이지를 읽을 경우, 발생오류에 대한 예외처리 try-except를 넣었다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load src/ds2_1_crawlLink.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readPythonOrg():\n",
    "    try:\n",
    "        r = requests.get(u'http://python.org/')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    soup=BeautifulSoup(r.content,\"lxml\")\n",
    "    my=soup.select(\"a\")\n",
    "    ahref=soup.find_all('a', href=True)\n",
    "    print \"total number of links:\",len(my)\n",
    "\n",
    "\n",
    "def main():\n",
    "    readPythonOrg()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### regex\n",
    "\n",
    "* 문자열에 포함된 패턴으로 태그 또는 추출할 데이터를 인식할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http url은 몇 개? 43\n",
      "0 http://www.ie6countdown.com/\n",
      "1 http://browsehappy.com/\n",
      "2 http://www.google.com/chromeframe/?redirect=true\n",
      "3 http://plus.google.com/+Python\n",
      "4 http://www.facebook.com/pythonlang?fref=ts\n",
      "5 http://twitter.com/ThePSF\n",
      "6 http://brochure.getpython.info/\n",
      "7 http://wiki.python.org/moin/Languages\n",
      "8 http://python.org/dev/peps/\n",
      "9 http://planetpython.org/\n",
      "10 http://pyfound.blogspot.com/\n",
      "11 http://pycon.blogspot.com/\n",
      "12 http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
      "13 http://blog.python.org\n",
      "14 http://feedproxy.google.com/~r/PythonInsider/~3/pUndlLcEcKE/python-337rc1-is-now-available-prior-to.html\n",
      "15 http://feedproxy.google.com/~r/PythonInsider/~3/pe2Ug4MA0Lg/python-2714-release-candidate-1.html\n",
      "16 http://feedproxy.google.com/~r/PythonInsider/~3/vY72b719CGk/python-354-and-python-347-are-now.html\n",
      "17 http://feedproxy.google.com/~r/PythonInsider/~3/ry7faTWPZiY/python-354rc1-and-python-347rc1-are-now.html\n",
      "18 http://feedproxy.google.com/~r/PythonInsider/~3/xgmAIcE1Wes/python-362-is-now-available.html\n",
      "19 http://www.djangoproject.com/\n",
      "20 http://www.pylonsproject.org/\n",
      "21 http://bottlepy.org\n",
      "22 http://tornadoweb.org\n",
      "23 http://flask.pocoo.org/\n",
      "24 http://www.web2py.com/\n",
      "25 http://wiki.python.org/moin/TkInter\n",
      "26 http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
      "27 http://www.wxpython.org/\n",
      "28 http://www.scipy.org\n",
      "29 http://pandas.pydata.org/\n",
      "30 http://ipython.org\n",
      "31 http://buildbot.net/\n",
      "32 http://trac.edgewall.org/\n",
      "33 http://roundup.sourceforge.net/\n",
      "34 http://www.ansible.com\n",
      "35 http://www.saltstack.com\n",
      "36 http://brochure.getpython.info/\n",
      "37 http://wiki.python.org/moin/Languages\n",
      "38 http://python.org/dev/peps/\n",
      "39 http://planetpython.org/\n",
      "40 http://pyfound.blogspot.com/\n",
      "41 http://pycon.blogspot.com/\n",
      "42 http://docs.python.org/devguide/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#p=re.compile('http://.+\"')\n",
    "p=re.compile('href=\"(http://.*?)\"')\n",
    "nodes=p.findall(_html)\n",
    "print \"http url은 몇 개?\",len(nodes)\n",
    "for i, node in enumerate(nodes):\n",
    "    print i, node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* regex를 사용해서 태그 값을 가져오기\n",
    "    * library를 사용하면 보다 간편하게 가져올 수 있지만, 배운 regex를 이용해보자.\n",
    "    * h1 태그\n",
    "    * p 태그"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Defined\n",
      "Compound Data Types\n",
      "Intuitive Interpretation\n",
      "Quick &amp; Easy to Learn\n",
      "All the Flow You&rsquo;d Expect\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "p=re.compile('<h1>(.*?)</h1>')\n",
    "h1tags=p.findall(_html)\n",
    "for tag in h1tags:\n",
    "    print tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "p=re.compile('<p>(.*?)</p>')\n",
    "ptags=p.findall(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print len(ptags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<strong>Notice:</strong> While Javascript is not essential for this website, your interaction with the content will be limited. Please turn Javascript on for the full experience. \n"
     ]
    }
   ],
   "source": [
    "print ptags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### xpath로 해보기\n",
    "\n",
    "* lxml.etree를 사용해 html을 파싱해서 자료 가져오기 (위에서 읽어온 html 변수를 사용)\n",
    "* xpath\n",
    "```\n",
    "$x('//*[@href]')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print type(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319299\n"
     ]
    }
   ],
   "source": [
    "print len(_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* lxml.etree.HTML()\n",
    "    * lxml.etree는 XML, HTML 모두 파싱할 수 있지만 사용하는 파서를 XMLParser(), HTMLParser()로 사전에 설정해야 오류가 발생하지 않는다.\n",
    "    * lxml.etree 대신 Python으로 만들어진 lxml.html을 사용하여 HTML을 처리할 수도 있다. \n",
    "\n",
    "문자를 읽는 함수 | 설명\n",
    "-----|-----\n",
    "etree.HTML() | html 문자열을 처리하는 경우 사용한다. 이러한 점에서 etree.fromstring()과 비슷하지만 HTMLParser()로 파싱을 하게 된다.\n",
    "etree.fromstring() | etree는 XML을 처리하는 객체. etree.fromstring()은 HTML 태그를 읽으면 오류를 발생하게 된다 (아래 참조).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "StartTag: invalid element name, line 1, column 2 (line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m StartTag: invalid element name, line 1, column 2\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "_htmlTree = etree.fromstring(_html)\n",
    "result = etree.tostring(_htmlTree, pretty_print=True, method=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "_htmlTree = etree.HTML(_html)\n",
    "result = etree.tostring(_htmlTree, pretty_print=True, method=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'href': '//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js', 'rel': 'prefetch'}\n",
      "1 {'href': '/static/stylesheets/style.css', 'type': 'text/css', 'rel': 'stylesheet', 'title': 'default'}\n",
      "2 {'media': 'not print, braille, embossed, speech, tty', 'href': '/static/stylesheets/mq.css', 'type': 'text/css', 'rel': 'stylesheet'}\n",
      "3 {'href': '/static/favicon.ico', 'type': 'image/x-icon', 'rel': 'icon'}\n",
      "4 {'href': '/static/apple-touch-icon-144x144-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '144x144'}\n",
      "5 {'href': '/static/apple-touch-icon-114x114-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '114x114'}\n",
      "6 {'href': '/static/apple-touch-icon-72x72-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '72x72'}\n",
      "7 {'href': '/static/apple-touch-icon-precomposed.png', 'rel': 'apple-touch-icon-precomposed'}\n",
      "8 {'href': '/static/apple-touch-icon-precomposed.png', 'rel': 'apple-touch-icon'}\n",
      "9 {'href': '/static/humans.txt', 'rel': 'author'}\n",
      "10 {'href': 'https://www.python.org/dev/peps/peps.rss/', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Enhancement Proposals'}\n",
      "11 {'href': 'https://www.python.org/jobs/feed/rss/', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Job Opportunities'}\n",
      "12 {'href': 'https://feeds.feedburner.com/PythonSoftwareFoundationNews', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Software Foundation News'}\n",
      "13 {'href': 'https://feeds.feedburner.com/PythonInsider', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Insider'}\n",
      "14 {'href': '#content', 'title': 'Skip to content'}\n",
      "15 {'href': '#python-network', 'aria-hidden': 'true', 'id': 'close-python-network', 'class': 'jump-link'}\n",
      "16 {'href': '/', 'class': 'current_item selectedcurrent_branch selected', 'title': 'The Python Programming Language'}\n",
      "17 {'href': '/psf-landing/', 'title': 'The Python Software Foundation'}\n",
      "18 {'href': 'https://docs.python.org', 'title': 'Python Documentation'}\n",
      "19 {'href': 'https://pypi.python.org/', 'title': 'Python Package Index'}\n"
     ]
    }
   ],
   "source": [
    "nodes=_htmlTree.xpath('//*[@href]')\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    if i<20:\n",
    "        print i, node.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### css selector\n",
    "\n",
    "* css select\n",
    "    ```\n",
    "    $$('a[href]')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "\n",
    "html = lxml.html.fromstring(r.text)\n",
    "sel=CSSSelector('a[href]')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "0 #content Skip to content\n",
      "1 #python-network \n",
      "                    \n",
      "2 / Python\n",
      "3 /psf-landing/ PSF\n",
      "4 https://docs.python.org Docs\n",
      "5 https://pypi.python.org/ PyPI\n",
      "6 /jobs/ Jobs\n",
      "7 /community/ Community\n",
      "8 #top \n",
      "                    \n",
      "9 / None\n",
      "10 #site-map None\n",
      "11 # None\n",
      "12 javascript:; Smaller\n",
      "13 javascript:; Larger\n",
      "14 javascript:; Reset\n",
      "15 # Socialize\n",
      "16 http://plus.google.com/+Python None\n",
      "17 http://www.facebook.com/pythonlang?fref=ts None\n",
      "18 http://twitter.com/ThePSF None\n",
      "19 /community/irc/ None\n"
     ]
    }
   ],
   "source": [
    "print len(nodes)\n",
    "for i,node in enumerate(nodes):\n",
    "    #print lxml.html.tostring(item)\n",
    "    if i<20:\n",
    "        print i, node.get('href'), node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-3: 위키에서 'python'을 검색해서 http url을 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "위키페이지는 집단지성을 대표하는 사이트이다. Python 페이지로 가서 다음을 출력한다.\n",
    "* 소개글\n",
    "* 다른 페이지로 가는 링크 목록\n",
    "\n",
    "웹브라우저 메뉴에서 소스보기를 클릭하면 html 소스를 볼 수 있다. 하나씩 세어도 답을 할 수 있지만 프로그램으로 하면 시간, 노력, 오류를 줄일 수 있다.\n",
    "\n",
    "### 해결\n",
    "\n",
    "* BeautifulSoup, lxml 라이브러리를 사용해 csss selector 첫째 문단과 링크 목록을 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### BeautifulSoup css selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(r.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 소스보기를 해서 가져오려는 태그의 css selector를 찾는다.\n",
    "* Chrome javascript console > 태그 하이라이트 > '...'에서 오른쪽 버튼 > copy > copy selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results=soup.select('div #mw-content-text p') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e in results:\n",
    "    print e.get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* http 링크를 검색한다. css a[href^=\"http\"]를 사용한다. 즉 http로 시작하는 문자열 값을 가진 href를 의미한다.\n",
    "여기서 따옴표를 지키도록 한다. \"a[href^='http']\"는 틀린 문법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links=soup.select('a[href^=\"http\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 위키에서 lxml css.selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "# build the DOM Tree\n",
    "tree = lxml.html.fromstring(r.text)\n",
    "# print the parsed DOM Tree\n",
    "#print lxml.html.tostring(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results=tree.cssselect('div #mw-content-text p') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Python interpreters are available for many <a href=\"/wiki/Operating_system\" title=\"Operating system\">operating systems</a>, allowing Python code to run on a wide variety of systems. <a href=\"/wiki/CPython\" title=\"CPython\">CPython</a>, the <a href=\"/wiki/Reference_implementation\" title=\"Reference implementation\">reference implementation</a> of Python, is <a href=\"/wiki/Open_source\" class=\"mw-redirect\" title=\"Open source\">open source</a> software<sup id=\"cite_ref-27\" class=\"reference\"><a href=\"#cite_note-27\">[27]</a></sup> and has a community-based development model, as do nearly all of its variant implementations. CPython is managed by the non-profit <a href=\"/wiki/Python_Software_Foundation\" title=\"Python Software Foundation\">Python Software Foundation</a>.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the HTML for the first result.\n",
    "match = results[2]\n",
    "print lxml.html.tostring(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreters are available for many \n"
     ]
    }
   ],
   "source": [
    "# print the text of the first result.\n",
    "print match.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load src/ds3_3_readWiki.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html\n",
    "#from lxml.cssselect import CSSSelector\n",
    "\n",
    "# build the DOM Tree\n",
    "# print the parsed DOM Tree\n",
    "#print lxml.html.tostring(tree)\n",
    "\n",
    "def readWikiLxml():\n",
    "    try:\n",
    "\tr = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    tree = lxml.html.fromstring(r.text)\n",
    "    results=tree.cssselect('div #mw-content-text p') \n",
    "    for e in results:\n",
    "\tprint e.text\n",
    "\n",
    "def readWikiBS():\n",
    "    try:\n",
    "\tr = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    soup=BeautifulSoup(r.text,\"lxml\")\n",
    "    results=soup.select('div #mw-content-text p') \n",
    "    for e in results:\n",
    "\tprint e.get_text().strip()\n",
    "    links=soup.select('a[href^=\"http\"]')\n",
    "    #links=soup.select(\"a[href^='http']\") -> not working\n",
    "    print \"total links: \",len(links)\n",
    "    for e in links:\n",
    "        print e\n",
    "\n",
    "def main():\n",
    "    #readWikiLxml()\n",
    "    readWikiBS()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-4: 한국 포털사이트에서 노래제목을 검색해서 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "노래는 개인의 선호가 뚜렸해서 추천에 많이 쓰이고 있다. 개인 또는 행사의 상황에 어울리는 노래를 선정해 알려주는 추천을 말한다. 예제에서는 '비 오는'이라는 단어를 검색하여 해당하는 노래 제목을 가져오는 문제이다.\n",
    "주의: 음악에는 저작권이 있다. 이 예제는 교육 목적으로 행해지는 실습이다. 상업적인 목적으로 사용할 경우는 반드시 저작권을 위반하지 않도록 주의가 필요하다.\n",
    "\n",
    "### 해결\n",
    "네이버음악 사이트 http://music.naver.com/ 에서 제공하는 노래제목 검색 기능을 사용해서 노래제목을 가져온다. 추천은 다음에 배우기로 한다. 노래는 제목, 가수, 앨범이 게시판 형식으로 구성되어 있다. 게시판은 pagination이라고 하는 기능이 있어 여러 페이지를 반복해서 가져와야 한다.\n",
    "\n",
    "> pagination은 검색결과가 여러 페이지일 경우 사용하는 기능이다. 검색결과가 150건 일 경우, 10개로 나누어 15페이지가 제공되는 예를 들 수 있다. '더보기', '목록번호', '맨 앞으로 이동', '맨 뒤로 이동' 등의 버튼이 제공되고 이를 사용해서 데이터를 조회할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### regex\n",
    "\n",
    "http://music.naver.com/ 로 가서 '비오는'을 검색한다.\n",
    "그 결과 15건의 노래가 검색된다.\n",
    "이 때 주소창에 나타나는 url을 복사해서 프로그램에 사용하기로 한다.\n",
    "urllib.urlopen()을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "keyword='비오는'\n",
    "#f = urllib.urlopen(\"http://music.naver.com/search/search.nhn?query=\"+keyword+\"&x=0&y=0\")\n",
    "f = urllib.urlopen(\"http://music.naver.com/search/search.nhn?query=\"+keyword)\n",
    "mydata = f.read();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 비 오는 거리\n",
      "132369\n"
     ]
    }
   ],
   "source": [
    "pos = mydata.find(\"트랙 리스트\")\n",
    "if (pos>0):\n",
    "    pos = mydata.find(\"_title title NPI=\", pos);\n",
    "    pos = mydata.find(\"title=\",pos+20)\n",
    "    pos2 = mydata.find(\"\\\"\", pos+8)\n",
    "    print \"---\",mydata[pos+7:pos2]\n",
    "print len(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title=\"검색어 입력\" value=\"비오는\" maxlength=\"50\" accesskey=\"s\"\n",
      "title=\"비오는날\" alt=\"비오는날\"\n",
      "title=\"비오는 금요일\" alt=\"비오는 금요일\"\n",
      "title=\"비 오는 거리\" ><span class=\"ellipsis\"\n",
      "title=\"1집 비오는 거리\" class=\"_album NPI=a:album,r:1,i:682\"><span class=\"ellipsis\"\n",
      "title=\"비오는 날 수채화\" ><span class=\"ellipsis\"\n",
      "title=\"비오는 날 수채화 1 OST\" class=\"_album NPI=a:album,r:2,i:33001\"><span class=\"ellipsis\"\n",
      "title=\"비오는 압구정\" ><span class=\"ellipsis\"\n",
      "title=\"비 오는 거리\" ><span class=\"ellipsis\"\n",
      "title=\"비 오는 거리\" class=\"_album NPI=a:album,r:4,i:442032\"><span class=\"ellipsis\"\n",
      "title=\"비 오는 거리  (Feat. 핫펠트)\" ><span class=\"ellipsis\"\n",
      "title=\"비오는 거리\" ><span class=\"ellipsis\"\n",
      "title=\"유ㄹish.1 - 비오는 거리\" class=\"_album NPI=a:album,r:6,i:208754\"><span class=\"ellipsis\"\n",
      "title=\"비오는 거리\" ><span class=\"ellipsis\"\n",
      "title=\"비오는 날, 산책\" ><span class=\"ellipsis\"\n",
      "title=\"비오는 날, 산책\" class=\"_album NPI=a:album,r:8,i:620775\"><span class=\"ellipsis\"\n",
      "title=\"비 오는 날\" ><span class=\"ellipsis\"\n",
      "title=\"비 오는 날\" class=\"_album NPI=a:album,r:9,i:656486\"><span class=\"ellipsis\"\n",
      "title=\"비오는 날엔\" ><span class=\"ellipsis\"\n",
      "title=\"비오는 날엔\" class=\"_album NPI=a:album,r:10,i:310321\"><span class=\"ellipsis\"\n",
      "title=\"비오는 날은 푸르다\" ><span class=\"ellipsis\"\n",
      "title=\"비오는 날은 푸르다\" class=\"_album NPI=a:album,r:11,i:660894\"><span class=\"ellipsis\"\n",
      "title=\"비오는 압구정\" ><span class=\"ellipsis\"\n",
      "title=\"비 오는 이런 날에\" ><span class=\"ellipsis\"\n",
      "title=\"비 오는 이런 날에\" class=\"_album NPI=a:album,r:13,i:560089\"><span class=\"ellipsis\"\n",
      "title=\"Acoustic Rain (비오는 날 듣는 감성 팝음악 모음집)\" class=\"_album NPI=a:album,r:14,i:385222\"><span class=\"ellipsis\"\n",
      "title=\"비 오는 거리에서\" ><span class=\"ellipsis\"\n",
      "title=\"Acoustic Rain (비오는 날 듣는 감성 팝음악 모음집)\"\n",
      "title=\"비 오는 날 듣고 싶은 추억의 팝송\"\n",
      "title=\"비오는 날 수채화 1 OST\"\n",
      "title=\"비오는 금요일\"\n",
      "title=\"비오는 금요일\" alt=\"비오는 금요일\" class=\"NPI=a:artist,r:,i:271713\"\n",
      "title=\"7080 팝송 발라드 (비오는 날의 슬픈 추억 올드팝 연가)\"\n",
      "title=\"비 오는 날\"\n",
      "title=\"비오는 압구정\"\n",
      "title=\"비오는 날에\"\n",
      "title=\"비오는 거리 (Feat. 단비)\"\n",
      "title=\"비오는 날 떡볶이\"\n",
      "title=\"`비오는날의 수채화` 피아노커버\"\n",
      "title=\"`비오는날의 수채화 ` 피아노연주\"\n",
      "title=\"비오는날에 어울리지않을까 싶어요~\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "p=re.compile('title=\".*비.?오는.*\"')\n",
    "#res=p.search(data)\n",
    "res=p.findall(mydata)\n",
    "for item in res:\n",
    "    print item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### css selector\n",
    "\n",
    "* 웹브라우저 자바스크립트 창을 열어서 css selector를 복사해서 살펴본다.\n",
    "    * 맨 처음부터 따라가면\n",
    "```\n",
    "body > #wrap > div.fix_conts > #container > .container_inner > #content\n",
    "```\n",
    "    * 다음 계속 이어가면\n",
    "```\n",
    "#content > div:nth-child(4) \n",
    "> div._tracklist_mytrack.tracklist_table.tracklist_type1._searchTrack\n",
    "> table > tbody > tr:nth-child(2) > td.name\n",
    "```\n",
    "    * 제목까지 읽으면\n",
    "```\n",
    "#content > div:nth-child(4) \n",
    "> div._tracklist_mytrack.tracklist_table.tracklist_type1._searchTrack\n",
    "> table > tbody > tr:nth-child(2) > td.name > a.title\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 요약하면:\n",
    "\n",
    "CSS selectors | 설명\n",
    "----------|----------\n",
    "#content | id가 content인 element를 선택\n",
    "#content > div:nth-child(4)' | 상위 #content의 4번째 div를 선택\n",
    "div._tracklist_mytrack | div아래 _tracklist_mytrack 클래스를 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 앞은 건너뛰고 table부터 쓰면 (중간부터 쓰니까, 속성을 사용해서 시작함)\n",
    "```\n",
    "'table[summary] > tbody > ._tracklist_move > .name > a.title'\n",
    "```\n",
    "    \n",
    "* 줄여서 다음의 css selector를 사용하기로 한다.\n",
    "\n",
    "CSS selectors | 설명\n",
    "----------|----------\n",
    "._tracklist_move | 클래스를 선택\n",
    "a.title | a link의 title을 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 전체 css selector 사용하기\n",
    "\n",
    "구글 개발자창에서 css selector를 복사해서 그 전체를, 정리가 안되었지만, 사용하기로 한다.\n",
    "'비 오는 거리' 노래 제목을 1건 출력하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "html = lxml.html.fromstring(mydata)\n",
    "nodes=html.cssselect('#content > div:nth-child(4) \\\n",
    "    > div._tracklist_mytrack.tracklist_table.tracklist_type1._searchTrack \\\n",
    "    > table > tbody > tr:nth-child(2) > td.name > a.title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    print node.text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "검색된 15건 노래를 출력해 본다. 전체를 가져올 경우는 'nth-child'가 제거되었다. 1건을 가져오는 경우와 비교하면 차이를 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 압구정\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 날 수채화\n",
      "비오는 거리\n",
      "비오는 거리\n",
      "비오는 압구정\n",
      "비 오는 날\n",
      "비오는 아침\n",
      "비오는 날엔\n",
      "비오는 날\n",
      "비 오는 거리에서\n",
      "비 오는 거리에서\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "html = lxml.html.fromstring(mydata)\n",
    "nodes=html.cssselect('#content > div:nth-child(4) \\\n",
    "    > div._tracklist_mytrack.tracklist_table.tracklist_type1._searchTrack \\\n",
    "    > table > tbody > tr > td.name > a.title')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    print node.text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 정리한 css selector 사용하기\n",
    "\n",
    "이번에는 css selector를 정리하여 사용해 본다. 자바스크립트 창에서 테스트를 해보면서 정리하는 것이 쉽다.\n",
    "여기서는 urllib대신, requests를 사용해서 해본다.\n",
    "목록에서 '더보기'를 찾아서 버튼을 눌러 본다. 주소창의 url과 params이 어떻게 변경되었는지 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import requests\n",
    "\n",
    "#p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\"}\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "r = requests.get(naverUrl,params=p)\n",
    "_html = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* html을 보려면\n",
    "    * r.text로 보거나\n",
    "    * lxml.html.tostring(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264801"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lxml.html.tostring(_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#sel = CSSSelector('table[summary] > tbody > ._tracklist_move > .name > a.title')\n",
    "sel = CSSSelector('._tracklist_move > .name > a.title')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* item.text()는 한글 문자 출력 오류\n",
    "* item.text_content()를 사용해서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 압구정\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 날 수채화\n",
      "비오는 거리\n",
      "비오는 거리\n",
      "비오는 압구정\n",
      "비 오는 날\n",
      "비오는 아침\n",
      "비오는 날엔\n",
      "비오는 날\n",
      "비 오는 거리에서\n",
      "비 오는 거리에서\n",
      "비오는 날, 산책\n",
      "비 오는 날\n",
      "비 오는 경리단길 (Feat. 양은선)\n",
      "비오는 압구정\n",
      "비오는 날\n",
      "7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기)\n",
      "비오는날의 수채화 (Feat. 정혜민, Misty)\n",
      "비오는 밤\n",
      "비오는 날의 수채화\n",
      "비 오는 날의 수채화\n",
      "비 오는 거리\n",
      "비오는 날은 푸르다\n",
      "비오는 이른 새벽 자장가\n",
      "Rainy Day (비오는 날)\n",
      "비오는 금요일\n",
      "I'd Love You To Want Me (CF '코업레지던스', 영화...\n",
      "Rhythm Of The Rain (빗줄기의 리듬 : CF 'LG 정유...\n",
      "자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가)\n",
      "자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기...\n",
      "비오는 거리\n",
      "비오는 날엔 (Feat. 어쿠스틱 콜라보)\n",
      "Rain (호세 펠라치아노의 대표곡 : 레인)\n",
      "House Of The Rising Sun (해뜨는 집, 드라마 '올인' OST)\n",
      "California Dreamin' (캘리포니아 드림 - 영화...\n",
      "비 오는 밤\n",
      "자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가)\n",
      "비오는 일요일\n",
      "자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가)\n",
      "비오는 날엔\n",
      "비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가)\n",
      "자장가 (비오는 소리와 함께하는 모차르트 아기 자장가)\n",
      "비오는 날의 수채화\n",
      "비오는 날엔 막걸리 (Feat. 신승열)\n",
      "Evergreen\n",
      "자장가 (비오는 소리와 함께하는 위안 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    print node.text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 곡명, 아티스트, 앨범 모두 가져오기\n",
    "    * html이 정형적이지 않아서 어렵다.\n",
    "    * 2단계 작업.\n",
    "        * 곡명, 아티스트, 앨범 항목을 가지고 있는 상위 태그를 먼저 선정하고, 그 안의 개별 항목을 선정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr class=\"_tracklist_move {TRACK_TYPE}\" style=\"display:none;\" trackdata=\"{TRACK_DATA}\">\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"chk\"><input type=\"checkbox\" title=\"&#49440;&#53469;\" class=\"_chkbox_item input_chk {TRACK_CHECK_NCLICKS}\"> </td>\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"order\">{TRACK_NUM}</td>\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"name\">\r\n",
      "\r\n",
      "\t\t\t\t\t\t\t\t{PLAY_TOGGLE}\r\n",
      "\t\t\t\t\t\t\t\t{ADD_TOGGLE}\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\t\t\t\t\t<span class=\"_ico_title ico_title\"><img height=\"18\" width=\"23\" alt=\"TITLE\" src=\"http://static.naver.net/nmusic/201\n"
     ]
    }
   ],
   "source": [
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "sel = CSSSelector('._tracklist_move')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)\n",
    "print lxml.html.tostring(nodes[0])[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 개별 항목의 선정\n",
    "* 우선 1개씩 해 본다.\n",
    "    * results[0]은 제목행이므로, 그 다음을 처리한다.\n",
    "    * 태그가 정형적이지 않으므로, selector가 일정하지 않다는 점에 주의한다.\n",
    "        * Chrome console창을 이용해서 하나씩 작업하므로, selector를 정의하는데 노력이 수반된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "_name=_selName(nodes[1])\n",
    "_artist=_selArtist(nodes[1])\n",
    "_album=_selAlbum(nodes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "소울스타 (SoulstaR)\n",
      "비 오는 거리\n"
     ]
    }
   ],
   "source": [
    "print _name[0].text_content()\n",
    "print _artist[0].text_content().strip()\n",
    "print _album[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 반복문을 이용하여 모든 노래를 출력한다.\n",
    "    * if문은 노래제목이 있는 없는 경우 제거한다 (제목 행을 제거하는 효과)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "강인원 --- 비오는 날 수채화 --- 비오는 날 수채화 1 OST\n",
      "오소연 --- 비 오는 날 --- 비 오는 날\n",
      "동요시대 --- 비오는날 (동요) (멜로디 MR) --- 동요 MR반주 5\n",
      "서영은 --- 비오는 거리 --- 1집 Romantic 1\n",
      "루드 페이퍼(Rude Paper) --- 비오는 밤에 --- 1집 Paper Spectrum\n",
      "김민우 --- 비오는 날 (Inst.) --- 비오는 날\n",
      "조영순 --- 비오는 남산 --- 무진장 트롯트 골든 1＆2\n",
      "베이빌론(Babylon) --- 비 오는 거리  (Feat. 핫펠트) --- BETWEEN US\n",
      "브라운 아이즈 --- 비오는 압구정 --- 2집 Reason 4 Breathing?\n",
      "하이니(Hi.ni) --- 비오는 날은 푸르다 --- 비오는 날은 푸르다\n",
      "Richard Marx --- One More Time --- 김현주의 비오는 거리\n",
      "SG 워너비 --- 비 오는 날의 수채화 --- Classic Odyssey\n",
      "Romantisch Jazzkapelle --- Yesterday (비틀즈 예스터 데이 : CF `시몬스침대`) --- 뉴에이지 연가 : 비 오는 날의 거리, 추억, 그리고 아름다운 재즈 피아노(Pop 올드 팝, 클래식, 영화 OST 베스트 연주 음악)\n",
      "강윤식 --- 비오는날 수채화 (발라드 Ver.) (With 김명상, 강윤식) --- 1980-2010 리뉴얼 - 내 노래 다시 부르기\n"
     ]
    }
   ],
   "source": [
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    _name=_selName(node)\n",
    "    _artist=_selArtist(node)\n",
    "    _album=_selAlbum(node)\n",
    "    if _name:\n",
    "        print _artist[0].text_content().strip(),\n",
    "        print \"---\",\n",
    "        print _name[0].text_content(),\n",
    "        print \"---\",\n",
    "        print _album[0].text_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소울스타 (SoulstaR) --- 비 오는 거리 --- 비 오는 거리\n",
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "은가은 --- 비 오는 이런 날에 --- 비 오는 이런 날에\n",
      "브라운 아이즈 --- 비오는 압구정 --- 2집 Reason 4 Breathing?\n",
      "베이빌론(Babylon) --- 비 오는 거리  (Feat. 핫펠트) --- BETWEEN US\n",
      "강인원 --- 비오는 날 수채화 --- 비오는 날 수채화 1 OST\n",
      "유리상자 --- 비오는 거리 --- 유ㄹish.1 - 비오는 거리\n",
      "서영은 --- 비오는 거리 --- 1집 Romantic 1\n",
      "브라운 아이즈 --- 비오는 압구정 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "오소연 --- 비 오는 날 --- 비 오는 날\n",
      "재주소년 --- 비오는 아침 --- 1집 재주소년 (才洲少年)\n",
      "소심한 오빠들 --- 비오는 날엔 --- 비오는 날엔\n",
      "루싸이트 토끼 --- 비오는 날 --- 1집 Twinkle Twinkle\n",
      "아스트로피아노 --- 비 오는 거리에서 --- 비 오는 거리에서\n",
      "이승철 --- 비 오는 거리에서 --- 시간 참 빠르다\n",
      "모모캣츠(Momocats) --- 비오는 날, 산책 --- 비오는 날, 산책\n",
      "김봄 --- 비 오는 날 --- 비 오는 날\n",
      "로만티코(Romantico) --- 비 오는 경리단길 (Feat. 양은선) --- Diminished Part 1\n",
      "서영은 --- 비오는 압구정 --- Unforgettable No.2\n",
      "오은영 --- 비오는 날 --- 비오는 날\n",
      "Flower Singers --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "럼블 피쉬 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Memory For You\n",
      "도나웨일(Donawhale) --- 비오는 밤 --- 1집 Donawhale\n",
      "박정현 --- 비오는 날의 수채화 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "SG 워너비 --- 비 오는 날의 수채화 --- Classic Odyssey\n",
      "SG 워너비 --- 비 오는 거리 --- Classic Odyssey\n",
      "하이니(Hi.ni) --- 비오는 날은 푸르다 --- 비오는 날은 푸르다\n",
      "롤러코스터 --- 비오는 이른 새벽 자장가 --- 1집 내게로 와\n",
      "김광민 --- Rainy Day (비오는 날) --- 1집 Letter From The Earth\n",
      "비오는 금요일 --- 비오는 금요일 --- 비오는 금요일\n",
      "Lobo --- I'd Love You To Want Me (CF '코업레지던스', 영화... --- 추억의 7080 팝송 베스트 - Golden Pop Best (CF, 드라마, 영화에 나오는 오리지날 올드 팝 : 비 오는 날, 드라이브, 카페 음악)\n",
      "Cascades --- Rhythm Of The Rain (빗줄기의 리듬 : CF 'LG 정유... --- 추억의 7080 팝송 베스트 - Golden Pop Best (CF, 드라마, 영화에 나오는 오리지날 올드 팝 : 비 오는 날, 드라이브, 카페 음악)\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기... --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "이금성 --- 비오는 거리 --- 비오는 거리\n",
      "노블레스 --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- 7집 Growing Pains\n",
      "Jose Feliciano --- Rain (호세 펠라치아노의 대표곡 : 레인) --- 추억의 7080 팝송 베스트 - Golden Pop Best (CF, 드라마, 영화에 나오는 오리지날 올드 팝 : 비 오는 날, 드라이브, 카페 음악)\n",
      "The Animals --- House Of The Rising Sun (해뜨는 집, 드라마 '올인' OST) --- 추억의 7080 팝송 베스트 - Golden Pop Best (CF, 드라마, 영화에 나오는 오리지날 올드 팝 : 비 오는 날, 드라이브, 카페 음악)\n",
      "Mamas & Papas --- California Dreamin' (캘리포니아 드림 - 영화... --- 추억의 7080 팝송 베스트 - Golden Pop Best (CF, 드라마, 영화에 나오는 오리지날 올드 팝 : 비 오는 날, 드라이브, 카페 음악)\n",
      "어프로그레시브 피아노 --- 비 오는 밤 --- One Day\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "온음 --- 비오는 일요일 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "유리상자 --- 비오는 날엔 --- 4집 Home\n",
      "백색소음 --- 비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가) --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 모차르트 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "권인하 --- 비오는 날의 수채화 --- 첫사랑\n",
      "레미 --- 비오는 날엔 막걸리 (Feat. 신승열) --- 비오는 날엔 막걸리\n",
      "Various Artists --- Evergreen --- 비 오는 날 듣고 싶은 추억의 팝송\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 위안 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import lxml.html\n",
    "import requests\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\"}\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "r = requests.get(naverUrl,params=p)\n",
    "_html = lxml.html.fromstring(r.text)\n",
    "\n",
    "sel = CSSSelector('table[summary] > tbody > ._tracklist_move')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)\n",
    "\n",
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    _name=_selName(node)\n",
    "    _artist=_selArtist(node)\n",
    "    _album=_selAlbum(node)\n",
    "    if _name:\n",
    "        print _artist[0].text_content().strip(),\n",
    "        print \"---\",\n",
    "        print _name[0].text_content(),\n",
    "        print \"---\",\n",
    "        print _album[0].text_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 연속\n",
    "    * params에 track, pageNo를 추가하기\n",
    "    https://www.url-encode-decode.com/에서 encode, decode기능을 제공\n",
    "    * naver의 url을 관찰하면 p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "    '%27%eb%b9%84%ec%98%a4%eb%8a%94%27'는 '비오는'이라는 키워드\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load src/ds3_4_naverMusic.py\n",
    "#!\n",
    "import lxml.html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#keyword='비오는'\n",
    "#p = {'query': '비오는', '&x': 0, '&y':0}\n",
    "pageNo=1\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "#r = requests.get(\"http://music.naver.com/search/search.nhn?query=\"+keyword+\"&x=0&y=0\")\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "def readMusicLxml():\n",
    "    try:\n",
    "        r = requests.get(naverUrl,params=p)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    _html = lxml.html.fromstring(r.text)\n",
    "    #sel = CSSSelector('table[summary] > tbody > ._tracklist_move')\n",
    "    sel = CSSSelector('._tracklist_move')\n",
    "    # Apply the selector to the DOM tree.\n",
    "    nodes = sel(_html)\n",
    "    _selName = CSSSelector('.name > a.title')\n",
    "    _selArtist = CSSSelector('._artist.artist')\n",
    "    _selAlbum= CSSSelector('.album > a')\n",
    "    for node in nodes:\n",
    "        #print lxml.html.tostring(item)\n",
    "        _name=_selName(node)\n",
    "        _artist=_selArtist(node)\n",
    "        _album=_selAlbum(node)\n",
    "        if _name:\n",
    "            print _artist[0].text_content().strip(),\n",
    "            print \"---\",\n",
    "            print _name[0].text_content(),\n",
    "            print \"---\",\n",
    "            print _album[0].text_content()\n",
    "\n",
    "def readMusicBS():\n",
    "    try:\n",
    "        #pageNo=1\n",
    "        for pageNo in range(10):\n",
    "            p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "            r = requests.get(naverUrl,params=p)\n",
    "            #if r.text is not '':\n",
    "            soup=BeautifulSoup(r.text,\"lxml\")\n",
    "            _selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "            _selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "            _selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "            print \"total number of items:\",len(_selName)\n",
    "            for i in range(len(_selName)):\n",
    "                print pageNo,'---',_selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n",
    "            #pageNo+=1\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "\n",
    "def main():\n",
    "    readMusicLxml()\n",
    "    readMusicBS() #bug - print header and no last line \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds3_4_naverMusic.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-5 : 국제학회 목록을 가져오기\n",
    "\n",
    "* IEEE 학회를 검색하는 url\n",
    "```\n",
    "http://www.ieee.org/conferences_events/conferences/search/index.html\n",
    "```\n",
    "\n",
    "* 크롬 브라우저 > 보기 > 개발자 정보 > javascript console\n",
    "    * Elements 창에서 검색을 하면 원하는 문자열을 찾을 수 있다.\n",
    "    * css로 태그를 찾아 본다.\n",
    "        ```\n",
    "        'div.content-r-full table.nogrid-nopad tr'\n",
    "        ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "r = requests.get('http://www.ieee.org/conferences_events/conferences/search/index.html')\n",
    "\n",
    "html = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en-us\" xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en-us\">\r\n",
      "<head><meta http-equiv=\"c\n"
     ]
    }
   ],
   "source": [
    "print lxml.html.tostring(html)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 66개의 데이터를 가지고 있다. 페이지를 열어서 비교해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "sel=CSSSelector('div.content-r-full table.nogrid-nopad tr p>a[href]')\n",
    "nodes = sel(html)\n",
    "print len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "2029 IEEE/MTT-S International Microwave Symposium - IMS 2029\n",
      "----------\n",
      "31 May - 08 Jun 2029\n",
      "----------\n",
      "Boston Convention and Exhibition Center\n",
      "----------\n",
      "2025 IEEE/MTT-S International Microwave Symposium - IMS 2025\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for node in nodes[:10]:\n",
    "    print node.text\n",
    "    print \"----------\"\n",
    "    #print lxml.html.tostring(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```\n",
    "\n",
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds_web_crawl_ieee.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  142204\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "2036 IEEE/MTT-S International Microwave Symposium - IMS 2036\n",
      "----------\n",
      "01 Jun - 06 Jun 2036\n",
      "----------\n",
      "Boston Convention and Exhibition Center (BCEC)\n",
      "----------\n",
      "2031 IEEE/MTT-S International Microwave Symposium - IMS 2031\n",
      "----------\n",
      "01 Jun - 06 Jun 2031\n",
      "----------\n",
      "Boston Convention and Exhibition Center (BCEC)\n",
      "----------\n",
      "2029 IEEE/MTT-S International Microwave Symposium - IMS 2029\n",
      "----------\n",
      "31 May - 08 Jun 2029\n",
      "----------\n",
      "Boston Convention and Exhibition Center\n",
      "----------\n",
      "2026 IEEE/MTT-S International Microwave Symposium - IMS 2026\n",
      "----------\n",
      "07 Jun - 12 Jun 2026\n",
      "----------\n",
      "Boston Convention and Exhibition Center (BCEC)\n",
      "----------\n",
      "2025 IEEE/MTT-S International Microwave Symposium - IMS 2025\n",
      "----------\n",
      "15 Jun - 20 Jun 2025\n",
      "----------\n",
      "Moscone Convention Center\n",
      "----------\n",
      "2024 IEEE/MTT-S International Microwave Symposium - IMS 2024\n",
      "----------\n",
      "16 Jun - 21 Jun 2024\n",
      "----------\n",
      "Walter E. Washington Convention Center\n",
      "----------\n",
      "S4XXX Test\n",
      "----------\n",
      "04 Sep - 07 Sep 2023\n",
      "----------\n",
      "tbd\n",
      "----------\n",
      "2023 Annual International Conference of the IEEE Engineering in Medicine & Biology Conference (EMBC)\n",
      "----------\n",
      "25 Jul - 29 Jul 2023\n",
      "----------\n",
      "International Convention Centre Sydney (ICC Sydney)\n",
      "----------\n",
      "2023 IEEE/MTT-S International Microwave Symposium - IMS 2023\n",
      "----------\n",
      "11 Jun - 16 Jun 2023\n",
      "----------\n",
      "San Diego Convention Center\n",
      "----------\n",
      "2023 IEEE International Solid- State Circuits Conference (ISSCC)\n",
      "----------\n",
      "14 Feb - 26 Feb 2023\n",
      "----------\n",
      "Marriott Marquis\n",
      "----------\n",
      "2022 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC)\n",
      "----------\n",
      "26 Sep - 29 Sep 2022\n",
      "----------\n",
      "Sheraton Denver Downtown\n",
      "----------\n",
      "2022 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\n",
      "----------\n",
      "25 Jul - 29 Jul 2022\n",
      "----------\n",
      "raleigh CC\n",
      "----------\n",
      "2022  IEEE/MTT-S International Microwave Symposium - IMS 2022\n",
      "----------\n",
      "12 Jun - 17 Jun 2022\n",
      "----------\n",
      "Colorado Convention Center\n",
      "----------\n",
      "2022 59th ACM/EDAC/IEEE Design Automation Conference (DAC)\n",
      "----------\n",
      "06 Jun - 10 Jun 2022\n",
      "----------\n",
      "Moscone Center\n",
      "----------\n",
      "2022 IEEE International Solid- State Circuits Conference (ISSCC)\n",
      "----------\n",
      "15 Feb - 27 Feb 2022\n",
      "----------\n",
      "Marriott Marquis\n",
      "----------\n",
      "2022 Annual Conference on Magnetism and Magnetic Materials (MMM)\n",
      "----------\n",
      "10 Jan - 14 Jan 2022\n",
      "----------\n",
      "Hyatt Regency New Orleans\n",
      "----------\n",
      "2021 IEEE International Electron Devices Meeting (IEDM)\n",
      "----------\n",
      "13 Dec - 15 Dec 2021\n",
      "----------\n",
      "Hilton San Francisco Union Square\n",
      "----------\n",
      "2021 IEEE International Conference on Image Processing (ICIP)\n",
      "----------\n",
      "19 Sep - 22 Sep 2021\n",
      "----------\n",
      "DENA'INA Civic and Convention Center\n",
      "----------\n",
      "2021 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC)\n",
      "----------\n",
      "13 Sep - 16 Sep 2021\n",
      "----------\n",
      "San Antonio Marriott Rivercenter\n",
      "----------\n",
      "2021 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\n",
      "----------\n",
      "27 Jul - 31 Jul 2021\n",
      "----------\n",
      "Raleigh convention center\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_5_readIEEE.py\n",
    "#!\n",
    "\n",
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "\n",
    "def readIEEE():\n",
    "    try:\n",
    "        r = requests.get('http://www.ieee.org/conferences_events/conferences/search/index.html')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    page=r.text\n",
    "    print \"length: \",len(page)\n",
    "    html = lxml.html.fromstring(page)\n",
    "    sel=CSSSelector('div.content-r-full table.nogrid-nopad tr p>a[href]')\n",
    "    nodes = sel(html)\n",
    "    for node in nodes:\n",
    "        print node.text\n",
    "        print \"----------\"\n",
    "\n",
    "def main():\n",
    "    readIEEE()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "2029 IEEE/MTT-S International Microwave Symposium - IMS 2029\r\n",
      "----------\r\n",
      "31 May - 08 Jun 2029\r\n",
      "----------\r\n",
      "Boston Convention and Exhibition Center\r\n",
      "----------\r\n",
      "2025 IEEE/MTT-S International Microwave Symposium - IMS 2025\r\n",
      "----------\r\n",
      "15 Jun - 20 Jun 2025\r\n",
      "----------\r\n",
      "Moscone Convention Center\r\n",
      "----------\r\n",
      "2024 IEEE/MTT-S International Microwave Symposium - IMS 2024\r\n",
      "----------\r\n",
      "16 Jun - 21 Jun 2024\r\n",
      "----------\r\n",
      "Walter E. Washington Convention Center\r\n",
      "----------\r\n",
      "2023 Annual International Conference of the IEEE Engineering in Medicine & Biology Conference (EMBC)\r\n",
      "----------\r\n",
      "25 Jul - 29 Jul 2023\r\n",
      "----------\r\n",
      "International Convention Centre Sydney (ICC Sydney)\r\n",
      "----------\r\n",
      "2023 IEEE/MTT-S International Microwave Symposium - MTT 2023\r\n",
      "----------\r\n",
      "11 Jun - 16 Jun 2023\r\n",
      "----------\r\n",
      "San Diego Convention Center\r\n",
      "----------\r\n",
      "2022 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\r\n",
      "----------\r\n",
      "25 Jul - 29 Jul 2022\r\n",
      "----------\r\n",
      "raleigh CC\r\n",
      "----------\r\n",
      "2022 IEEE/MTT-S International Microwave Symposium - MTT 2022\r\n",
      "----------\r\n",
      "12 Jun - 17 Jun 2022\r\n",
      "----------\r\n",
      "Colorado Convention Center\r\n",
      "----------\r\n",
      "2022 59th ACM/EDAC/IEEE Design Automation Conference (DAC)\r\n",
      "----------\r\n",
      "06 Jun - 10 Jun 2022\r\n",
      "----------\r\n",
      "Moscone Center\r\n",
      "----------\r\n",
      "2022 Annual Conference on Magnetism and Magnetic Materials (MMM)\r\n",
      "----------\r\n",
      "10 Jan - 14 Jan 2022\r\n",
      "----------\r\n",
      "Hyatt Regency New Orleans\r\n",
      "----------\r\n",
      "2021 IEEE International Electron Devices Meeting (IEDM)\r\n",
      "----------\r\n",
      "13 Dec - 15 Dec 2021\r\n",
      "----------\r\n",
      "Hilton San Francisco Union Square\r\n",
      "----------\r\n",
      "2021 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\r\n",
      "----------\r\n",
      "27 Jul - 31 Jul 2021\r\n",
      "----------\r\n",
      "Raleigh convention center\r\n",
      "----------\r\n",
      "2021 IEEE International Conference on Plasma Science (ICOPS)\r\n",
      "----------\r\n",
      "20 Jun - 25 Jun 2021\r\n",
      "----------\r\n",
      "Harvey's & Harrah's\r\n",
      "----------\r\n",
      "2021 IEEE/MTT-S International Microwave Symposium - MTT 2021\r\n",
      "----------\r\n",
      "20 Jun - 24 Jun 2021\r\n",
      "----------\r\n",
      "Georgia World Congress Center\r\n",
      "----------\r\n",
      "2021 58th ACM/EDAC/IEEE Design Automation Conference (DAC)\r\n",
      "----------\r\n",
      "07 Jun - 11 Jun 2021\r\n",
      "----------\r\n",
      "Moscone Center\r\n",
      "----------\r\n",
      "2021 IEEE Pulsed Power Conference (PPC)\r\n",
      "----------\r\n",
      "01 Jun - 04 Jun 2021\r\n",
      "----------\r\n",
      "Sheraton Denver Downtown Hotel\r\n",
      "----------\r\n",
      "2021 IEEE 71st Electronic Components and Technologies Conference (ECTC)\r\n",
      "----------\r\n",
      "01 Jun - 04 Jun 2021\r\n",
      "----------\r\n",
      "Sheraton San diego Hotel & Marina\r\n",
      "----------\r\n",
      "2021 IEEE Symposium on Security and Privacy (SP)\r\n",
      "----------\r\n",
      "23 May - 27 May 2021\r\n",
      "----------\r\n",
      "Hyatt Regency San Francisco\r\n",
      "----------\r\n",
      "2021 IEEE International Workshop Technical Committee on Communications Quality and\r\n",
      "Reliability (CQR 2021)\r\n",
      "----------\r\n",
      "09 May - 14 May 2021\r\n",
      "----------\r\n",
      "Naples Beach Hotel & Golf Club\r\n",
      "----------\r\n",
      "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\r\n",
      "----------\r\n",
      "25 Apr - 30 Apr 2021\r\n",
      "----------\r\n",
      "Metro Toronto Convention Centre\r\n",
      "----------\r\n",
      "2020 IEEE International Electron Devices Meeting (IEDM)\r\n",
      "----------\r\n",
      "10 Dec - 18 Dec 2020\r\n",
      "----------\r\n",
      "Hilton San Francisco\r\n",
      "----------\r\n"
     ]
    }
   ],
   "source": [
    "!python src/ds3_5_readIEEE.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* 학회를 검색하는 폼에 입력하면, 검색문자열을 생성한다. 다음은 검색문자열이 포함된 url이다. 검색을 하는 경우 크롤링을 해본다.\n",
    "```\n",
    "http://www.ieee.org/conferences_events/conferences/search/index.html?\n",
    "RANGE_FROM_DATE=2017-01-01&RANGE_TO_DATE=2030-12-31&\n",
    "KEYWORDS=&\n",
    "COUNTRY=ALL&STATE=ALL&CITY=ALL&REGION=ALL&\n",
    "RECORD_NUM=ALL&SPONSOR=ALL&EXHIBIT=ALL&TUTORIALS=ALL&\n",
    "RowsPerPage=10&PageLinkNum=10&ActivePage=1&\n",
    "SORTORDER=asc&SORTFIELD=start_date&ROWSTART=0&CONF_SRCH_RDO=conf_date&\n",
    "utm_source=mm_link&utm_campaign=upcom&utm_medium=conf&utm_term=upcoming%20conferences\n",
    "```\n",
    "\n",
    "* 학회명, 학회일시, 학회장소를 구분해서 추출해 본다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-6: 한국 프로야구 팀 순위 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "최근 스포츠에 과학기법을 많이 활용하고 있다. 세밀한 차이가 승패를 좌우하는 까닭에 실시간으로 데이터를 분석해 보다 과학적으로 순간 순간의 결정에 활용하고 있다. 야구가 좋은 예이다. 많은 데이터를 가지고, 특정 투수에 대한 선수의 약점, 선수에 대한 필드의 배치를 결정하기도 한다.\n",
    "한국 프로야구 팀의 순위를 가져오기로 한다.\n",
    "\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지로 가서 소스보기를 해본다. \n",
    "기록이 테이블 형식으로 구성되어 있다.\n",
    "야구선수 또는 팀은 한글이다. 검색하려면 unicode로 패턴 찾는다. 한글 앞에 unicode를 의미하는 u'타자'라고 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kbreport.com/leader/main?rows=20&order=oWAR&orderType=DESC&teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import requests\n",
    "urlbase=\"http://www.kbreport.com/leader/main?\"\n",
    "url1=\"rows=20&order=oWAR&orderType=DESC&\"\n",
    "url2=\"teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\"\n",
    "urlbaseball=urlbase+url1+url2\n",
    "print urlbaseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kbreport.com/leader/main?rows=20&order=oWAR&orderType=DESC&teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\n",
      " href=\"/history/main\"><li>역대기록</li></a>\n",
      "\t\t\t\t\t<a href=\"/statDic/main\"><li id=\"nav4\">STAT Dic</li></a>\n",
      "\t\t\t\t\t<a href=\"/event/hitProbabilityPerGame\"><li>투수 VS 타자</li></a>\n",
      "\t\t\t\t\t<!-- \n",
      "\t\t\t\t\t<a href=\"score.html\"><li id=\"nav1\">경기결과</li></a>\n",
      "\t\t\t\t\t<a href=\"/statBuzz/main\"><li id=\"nav2\">STAT BUZZ</li></a>\n",
      "\t\t\t\t\t<a href=\"depth.html\"><li>팀구성도</li></a>\n",
      "\t\t\t\t\t<a href=\"trade.html\"><li>선수이동내역</li></a>\n",
      "\t\t\t\t\t<a href=\"/leader/main\"><li>개인순위</li></a>\n",
      "\t\t\t\t\t<a href=\"team.html\"><li>팀순위</li></a>\n",
      "\t\t\t\t\t<a href=\"awa\n"
     ]
    }
   ],
   "source": [
    "data=requests.get(urlbaseball).text\n",
    "print data[6000:6500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6340\n",
      "8353\n"
     ]
    }
   ],
   "source": [
    "print data.find('top-score-top')\n",
    "print data.find('top-score end')\n",
    "\n",
    "#import re\n",
    "#p=re.compile('NC\\w+')\n",
    "#res=re.search('<title>', data)\n",
    "#res=re.search(u'타자.+', data)\n",
    "#res=re.search(u'야구.통계.+', data)\n",
    "#print res.group()\n",
    "\n",
    "#data.encode('utf-8')\n",
    "#print data\n",
    "#from BeautifulSoup import BeautifulSoup\n",
    "#BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r']\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n"
     ]
    }
   ],
   "source": [
    "mydata=data[6340:8353+len('top-score end')]\n",
    "import re\n",
    "p=re.compile(u'.승.+')\n",
    "#p=re.compile(u'.두산.')\n",
    "#res=p.search(data)\n",
    "found=p.findall(mydata)\n",
    "print found\n",
    "for item in found:\n",
    "    print item\n",
    "#print res.group()\n",
    "#findall?\n",
    "#print res.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## xpath\n",
    "\n",
    "* url\n",
    "http://www.kbreport.com/main\n",
    "\n",
    "* 경기결과의 표 구성: 11줄 (표 제목 포함)\n",
    "    * 표 제목 (table header) th\n",
    "    * 표 행 (table row ) tr\n",
    "    * 표 셀 (table cell) td\n",
    "\n",
    "순위 | 팀명 | 승 | 무 |  |  |  |  |  |  | 연속\n",
    "----|-----|---|---|--|--|--|--|--|--|--\n",
    "1   |     |   |   |  |  |  |  |  |  | 2승\n",
    "2   |     |   |   |  |  |  |  |  |  | 2패\n",
    "\n",
    "* selector\n",
    "\n",
    "xpath | 결과\n",
    "-----|-----\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")``` | 표 11줄\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td\")``` | 100개\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td[@class='center']\")``` | 20개\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td//a\")``` | 팀명 10개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* requests를 사용해서 url을 읽어온다.\n",
    "* 전체 길이를 len()을 사용해서 알 수 있다.\n",
    "* lxml을 사용해서 tree 구조를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://www.kbreport.com/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50011"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "_htmlTree = lxml.etree.HTML(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* tree에서 전체 행 11개를 가져온다.\n",
    "* 행의 셀이 서로 구조가 다르다. 잘 읽어 오는지 확인한다.\n",
    "    * 팀명은 a href로 구성되어 있고, 결과는 배열이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 [] [] Next Row\n",
      "1 [u'\\ub450\\uc0b0'] [] Next Row\n",
      "2 ['NC'] [] Next Row\n",
      "3 [u'\\ub125\\uc13c'] [] Next Row\n",
      "4 ['LG'] [] Next Row\n",
      "5 ['KIA'] [] Next Row\n",
      "6 ['SK'] [] Next Row\n",
      "7 [u'\\ud55c\\ud654'] [] Next Row\n",
      "8 [u'\\ub86f\\ub370'] [] Next Row\n",
      "9 [u'\\uc0bc\\uc131'] [] Next Row\n",
      "10 ['kt'] [] Next Row\n"
     ]
    }
   ],
   "source": [
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    print teams[0].text, teams[1].xpath('.//a/text()'), teams[2].xpath('.//a/text()'),\n",
    "    print \"Next Row\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* nodes는 결과가 여러 개 목록이므로 배열\n",
    "* 배열 nodes의 개별 요소 teams는 '_Element'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'lxml.etree._Element'>\n"
     ]
    }
   ],
   "source": [
    "print type(nodes)\n",
    "print type(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0번째 행:  tr\n",
      "-- 1번째 행, 태그: [<Element th at 0x7fbe8504b368>, <Element th at 0x7fbe84facf80>, <Element th at 0x7fbe84fac908>, <Element th at 0x7fbe84fac9e0>, <Element th at 0x7fbe84fac950>, <Element th at 0x7fbe84fac878>, <Element th at 0x7fbe84faca28>, <Element th at 0x7fbe84facdd0>, <Element th at 0x7fbe84facb00>, <Element th at 0x7fbe84facb48>]\n",
      "-- 2번째 행, 태그 2번째 (팀명): 두산\n",
      "-- 2번째 행, 태그 3번째 문자열: 93\n",
      "-- 2번째 행, 태그 3번째 태그: td\n"
     ]
    }
   ],
   "source": [
    "print \"-- 0번째 행: \", nodes[0].tag\n",
    "print \"-- 1번째 행, 태그:\", nodes[0].getchildren()\n",
    "print \"-- 2번째 행, 태그 2번째 (팀명):\", nodes[1].getchildren()[1].xpath(\".//a\")[0].text\n",
    "print \"-- 2번째 행, 태그 3번째 문자열:\", nodes[1].getchildren()[2].text\n",
    "print \"-- 2번째 행, 태그 3번째 태그:\", nodes[1].getchildren()[2].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 연습 후, if문으로 a link와 아닌 경우로 나누어 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\n"
     ]
    }
   ],
   "source": [
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    for cols in teams:\n",
    "        if cols.xpath('.//a/text()'):\n",
    "            print cols.xpath('.//a/text()')[0],\n",
    "        else:\n",
    "            print cols.text.strip(),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```\n",
    "\n",
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds_web_crawl_kbaseball.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lxml.etree\n",
    "\n",
    "r = requests.get('http://www.kbreport.com/main')\n",
    "_htmlTree = lxml.etree.HTML(r.text)\n",
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    for cols in teams:\n",
    "        if cols.xpath('.//a/text()'):\n",
    "            print cols.xpath('.//a/text()')[0],\n",
    "        else:\n",
    "            print cols.text.strip(),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 구조를 만들어 프로그램으로 만든다.\n",
    "    * 라이브러로 만들거나,\n",
    "    * 테스트하거나,\n",
    "    * 시작 점을 분명하게 할 수 있다.\n",
    "* main() 함수\n",
    "    * ```if __name__ == \"__main__\"```는 명령창에서 실행할 경우, 처음 실행되는 main()함수 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ds_web_crawl_kbaseball.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds_web_crawl_kbaseball.py\n",
    "# coding: utf-8\n",
    "import requests\n",
    "import lxml.etree\n",
    "\n",
    "def getkb():\n",
    "    r = requests.get('http://www.kbreport.com/main')\n",
    "    _htmlTree = lxml.etree.HTML(r.text)\n",
    "    nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "    print \"테이블 행 갯수: \", len(nodes)\n",
    "    counter=0\n",
    "    for teams in nodes:\n",
    "        for cols in teams:\n",
    "            if cols.xpath('.//a/text()'):\n",
    "                print cols.xpath('.//a/text()')[0],\n",
    "            else:\n",
    "                print cols.text.strip(),\n",
    "        print\n",
    "\n",
    "def main():\n",
    "    getkb()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\r\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\r\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\r\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\r\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\r\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\r\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\r\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\r\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\r\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\r\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\r\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\r\n"
     ]
    }
   ],
   "source": [
    "!python src/ds_web_crawl_kbaseball.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.9 동적 페이지에서 데이터 수집\n",
    "\n",
    "### 1.9.1 동적 페이지\n",
    "\n",
    "HTML은 정적페이지, Static Web Page이다. 웹페이지가 열리면, 단순히 읽을 수 있기만 가능하다. 열린 페이지는 내용이 변경되지 않는다.\n",
    "\n",
    "동적페이지는 사용자의 요청, 상황에 따라 내용이 변경된다. 클라이언트측 또는 서버측에서 그 페이지를 갱신할 수 있다.\n",
    "클라이언트측에서는 예를 들면 자바스크립트를 사용하여 사용자가 요청하면 내용이 새로 생성되어 웹페이지 변경된다.\n",
    "서버측에서도 내용을 변경하여 클라이언트로 전송할 수 있다. JSP, PHP를 사용하는 것이 좋은 예다.\n",
    "특히 자바스크립트가 포함된 페이지는 추출하려는 내용이 동적으로 생성되기 때문에 문제가 된다. HTML 파서는 정적페이지에서 정보를 추출하기 때문이다. 동적페이지는 자바스크립트를 실행하면서 데이터를 추출해야 한다.\n",
    "\n",
    "구분 | 설명 | 언어\n",
    "-----|-----|-----\n",
    "클라이언트 측 스크립트 | 클라이언트 측에서 내용이 변경된다. 사용자가 웹페이지에서 마우스 클릭 또는 키보드 입력을 하면 클라이언트에서 내용이 생성되어 페이지를 변경한다. | Javascript, Flash\n",
    "서버 측 스크립트 | 서버측에서 내용을 생성하여 전송된다. 웹페이지를 변경하려면 서버로 전송, 처리 결과를 받아서 변경한다.  | JSP, PHP, ASP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.9.2 Selenium\n",
    "\n",
    "GUI화면을 프로그램으로 조작할 수 있는 라이브러리이다. Python, Java, Javascript, Perl, PHP, C# 등 많은 언어를 지원한다. 테스트 또는 스크레이핑할 경우 활용된다.\n",
    "\n",
    "#### Selenium 설치\n",
    "\n",
    "Python에서 사용하므로, pip를 사용하여 설치한다.\n",
    "```\n",
    "pip install selenium\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### driver\n",
    "\n",
    "웹브라우저를 프로그램에서 호출하여 사용하기 위한 driver이다. 크롬을 설치하려면 운영체제에서 설치하는 것이 좋다.\n",
    "설치하고 나면 아래와 같이 버전을 출력할 수 있다. 경로가 설정되지 않으면 Python에서 경로오류가 발생한다.\n",
    "\n",
    "```\n",
    "sudo port install ChromeDriver # osx\n",
    "pip install chrome-driver # Ubuntu\n",
    "```\n",
    "\n",
    "설치하고 나면 쉘에서 버전을 확인할 수 있다.\n",
    "Python에서 사용하려면, 'webdriver.chrome.driver'를 사전에 설정한다.\n",
    "os.environ[\"webdriver.chrome.driver\"]=\"/usr/local/bin/chromedriver\"\n",
    "\n",
    "\n",
    "위에서 driver를 설정하면 웹브라우저가 뜨게 된다. 그러나 브라우저 없이 프로그램에서 driver를 사용할 경우에는 PhantomJS를 사용한다. 이를 headless brower라고 한다.\n",
    "\n",
    "```\n",
    "npm install -g phantomjs(o)\n",
    "apt install phantomjs (x, 부분설치)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromeDriver 2.26.436382 (70eb799287ce4c2208441fc057053a5b07ceabac)\r\n"
     ]
    }
   ],
   "source": [
    "!chromedriver -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.9.3 간단한 명령어\n",
    "\n",
    "* send_keys()\n",
    "* click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python.org에서 검색어를 프로그램에서 정해서 실행을 요청해 보자.\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "find_element_by_name(\"q\") | 'name'이 \"q\"인 태그를 찾는다.\n",
    "send_keys(\"pycon\") | 키보드 입력을 대신한다. \"pycon\"을 입력한다는 의미이다.\n",
    "send_keys(Keys.RETURN) | 'Keys.RETURN' 키보드 엔터를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#driver = webdriver.Chrome()\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "#assert \"No results found.\" not in driver.page_source\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyCon Pakistan\n",
      "Kiwi PyCon 2017\n",
      "PyCon Pune 2018\n",
      "Florida PyCon\n",
      "PyCon Colombia 2018\n",
      "PyCon India 2017\n",
      "PyCon Jamaica 2017\n",
      "PyCon FR 2017\n",
      "PyCon Ireland 2017\n",
      "PyCon Australia 2013\n",
      "PyCon Ireland 2012\n",
      "PyCon Ireland 2016\n",
      "PyCon Uruguay 2013\n",
      "PyCon US 2014\n",
      "PyCon Ukraine 2016\n",
      "Kiwi PyCon 2016\n",
      "PyCon US 2019\n",
      "PyCon UK 2013\n",
      "PyCon Italia 5\n",
      "PyCon CZ 2017\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "_html=driver.page_source\n",
    "soup=BeautifulSoup(_html,\"lxml\")\n",
    "for e in soup.select(\"h3 a\"):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-7: 로그인이 필요한 사이버강의실에서 강의계획서를 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "사이버강의실은 강의관련 공지, 강의계획서, 강의슬라이드와 같은 자료를 제공한다. 학교의 사이버강의실은 보통 개방되어 있지 않고 사용자의 로그인이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 해결\n",
    "\n",
    "* 사용자이름, 비밀번호를 넣을 수 있는 서식을 찾는다.\n",
    "* 이름, 비밀번호에 값을 넣는다.\n",
    "* 서버요청 버튼을 찾아서 클릭한다.\n",
    "* 여러 교과목 가운데 수강과목을 찾아 클릭한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://ecampus.smu.ac.kr/\")\n",
    "username=driver.find_element_by_id(\"input-username\")\n",
    "username.send_keys(\"myuserid\")\n",
    "password=driver.find_element_by_id(\"input-password\")\n",
    "password.send_keys(\"mypassword\")\n",
    "loginButton=driver.find_element_by_name(\"loginbutton\")\n",
    "loginButton.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* My Page로 가면 교과목 목록을 볼 수 있다.\n",
    "* 교과목 목록에서 \"컴퓨팅사고\" 과목을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mypage=driver.find_element_by_link_text(\"My Page\")\n",
    "mypage.click()\n",
    "mypage=driver.find_element_by_partial_link_text(\"컴퓨팅사고\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/ds3_7_ecampus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_7_ecampus.py\n",
    "from selenium import webdriver\n",
    "\n",
    "def readEcampus():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://ecampus.smu.ac.kr/\")\n",
    "    username=driver.find_element_by_id(\"input-username\")\n",
    "    username.send_keys(\"myuserid\")\n",
    "    password=driver.find_element_by_id(\"input-password\")\n",
    "    password.send_keys(\"mypassword\")\n",
    "    loginButton=driver.find_element_by_name(\"loginbutton\")\n",
    "    loginButton.click()\n",
    "\n",
    "    mypage=driver.find_element_by_link_text(\"My Page\")\n",
    "    mypage.click()\n",
    "    mypage=driver.find_element_by_partial_link_text(\"컴퓨팅사고\")\n",
    "\n",
    "def main():\n",
    "    #readWikiLxml()\n",
    "    readWikiBS()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-8: 한국 프로야구 선수 기록 크롤링하기 (1)\n",
    "\n",
    "### 문제\n",
    "\n",
    "앞서 팀순위를 가져오는 프로그램을 만들었다. 선수기록을 가져와보자. 이전에 했던 방식으로 하면 가져올 수 없다는 것을 알게 된다.\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지로 가서 소스보기를 해본다. \n",
    "선수기록은 동적인 페이지로 구성되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 자바스크립트가 포함된 페이지\n",
    "\n",
    "* 야구데이터는 검색엔진을 이용하며, 검색결과가 정적인 HTML로 반환되지 않고 있다. 그래서 자세한 검색에 대한 결과를 스크레이핑 하려면 이 문제를 해결해야 한다.\n",
    "* 동적페이지, javascript가 페이지를 생성하면 크롤링을 할 수 없다.\n",
    "클래스 \".ltb-table\"는 테이블 조회결과이다. 개발자도구 콘솔에서 자바스크립트로 보면 그결과를 볼 수 있지만, BeautifulSoup에서는 불가능하다.\n",
    "\n",
    "http://www.kbreport.com/leader/main페이지를 살펴보면, '#/{{page}}'과 같이 내부 href를 생성하고 있다.\n",
    "\n",
    "```\n",
    "\t$(document).ready(function(){\n",
    "\t\tpaging.action({\n",
    "\t\t\tid : \"paging\"\n",
    "\t\t\t, totalCount : setNumber('284')\n",
    "\t\t\t, page : setNumber('1')\n",
    "\t\t\t, rows : setNumber('20')\n",
    "\t\t\t, allView : true\n",
    "\t\t\t, pageGroup : 5\n",
    "\t\t\t, link : \"#/{{page}}\"\n",
    "\t\t});\n",
    "\t\tswitched=false;\n",
    "\t\tupdateTables();\n",
    "\t});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* '더보기 >>' 버튼의 크롤링\n",
    "* css 크롤링\n",
    "* 검색조건을 넣어서 크롤링\n",
    "    * url 검색 'http://www.kbreport.com/player/list?key=이대호'\n",
    "\n",
    "    * javascript console 창\n",
    "```\n",
    "> $$('.dca-cb-table1 td')[0].innerText\n",
    "\"이대호\"\n",
    "> $$('.dca-cb-table1 td')[1].innerText\n",
    "\"1982-06-21\"\n",
    "> $$('.dca-cb-table1 td')[2].innerText\n",
    "\"2017\"\n",
    "> $$('.dca-cb-table1 td')[3].innerText\n",
    "\"롯데\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-9: 한국 프로야구 선수 기록 크롤링하기 (2)\n",
    "\n",
    "### 문제\n",
    "\n",
    "다른 사이트 www.koreabaseball.com를 스크레이핑해보자.\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지를 가져온다.\n",
    "데이터를 추출한다.\n",
    "단, paging에 javascript이 있어서 추가 작업이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "urlkorbase='http://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx'\n",
    "data=requests.get(urlkorbase).text\n",
    "#print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-10: 다음에서 환율 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "다음에 게시되고 있는 환율을 추출해 보자.\n",
    "자바스크립트가 포함되어 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습\n",
    "\n",
    "* 크롤링은 수집하는 데이터가 비구조적이라 쉽지 않다.\n",
    "* 관심있는 웹 사이트를 대상으로 크롤링을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-1: UC Irvine 기계학습 데이터\n",
    "\n",
    "* UC Irvine 기계학습 데이터 banknote authentication Data Set를 프로그래밍으로 가져와서 \n",
    "클래스별로 'entropy of image'의 평균을 구하시오\n",
    "* http://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-2: 기상청 도별 날씨 가져오기\n",
    "\n",
    "### 문제\n",
    "날씨는 다양하게 소비되고 있다. 농사, 스포츠, 야외행사, 그날의 의상 등 많은 경우에 날씨가 적지 않게 영향을 미치고 있다. 날씨는 API를 직접 사용하거나, 웹페이지에서 추출할 수 있다. 기상청 웹페이지에 게시되고 있는 날씨를 가져와 보자.\n",
    "\n",
    "* 기상청 http://www.kma.go.kr/index.jsp의 날씨\n",
    "* css selector\n",
    "    ```\n",
    "    $$('.region_weather_e')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-3: 국가통계 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "http://kosis.kr/index/index.jsp\n",
    "kosis='http://kosis.kr/statisticsList/statisticsList_01List.jsp?vwcd=MT_ZTITLE&parentId=A#SubCont'\n",
    "data=requests.get(urlkorbase).text\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-4: 신문 기사 및 댓글 스크레이핑 해보기\n",
    "\n",
    "\n",
    "우리나라 한국은행이 빅데이터를 활용해 경제정책에 반영하는 방안을 마련하고 있다. 세계 여러 나라가 웹에서 수집한 데이터를 활용해 물가, 소비, 경제심리와 관련한 통계 및 분석에 활용하는 추세에 발맞추어 가는 것으로 보인다. 한국은행은 빅데이터 업무를 담당할 '빅데이터통계연구반'을 설치하고 2017년 8월 활동을 시작했다고 한다.\n",
    "SNS, 경제기사에 대한 댓글, 경제관련 기사를 분석하여 경제정책에 반영할 계획으로 알려졌다.\n",
    "* [BIG KINDS-Pro](http://www.bigkinds.or.kr/)\n",
    "    * 2016년 개편 후, 데이터분석 기능을 제공\n",
    "    * 스크레이핑의 params이 검색에 문자열로 붙지 않는 문제가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-5: 영화 리뷰의 분석\n",
    "\n",
    "### 문제\n",
    "\n",
    "'어떤 영화를 볼까?'라고 질문에 댓글을 읽어보고 결정하는 사람들이 꽤 있다.\n",
    "온라인 상에는 상영하고 있는 영화에 댓글을 다는 기능이 있다.\n",
    "댓글에서 의미있는 데이터를 추출하여 영화에 대해 긍정적, 부정적 의견이 어떠한지 분류할 수 있다.\n",
    "댓글을 분석하여 해당 영화의 매출을 예측하기도 한다.\n",
    "영화 리뷰를 분석하여 의미있는 정보를 추출하는 관련 학술 논문이 많다.\n",
    "\n",
    "* http://movielens.org\n",
    "* Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. \"Thumbs up?: sentiment classification using machine learning techniques.\" Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10. Association for Computational Linguistics, 2002."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
