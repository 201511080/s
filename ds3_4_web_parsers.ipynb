{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 웹 데이터 추출\n",
    "\n",
    "* Last updated: 20180403TUE1140 20170917 20170401 20161004\n",
    "\n",
    "## 1.1 학습내용\n",
    "\n",
    "### 1.1.1 목표\n",
    "\n",
    "* 웹에서 가져온 페이지를 파싱할 수 있다.\n",
    "* 웹페이지에서 xpath, css selector를 사용하여 데이터를 추출할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.2 목차\n",
    "\n",
    "* 1.2 Parsing\n",
    "* 1.3 Developer tools\n",
    "* 1.3.1 브라우저에서 Javascript concole 창 열기\n",
    "* 1.3.2 Console 창에서 selector 찾기¶ \n",
    "* 1.3.3 Elements 창에서 selector 찾기\n",
    "* 1.4 dom \n",
    "* 1.5 BeautifulSoup\n",
    "* 1.5.1 설치\n",
    "* 1.5.2 BeautifulSoup 객체\n",
    "* 1.5.3 태그 객체\n",
    "* 1.5.4 문자열 객체\n",
    "* 1.5.5 Comment 객체\n",
    "* 1.5.6 찾기\n",
    "* 1.6 regex\n",
    "* 1.6.1 문자, 순자 추출해 보기\n",
    "* 1.6.2 BeautifulSoup과 같이 regex를 사용\n",
    "* --- \n",
    "* 1.7 xpath\n",
    "* 1.7.1 lxml\n",
    "* 1.7.2 파일에서 파싱\n",
    "* 1.7.2 문자열에서 파싱\n",
    "* 1.8 css selectors\n",
    "* 1.8.1 html에서 css \n",
    "* 1.8.2 lxml을 사용해서 하기\n",
    "* 1.8.3 BeautifulSoup을 사용해서 하기\n",
    "* 1.8.4 테이블을 읽기\n",
    "---\n",
    "* 1.9 동적 페이지에서 데이터 수집\n",
    "* 1.9.1 동적 페이지\n",
    "* 1.9.2 Selenium\n",
    "* 1.9.3 간단한 명령어\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.3 문제\n",
    "\n",
    "* 문제 웹데이터-1: python.org 페이지가 가지고 있는 최근 뉴스 출력하기\n",
    "* 문제 웹데이터-2: python.org 페이지를 크롤링해서 http url를 출력하기\n",
    "    * BeautifulSoup, regex, xpath, css selector\n",
    "* 문제 웹데이터-3: 위키에서 'python'을 검색해서 http url을 출력하기\n",
    "    * 위키에서 검색하기, 위키에서 css selector\n",
    "* 문제 웹데이터-4: 한국 포털사이트에서 노래 제목을 검색해서 가져오기\n",
    "    * regex, lxml css selector - 노래제목, 아티스트, 앨범 출력\n",
    "* 문제 웹데이터-5: 국제학회 목록을 가져오기\n",
    "    * lxml css.selector, Scrapy에서 연속 추출\n",
    "* 문제 웹데이터-6: 한국 프로야구 팀순위 가져오기\n",
    "    * kbreport.com, regex 단순 문자열 검색, xpath\n",
    "* 문제 웹데이터-7: 로그인이 필요한 사이버강의실에서 강의계획서를 가져오기\n",
    "* 문제 웹데이터-8: 한국 프로야구 선수 기록 크롤링하기 (1)\n",
    "* 문제 웹데이터-9: 한국 프로야구 선수 기록 크롤링하기 (2)\n",
    "* 문제 웹데이터-10: 다음에서 환율 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.4 연습\n",
    "\n",
    "* 연습 웹데이터-1: UC Irvine 기계학습 데이터\n",
    "* 연습 웹데이터-2: 기상청 도별 날씨 가져오기기\n",
    "* 연습 웹데이터-3: 국가통계 가져오기\n",
    "* 연습 웹데이터-4: 신문 크롤링 해보기\n",
    "* 연습 웹데이터-5: 영화 리뷰의 분석\n",
    "* 주식, tripadvisor는 'scrapy'에서 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Parsing\n",
    "\n",
    "파싱은 입력데이터를 **자료구조로 변환**하는 것을 말한다. 우리가 말하는 문장은 주어, 목적어, 동사와 같은 문법구조로 파싱할 수 있다. 웹데이터도 자료구조, **보통 '트리' 구조**로 변환해서 원하는 항목을 추출할 수 있다.\n",
    "\n",
    "* 웹데이터는 **'문자'**이다. 앞 서 설명한 바와 같이 '숫자'도 문자로 인식된다.\n",
    "* 파싱을 하지 않으면, 태그를 추출하기 위해서는 문자 하나 하나씩 처리해야 하기 때문에 많은 노력이 필요하다.\n",
    "* 예를 들어 ```<h1>...</h1>```은 **부등호문자,h,1과 같은 문자로 구성**된 것으로 간주한다.\n",
    "* 따라서 시작태그, 끝태그를 찾으려면 꽤 복잡한 처리과정이 필요하다.\n",
    "* 요약하면, 웹데이터는 문자로 만들어져 있고 태그구조를 가지고 있지만, 태그를 처리하기 용이한 tree구조를 만들어야 한다는 점에 유의한다.\n",
    "* 파싱을 하면, 이런 **태그 요소를 분리하고, tree구조로 만들어** 분석을 용이하게 할 수 있다.\n",
    "* HTML DOM, XML, json은 tree 구조를 가지고, 특정 요소를 선택할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 프로그램에서 하는 일을 단계 별로 살펴보자. 우선 파서를 선택하고, html을 읽어서 tree구조로 변환한 후, 필요한 데이터항목을 추출하는 다음 과정을 실행한다.\n",
    "\n",
    "단계 | 작업절차 | BeautifulSoup 예 | lxml 예\n",
    "-----|-----|-----|-----\n",
    "단계 1 | 사용하려는 파서 선택 | from bs4 import BeautifulSoup | import lxml.etree\n",
    "단계 2 | 페이지를 파싱하고, 트리를 생성한다 | soup=BeautifulSoup('my.html') | tree=lxml.etree.parse('my.html')\n",
    "단계 3 | 트리에서 필요한 요소를 정한다. | 태그, 클래스... | 좌동\n",
    "단계 4 | 필요한 요소를 가져온다. | soup.select() | tree.xpath() 또는 tree.css()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"465px\" style=\"width:303px;height:465px;\" version=\"1.1\" viewBox=\"0 0 303 465\" width=\"303px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><filter height=\"300%\" id=\"f1\" width=\"300%\" x=\"-1\" y=\"-1\"><feGaussianBlur result=\"blurOut\" stdDeviation=\"2.0\"/><feColorMatrix in=\"blurOut\" result=\"blurOut2\" type=\"matrix\" values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0\"/><feOffset dx=\"4.0\" dy=\"4.0\" in=\"blurOut2\" result=\"blurOut3\"/><feBlend in=\"SourceGraphic\" in2=\"blurOut3\" mode=\"normal\"/></filter></defs><g><ellipse cx=\"150\" cy=\"18\" fill=\"#000000\" filter=\"url(#f1)\" rx=\"10\" ry=\"10\" style=\"stroke: none; stroke-width: 1.0;\"/><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"158\" x=\"71\" y=\"68\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"138\" x=\"81\" y=\"89.1387\">stage 1: import library</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"175\" x=\"62.5\" y=\"142\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"155\" x=\"72.5\" y=\"163.1387\">stage 2: get html strings</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"243\" x=\"28.5\" y=\"216\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"223\" x=\"38.5\" y=\"237.1387\">stage 3: transform strings to a tree</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"182\" x=\"59\" y=\"290\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"162\" x=\"69\" y=\"311.1387\">stage 4: define a selector</text><rect fill=\"#FEFECE\" filter=\"url(#f1)\" height=\"33.9688\" rx=\"12.5\" ry=\"12.5\" style=\"stroke: #A80036; stroke-width: 1.5;\" width=\"288\" x=\"6\" y=\"364\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"12\" lengthAdjust=\"spacingAndGlyphs\" textLength=\"268\" x=\"16\" y=\"385.1387\">stage 5: get selected elements of the tree</text><ellipse cx=\"150\" cy=\"448\" fill=\"none\" filter=\"url(#f1)\" rx=\"10\" ry=\"10\" style=\"stroke: #000000; stroke-width: 1.0;\"/><ellipse cx=\"150.5\" cy=\"448.5\" fill=\"#000000\" rx=\"6\" ry=\"6\" style=\"stroke: none; stroke-width: 1.0;\"/><path d=\"M150,28.038 C150,36.932 150,50.844 150,62.572 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,67.781,154,58.781,150,62.781,146,58.781,150,67.781\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,102.338 C150,112.464 150,125.584 150,136.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,141.727,154,132.727,150,136.727,146,132.727,150,141.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,176.338 C150,186.464 150,199.584 150,210.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,215.727,154,206.727,150,210.727,146,206.727,150,215.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,250.338 C150,260.464 150,273.584 150,284.543 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,289.727,154,280.727,150,284.727,146,280.727,150,289.727\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,324.338 C150,334.464 150,347.584 150,358.5432 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,363.7267,154,354.7267,150,358.7267,146,354.7267,150,363.7267\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><path d=\"M150,398.0674 C150,408.5986 150,422.2536 150,432.4618 \" fill=\"none\" style=\"stroke: #A80036; stroke-width: 1.0;\"/><polygon fill=\"#A80036\" points=\"150,437.7367,154,428.7367,150,432.7367,146,428.7367,150,437.7367\" style=\"stroke: #A80036; stroke-width: 1.0;\"/></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%plantuml\n",
    "@startuml\n",
    "(*)--> \"stage 1: import library\"\n",
    "--> \"stage 2: transform web page string to a tree\"\n",
    "--> \"stage 3: define a selector\"\n",
    "--> \"stage 4: get selected elements of the tree\"\n",
    "-->(*)\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* parsing 관련 라이브러리\n",
    "    * HTMLParser - Python에서 **기본**으로 제공\n",
    "    * BeautifulSoup - lxml을 사용해서 구현된 parser (css는 지원하지만 XPath 지원하지 않는다.)\n",
    "    * lxml - C로 구현되어서 빠르다. 단독 또는 BeautifulSoup에서 사용할 수 있다. xml, html 파싱을 할 수 있다.\n",
    "    * regex - HTML 파서가 아니다. 패턴으로 파싱을 한다. BeautifulSoup과 같은 파서와 결합하여 사용할 수 있다.\n",
    "    * pyquery - jquery와 같은 기능의 라이브러리\n",
    "    * scrapy - 프레임워크로 대규모 프로젝트에 적합하다. 파이프라인pipelines을 사용하므로 빠르다.\n",
    "\n",
    "구분 | 라이브러리 | 설명\n",
    "-----|-----|-----\n",
    "웹데이터 수집 | urllib, requests, curl | 웹페이지 열고, http request(s), http response(s)\n",
    "웹데이터 파싱 | HTMLParser, BeautifulSoup, lxml, regex | 문자열 또는 xml, json을 파싱\n",
    "프레임워크 | scrapy (java nutch, crawler4j) | 큰 프로젝트에 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3 Developer tools\n",
    "\n",
    "파싱을 하려면 **HTML 소스**를 펼쳐 놓고, '요소' 즉 element를 찾아야 편리하다. Chrome 개발자 도구를 이용하면 찾기 편리하다. 구글 사이트에 사용법이 자세하게 설명되어 있다 https://developers.google.com/web/tools/chrome-devtools/console/. 이 창에서 css selector를 테스트하고 프로그램에 넣으면 편리하다.\n",
    "\n",
    "### 1.3.1 브라우저에서 Javascript concole 창 열기\n",
    "\n",
    "브라우저 | 콘솔창\n",
    "-----|-----\n",
    "Chrome | 브라우저 우측 상단 메뉴 > More tools > Developer Tools 또는 F12\n",
    "Internet Explorer | F12\n",
    "Firefox | Tools > Web Developer > Inspector\n",
    "Safari | advanced preferences > enable Develop menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3.2 Javascript console 창에서 selector 찾기\n",
    "\n",
    "콘솔창에서 javascript를 사용하여 selector를 추출할 수 있다.\n",
    "**xpath는 ```$x()```**, **css selecotr는 ```$()```**를 사용한다.\n",
    "\n",
    "단축키 | 설명\n",
    "-----|-----\n",
    "\\$x('xpath') | XPath와 일치하는 요소의 배열을 반환\n",
    "\\$('selector') | CSS 선택기와 일치하는 첫 번째 요소를 반환, document.querySelector()의 단축\n",
    "\\$$('selector all') | CSS 선택기와 일치하는 모든 요소의 배열을 반환, document.querySelectorAll()의 단축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* HTML title을 xpath, css로 추출하는 예이다. selector 텍스트를 추출하려면 'innerText'를 사용한다.\n",
    "\n",
    "선택 | xpath | css\n",
    "-----|-----|-----\n",
    "title태그 선택 | ```$x('//head/title') 또는 $x('//title')``` | ```$$('title')```\n",
    "선택의 결과가 복수인 경우, 배열을 반환 | ```$x('//head/title')[0]``` | ```$$('title')[0]```\n",
    "태그의 문자열을 추출 | ```$x('//head/title')[0].innerText``` | ```$$('title')[0].innerText```\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3.3 Elements 창에서 selector 찾기\n",
    "\n",
    "'Elements' 메뉴에서 xpath 또는 selector를 사용할 수 있다.\n",
    "\n",
    "* html소스에서\n",
    "    * html tag를 누르면 맨 앞 '...'가 생김\n",
    "    * 이것을 누르면 팝업메뉴가 뜬다. 그리고 copy > xpath(또는 selector)를 선택하여 복사\n",
    "* 또는 단축키 **```<CTRL-F>```**로 '검색'창을 열고 검색 문자열, xpath, selector를 입력한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4 dom\n",
    "\n",
    "* HTML을 파싱해서 tree구조로 변환할 수 있다.\n",
    "* 이러한 html tree구조를 **DOM, Document Object Model**이라고 한다.\n",
    "* DOM의 각 노드는 html의 태그가 되고, 이를 읽어오고 쓰는 기능 API를 제공한다.\n",
    "* DOM에서 특정 노드를 선택해 몇 가지 쉬운 기능을 사용해보자.\n",
    "* **document.querySelector()**를 사용해 '.my'라는 클래스를 선택한다. 앞의 점이 class를 의미한다.\n",
    "    * h2태그의 배경색을 파란색으로 변경하는 기능이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h2 class=\"my\">Turn this into blue</h2>\n",
       "<button onclick=\"myFunction()\">Click</button>\n",
       "<script>\n",
       "    function myFunction() {\n",
       "        document.querySelector(\".my\").style.backgroundColor = \"blue\";\n",
       "    }\n",
       "</script>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<body>\n",
    "<h2 class=\"my\">Turn this into blue</h2>\n",
    "<button onclick=\"myFunction()\">Click</button>\n",
    "<script>\n",
    "    function myFunction() {\n",
    "        document.querySelector(\".my\").style.backgroundColor = \"blue\";\n",
    "    }\n",
    "</script>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **document.getElementById()**를 사용해 p2라는 명칭을 선택한다. \n",
    "    * id가 p2인 ```<p>```태그를 빨간새으로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
       "    <p id=\"p2\">Hello World!</p>\n",
       "    <script>\n",
       "        document.getElementById(\"p2\").style.color = \"RED\";\n",
       "    </script>\n",
       "    <p>Hello World turned into RED!</p>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<body>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.5 BeautifulSoup\n",
    "\n",
    "BeautifulSoup은 Python에서 사용하는 html, xml 파서이다. Java로 만들어진 jsoup도 유사한 기능을 가지고 있다. 이전 버전은 더 이상 지원되지 않으므로, 버전은 4로 한다.\n",
    "\n",
    "### 1.5.1 설치\n",
    "\n",
    "명령창에서 pip로 설치한다. 'sudo'는 관리자 권한이다. 윈도우 Anaconda는 기본 설치되어 있다.\n",
    "```python\n",
    "pip install beautifulsoup4 (beautifulsoup은 버전3을 설치한다)\n",
    "```\n",
    "\n",
    "Linux Ubuntu에서 apt를 사용하여 설치할 수 있다.\n",
    "```python\n",
    "apt install python-bs4 (Python 2을 사용하는 경우)\n",
    "apt install python3-bs4 (Python 3을 사용하는 경우)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파서를 넣어주지 않으면 기본 파서를 사용한다.\n",
    "\n",
    "파서 | 설치 | 설정\n",
    "-----|-----\n",
    "html.parser | Python에 내장 | BeautifulSoup(markup, \"html.parser\")\n",
    "lxml parser | C로 만든 파서, 별도 설치가 필요 | BeautifulSoup(markup, \"lxml\")\n",
    "\n",
    "* Linux Ubuntu에서 'lxml' 설치\n",
    "\n",
    "```python\n",
    "apt-get install python-lxml\n",
    "```\n",
    "\n",
    "* 파이썬 패키지 저장소에서 'lxml' 설치\n",
    "\n",
    "```python\n",
    "pip install lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* BeautifulSoup은 html을 DOM으로 변환하여, 다음 4가지 객체를 생성하여 활용한다.\n",
    "\n",
    "객체 | 설명\n",
    "-----|-----\n",
    "BeautifulSoup | html을 DOM으로 변환한 문서 전체를 말한다. 아래에서 파싱한 결과가 들어있는 'soup' 이다.\n",
    "Tag | html 태그이다. 태그명, 태그속성, 태그의 텍스트를 가지고 있다.\n",
    "NavigableString | Python에서 사용하는 unicode 문자열과 유사하지만, 몇 가지 추가되는 기능을 제공한다.\n",
    "Comment | html comment, 도움말을 뜻한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.2 BeautifulSoup 객체\n",
    "\n",
    "* BeautifulSoup 라이브러리를 **from ... import ...** 호출방식으로 사용한다.\n",
    "* 예를 들어 my.py에서 x.py를 호출한다고 하자.\n",
    "    * (1) x.py가 import y를 가지고 있다고 하자.\n",
    "    * (2) my.py에서 x.py는 import mylib.x라고 불러 사용할 수 있다.\n",
    "    * (3) 그러면 x.py에서 가지고 있는 import y는 오류가 된다. 즉, 상대호출이라서 from mylib import y로 변경해 주어야 맞다.\n",
    "\n",
    "```python\n",
    "my.py        # (2) 여기서 x.py를 호출하려면 import mylib.x는 오류(x) \n",
    "mylib\\\n",
    "      x.py   # (1) 여기 import y를 가지고 있다고 하자. (3) import y -> from mylib import y (o)\n",
    "      y.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_html=\"\"\"<html>\n",
    "<body>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(_html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[document]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <b>\n",
      "   <!--This page is to show how to use BeautifulSoup-->\n",
      "  </b>\n",
      "  <p id=\"p2\">\n",
      "   Hello World!\n",
      "  </p>\n",
      "  <script>\n",
      "   document.getElementById(\"p2\").style.color = \"RED\";\n",
      "  </script>\n",
      "  <p>\n",
      "   Hello World turned into RED!\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.3 태그 객체\n",
    "\n",
    "HTML 태그의 객체이다. 태그명, 속성, 텍스트 등을 읽을 수 있다.\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "soup.p | dot 연산자를 사용해 태그를 읽을 수 있다. 태그 자체를 읽으며 여러 개가 있더라도 처음 태그를 읽어 온다.\n",
    "soup.p.attrs | 태그의 속성을 dictionary 구조로 읽는다.\n",
    "soup.p['id'] | 태그의 속성을 dictionary 구조로 []괄호를 사용하여 읽는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "soup은 DOM을 가지고 있고, 그 중 'p' 태그객체를 살펴 보자.\n",
    "파싱을 하면서 자신이 어떤 타잎을 다루고 있는지 알고 있는 편이 좋다.\n",
    "'soup.p'의 type을 확인하면, 아래와 같이 **bs4.element.Tag**이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "soup.p 태그객체의 속성을 HTML 소스에서 확인해보자.\n",
    "속성은 'id'가 하나만 있고, 그 값을 알아볼 수 있다.\n",
    "또한 부모객체를 알아볼 수 있다. 계층을 하나 위 부모는 'body' 태그가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n",
      "{u'id': u'p2'}\n",
      "p2\n"
     ]
    }
   ],
   "source": [
    "print soup.p\n",
    "print soup.p.attrs\n",
    "print soup.p['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<b><!--This page is to show how to use BeautifulSoup--></b>\n",
      "<p id=\"p2\">Hello World!</p>\n",
      "<script>\n",
      "        document.getElementById(\"p2\").style.color = \"RED\";\n",
      "    </script>\n",
      "<p>Hello World turned into RED!</p>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "print soup.p.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.4 문자열 객체\n",
    "\n",
    "* 태그의 텍스트를 '.string'으로 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "print type(soup.p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print soup.p.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.5 Comment 객체\n",
    "\n",
    "html 문서에 도움말을 넣을 경우, <!–– 도움말 ––> 태그를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Comment'>\n",
      "This page is to show how to use BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "print type(soup.b.string)\n",
    "print soup.b.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5.6 찾기\n",
    "\n",
    "find() 또는 find_all() 함수를 사용한다.\n",
    "**문자열이 아니라, 태그**를 찾아 준다.\n",
    "조건은 함수 인자에 적는다. 태그명, 태그속성을 **'=' 또는 dictionary 형식**으로 적는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n"
     ]
    }
   ],
   "source": [
    "print soup.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p2\">Hello World!</p>\n"
     ]
    }
   ],
   "source": [
    "print soup.find(\"p\",id=\"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "Hello World!\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "p2tag=soup.find(\"p\", {\"id\":\"p2\"})\n",
    "print type(p2tag)\n",
    "print p2tag.text     # 모든 child의 string을 출력\n",
    "print p2tag.string   # 해당 Tag의 string을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* text vs string\n",
    "    * string은 해당 태그만 (child tag 제외)\n",
    "    * text는 child의 text까지 합성해서 돌려줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myhtml=\"\"\"<td>cell 1</td>\n",
    "<td></td>\n",
    "<td><bold>bold cell 3</bold></td>\n",
    "<td>cell 4<bold>bold text</bold></td>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(myhtml,\"html.parser\")\n",
    "_td=soup.find_all(\"td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell 1\n",
      "\n",
      "bold cell 3\n",
      "cell 4bold text\n"
     ]
    }
   ],
   "source": [
    "for e in _td:\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell 1\n",
      "None\n",
      "bold cell 3\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for e in _td:\n",
    "    print e.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-1: python.org 페이지가 가지고 있는 최근 뉴스 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "크롤링하려는 'www.python.org'는 파이썬 언어에서 운영하는 홈페이지이므로 자주 방문한게 된다.\n",
    "여기서 이 페이지가 포함하는 '최신 뉴스'를 알아보려고 한다.\n",
    "문제를 풀기 전에 'python.org'를 웹브라우저에서 방문한다.\n",
    "'Latest News'를 찾고 그 아래 뉴스를 읽어본다.\n",
    "\n",
    "### 풀이\n",
    "\n",
    "BeautifulSoup을 사용하여 html을 DOM으로 파싱하고, 원하는 태그를 찾는다.\n",
    "우선 '소스보기'에서 원하는 태그를 찾아서, 그 태그를 조건으로 넣어야 편리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "page=r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 원하는 태그를 찾으면, class 'blog-widget'이라는 것을 알 수 있다.\n",
    "* class 다음에는 '_'를 넣어 준다. 또는 key-value 형식으로 맞추어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news=soup.find(\"div\", class_=\"blog-widget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-16T21:58:00.000005+00:00\n"
     ]
    }
   ],
   "source": [
    "print news.li.time['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest bugfix release in the Python 2.7 series, Python ...\n"
     ]
    }
   ],
   "source": [
    "print news.li.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>\\n<time datetime=\"2017-09-16T21:58:00.000005+00:00\"><span class=\"say-no-more\">2017-</span>09-16</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/3SUhDRzB1-s/python-2714-released.html\">The latest bugfix release in the Python 2.7 series, Python ...</a></li>, <li>\\n<time datetime=\"2017-09-07T00:13:00.000003+00:00\"><span class=\"say-no-more\">2017-</span>09-07</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/pUndlLcEcKE/python-337rc1-is-now-available-prior-to.html\">Python 3.3.7rc1 is now available, the release candidate of Python ...</a></li>, <li>\\n<time datetime=\"2017-08-27T03:41:00.000006+00:00\"><span class=\"say-no-more\">2017-</span>08-27</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/pe2Ug4MA0Lg/python-2714-release-candidate-1.html\">The first release candidate for Python 2.7.14 is now available ...</a></li>, <li>\\n<time datetime=\"2017-08-09T07:34:00.000002+00:00\"><span class=\"say-no-more\">2017-</span>08-09</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/vY72b719CGk/python-354-and-python-347-are-now.html\">Python 3.5.4 and Python 3.4.7 are now available for download. ...</a></li>, <li>\\n<time datetime=\"2017-07-25T08:40:00.000001+00:00\"><span class=\"say-no-more\">2017-</span>07-25</time>\\n<a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/ry7faTWPZiY/python-354rc1-and-python-347rc1-are-now.html\">Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...</a></li>]\n"
     ]
    }
   ],
   "source": [
    "print news.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 지금까지 찾은 항목을 for 문으로 모두 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-16T21:58:00.000005+00:00 The latest bugfix release in the Python 2.7 series, Python ...\n",
      "2017-09-07T00:13:00.000003+00:00 Python 3.3.7rc1 is now available, the release candidate of Python ...\n",
      "2017-08-27T03:41:00.000006+00:00 The first release candidate for Python 2.7.14 is now available ...\n",
      "2017-08-09T07:34:00.000002+00:00 Python 3.5.4 and Python 3.4.7 are now available for download. ...\n",
      "2017-07-25T08:40:00.000001+00:00 Python 3.5.4rc1 and Python 3.4.7rc1 are now available for download. ...\n"
     ]
    }
   ],
   "source": [
    "for e in news.find_all(\"li\"):\n",
    "    print e.time[\"datetime\"], e.a.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  49299\n",
      "2018-03-31T11:56:00.000005+00:00 On behalf of the PyPA, I am pleased to announce ...\n",
      "2018-03-30T01:42:00.000004+00:00 Python 3.7.0b3 is the third of four planned beta previews of Python ...\n",
      "2018-03-28T21:59:00.000002+00:00 Python 3.6.5 is now available.  3.6.5 is the fifth maintenance release of ...\n",
      "2018-03-26T20:59:00+00:00 The new Python Package Index at https://pypi.org is now in ...\n",
      "2018-03-14T04:46:00.000002+00:00 Python 3.6.5rc1 is the first release candidate for Python 3.6.5, ...\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_1_readPythonOrgBS.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readLatestNews():\n",
    "    try:\n",
    "        r = requests.get(u'http://python.org/')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    page=r.text\n",
    "    print \"length: \",len(page)\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    news=soup.find(\"div\", class_=\"blog-widget\")\n",
    "    for e in news.find_all(\"li\"):\n",
    "\tprint e.time[\"datetime\"], e.a.string\n",
    "\n",
    "def main():\n",
    "    readLatestNews()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 추가문제: \"Use Python for..\"를 수집해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.6 regex\n",
    "\n",
    "* 정규식 regular expression은 문자열로 표현한 정규표현으로, 패턴매칭에 사용한다.\n",
    "* 정규식을 사용하면 복잡한 패턴을 단순하게 처리할 수 있다.\n",
    "* 정규식은 메타문자를 사용한다. 역슬래시 '\\'와 결합하여 특별한 의미를 가진다. 예를 들어, d는 역슬래시와 결합하여 숫자를, s는 공백을 의미한다.\n",
    "\n",
    "정규식 | 설명 | 예\n",
    "-----|-----|-----\n",
    "() | grouping | (\\d{1,2})\n",
    "\\d | any character in the range 0-9 |\n",
    "\\s | any whitespace |\n",
    "\\w | any character in the range 0-9, A-Z, a-z |\n",
    "[] | a signle character | [a-cx-z] = \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\"\n",
    "\\- | range separator | [0123456789] = [0-9]\n",
    "\\* | the preceding element zero or more times | ab*c = \"ac\", \"abc\", \"abbbc\"\n",
    "\\+ | the preceding element one or more times  | ba+ = \"ba\", \"baa\", \"baaa\", and so on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.6.1 문자, 순자 추출해 보기\n",
    "\n",
    "* 정규식을 사용하면 문장에서 숫자, 문자를 편리하게 추출할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자와 문자:  ['Here', 'goes', 'my', 'phone', 'number', '2287', '1111', 'Nice', 'to', 'meet', 'you', 'Merry', 'Christmas']\n",
      "숫자:  ['2287', '1111']\n",
      "대문자를 가진 단어:  ['Here', 'Nice', 'Merry', 'Christmas']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence=\"Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas\"\n",
    "regex1='\\w+'\n",
    "print \"숫자와 문자: \",re.findall(regex1, sentence)\n",
    "regex2='\\d+'\n",
    "print \"숫자: \",re.findall(regex2, sentence)\n",
    "regex3 = '[A-Z]\\w+'\n",
    "print \"대문자를 가진 단어: \",re.findall(regex3, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 정규식을 사용하여 태그를 찾을 수 있다.\n",
    "* a태그의 문자열을 읽어 본다.\n",
    "    * a태그의 패턴을 정하고,\n",
    "    * 그 안의 모든 문자 '.*'를 '()'그룹으로 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tag:  ['foo']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tags='<html><body><div>asdfasdf</div><p><a>foo</a></p></body></html>'\n",
    "regex=\"<a>(.*)</a>\"\n",
    "print \"a tag: \",re.findall(regex, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.6.2 BeautifulSoup과 같이 regex를 사용\n",
    "\n",
    "* 패턴을 가지고 있는 태그의 문자열을 찾을 수 있다.\n",
    "* 패턴을 가지고 있는 태그, 속성을 검색할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup import BeautifulSoup\n",
    "import re\n",
    "\n",
    "htmlstr = \"\"\"\n",
    "<p>Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas</p>\n",
    "<p>this is text</p2>\n",
    "<a href=\"https://www.example.com\">Visit example.com</a>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(htmlstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tag:  <p>Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas</p>\n",
      "text:  Here goes my phone number 2287-1111. Nice to meet you! Merry Christmas\n"
     ]
    }
   ],
   "source": [
    "for e in soup(text=re.compile(r'\\d+')):\n",
    "    print \"tag: \", e.parent\n",
    "    print \"text: \", e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit example.com\n"
     ]
    }
   ],
   "source": [
    "for e in soup.findAll(href=re.compile(\"ex\")):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.7 xpath\n",
    "\n",
    "xpath는 XML Path Language의 약어로 xml문서를 트리구조로 표현하고, 노드를 선택하기 위해 사용하는 조회언어이다.\n",
    "\n",
    "* xpath 표현\n",
    "\n",
    "Expression | 설명 | 예\n",
    "---------|----------|----------\n",
    "/ | root부터 선택 | ```$x('/html')``` 루트에 있는 html 선택\n",
    "// | 어디에 있는지 상관없이 선택 | ```$x('//div')``` 어디에 있든 div 선택 \n",
    ". | Selects the current node | \n",
    ".. | Selects the parent of the current node | \n",
    "@ | Selects attributes | //@href 속성href를 가진 모든 노드\n",
    "\\* | all |\n",
    "@* | 속성 모두 | //div[@*] 속성을 가지고 있는 모든 div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.1 lxml\n",
    "\n",
    "lxml은:\n",
    "* lxml.etree는 **XML**을 파싱한다. 그러나 HTMLParsor()를 사용하면 html을 파싱할 수 있다.\n",
    "* lxml.html는 **HTML**을 파싱할 경우 사용한다.\n",
    "\n",
    "BeautifulSoup은 xpath를 지원하지 않는다.\n",
    "실행하는 단계는 다른 라이브러리를 사용하는 단계와 다르지 않다.\n",
    "불완전한 태그일 경우 오류가 발생할 수 있다는 점에 주의한다.\n",
    "\n",
    "구분 | 파싱 | 설명 | 읽는 함수\n",
    "-----|-----|-----|-----\n",
    "lxml.etree | XML | c로 구현해서 빠르다. HTMLParsor()파서를 선택하면 HTML을 파싱할 수 있다. | **파일**에서 읽기 parse()<br>**문자열**에서 읽기 fromstring() (단 html은 XML로 인식하기 때문에 HTML()함수를 사용한다.)\n",
    "lxml.html | HTML | Python으로 구현 | 상동\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* lxml.etree에서 HTML을 파싱하려면 HTMLParser()를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "parser=lxml.etree.HTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.2 파일에서 파싱\n",
    "\n",
    "* 파일에서 읽으므로 parse() 함수를 사용한다.\n",
    "* 디렉토리로부터 파일을 읽을 경우, os.path.join()을 사용한다. 앞서 설명한 바와 같이 디렉토리 구분자로 인한 오류를 제거할 수 있다.\n",
    "```<meta>``` 태그는'시작'은 있고, '끝' 태그가 없어 오류가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tree=lxml.etree.parse(os.path.join('src','mypage2.html'),parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* getiterator()는 모든 태그를 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 태그: html -> \n",
      "\n",
      "- 태그: head -> \n",
      "\n",
      "- 태그: meta -> None\n",
      "- 태그: title -> My Home Page\n",
      "- 태그: body -> \n",
      "\n",
      "- 태그: h1 -> 안녕하십니까\n",
      "- 태그: p -> 오늘은 프로그래밍 하는 날...\n",
      "- 태그: p -> Today we do programming...\n"
     ]
    }
   ],
   "source": [
    "for node in tree.getiterator():\n",
    "    print \"- 태그:\", node.tag, \"->\", node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.7.2 문자열에서 파싱\n",
    "\n",
    "* html 문자열을 파싱한다. 문자열은 파일에서 읽어서 만든다.\n",
    "* 'mypage2.html'은 meta 태그를 포함하고 있어, 오류가 발생한다는 점 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 태그: html {}\n",
      "- 태그: body {}\n",
      "- 태그: h1 {}\n",
      "- 태그: b {}\n",
      "- 태그: <cyfunction Comment at 0x7f6cc97cf590> <lxml.etree._ImmutableMapping object at 0x7f6cc97a1790>\n",
      "- 태그: p {'id': 'p2'}\n",
      "- 태그: script {}\n",
      "- 태그: p {}\n"
     ]
    }
   ],
   "source": [
    "import lxml.etree\n",
    "_html=\"\"\"<html>\n",
    "<body>\n",
    "    <h1>안녕하세요</h1>\n",
    "    <b><!--This page is to show how to use BeautifulSoup--></b>\n",
    "    <p id=\"p2\">Hello World!</p>\n",
    "    <script>\n",
    "        document.getElementById(\"p2\").style.color = \"RED\";\n",
    "    </script>\n",
    "    <p>Hello World turned into RED!</p>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "tree=lxml.etree.fromstring(_html)\n",
    "for node in tree.getiterator():\n",
    "    print \"- 태그:\", node.tag, node.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 트리구조로 만드는 작업을 하고 난 후 xpath를 사용할 수 있다.\n",
    "* xpath를 사용하여 h1 태그의 문자열을 읽는다.\n",
    "* unicode값이 반환된다. 또한 배열로 만들어져 있다는 점에 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\uc548\\ub155\\ud558\\uc138\\uc694']\n"
     ]
    }
   ],
   "source": [
    "tree=lxml.etree.fromstring(_html)\n",
    "print tree.xpath('//h1/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요\n"
     ]
    }
   ],
   "source": [
    "print tree.xpath('//h1/text()')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.8 css selectors\n",
    "\n",
    "CSS는 html의 스타일을 정하는 규칙을 가지고 있다. 스타일 태그의 선택자 selector를 사용하여, 원하는 태그를 추출할 수 있다.\n",
    "\n",
    "* [css selectors](http://www.w3schools.com/cssref/css_selectors.asp)\n",
    "\n",
    "selector | css | 설명 | xpath\n",
    "------------|------------|------------|------------\n",
    "[attribute] | $$('input[type=\"email\"]') | input type을 선택 | $x('//input[@type=\"email\"]')\n",
    "type | 'div' 'a' | div 태그, a 태그 | '//div' '//a'\n",
    "class | '.foo' | class 속성이 foo를 선택 | '//*[@class=\"foo\"]'\n",
    "id | '#foo' | id foo (1개만 선택. 클래스는 여러 개 선택) | '//*[@id=\"foo\"]'\n",
    "universal | '*' | all | '//*'\n",
    "descendents | 'div a' | all a's inside div (여러 세대 떨어져도 선택) | '//div//a' \n",
    "child | 'div > a' | a's only children to the div (1세대 다음) | '//div/a'\n",
    "parents | a ~ b | any parents of b (여러 세대 위) |\n",
    "grouped | 'h1, h2' | 'h1 h2' |\n",
    "text | 'a::text' | 선택한 노드, element의 text.<br>javascript console에서는 'innerText' | '//a/text()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.8.1 html에서 css\n",
    "\n",
    "css는 Cascading Style Sheets, html문서의 스타일을 설정한다. html 색, 폰트 등 어떻게 보여지는지를 정한다. 아래는 css를 html에 넣어서 태그의 스타일을 설정하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/mypage3.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/mypage3.html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>My Home Page</title>\n",
    "    <style>\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            color:red;\n",
    "            font-family: 'Droid Sans', sans-serif;\n",
    "        };  \n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>안녕하십니까</h1>\n",
    "    <p>오늘은 프로그래밍 하는 날...</p>\n",
    "    <p>Today we do programming...</p>\n",
    "\n",
    "    <div id=\"divid\">\n",
    "        <h2>Hello h2</h2>\n",
    "        <p>Here we use div id.</p>\n",
    "        <a href=\"https://www.example.com\">Visit example.com</a>\n",
    "    </div>\n",
    "    <div class=\"divclass\">\n",
    "        <h2>Welcome</h2>\n",
    "        <p>Here we use div class.</p>\n",
    "        <ul>\n",
    "            <li>first</li>\n",
    "            <li>second</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "\n",
    "    <form action=\"\">\n",
    "    Email <input type=\"email\" value=\"emailvalue\" name=\"emailname\" id=\"emailid\"\n",
    "        class=\"emailclass\" style=\"background-color: green;\"required>\n",
    "    Zip Code <input type=\"number\" name=\"zipname\" required>\n",
    "    <textarea rows=\"4\" columns=\"50\"></textarea>\n",
    "    <input type=\"submit\" value=\"Submit\">\n",
    "    </form>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.8.2 lxml을 사용해서 하기\n",
    "\n",
    "* lxml.html을 사용한다. lxml.html은 파이썬으로 만들어졌다.\n",
    "* cssselect 라이브러리가 없는 경우에는 pip를 사용해서 설치한다.\n",
    "```python\n",
    "pip install lxml cssselect\n",
    "```\n",
    "\n",
    "* 리눅스에서는 xml라이브러리가 필요하다.\n",
    "```python\n",
    "sudo apt-get install libxml2-dev libxslt1-dev\n",
    "pip install lxml cssselect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* lxml은 broken html을 처리할 수 있다. 시작-끝 태그로 구성되지 않은 meta 태그가 오류 없이 처리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "htmlstr=\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>My Home Page</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>안녕하십니까</h1>\n",
    "<p>오늘은 프로그래밍 하는 날...</p>\n",
    "<p>Today we do programming...</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "tree = lxml.html.fromstring(htmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* nth-child(2)는 부모의 2번째 child를 선택한다. 부모 body의 2번째 p 태그이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body :nth-child(1)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘은 프로그래밍 하는 날...\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body :nth-child(2)'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in tree.cssselect('body h1'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.8.3 BeautifulSoup을 사용해서 하기\n",
    "\n",
    "BeautifulSoup도 css selector를 지원한다. 사용하는 방법은 lxml과 유사하다. 같이 비교하면서 사용해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(htmlstr,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하십니까\n"
     ]
    }
   ],
   "source": [
    "for e in soup.select('body h1'):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.8.4 테이블을 읽기\n",
    "\n",
    "테이블은 데이터를 행과 열로 표현하는 방식으로, 웹페이지에서 자주 사용되고 있다.\n",
    "\n",
    "아래와 같이 table은 헤더(thead)와 내용(tbody)으로 구분하고 있다.\n",
    "경우에 따라 tbody는 생략할 수 있다. thead가 없는 경우 또는 tbody 다음 첫 줄이 tr인 경우가 그렇다.\n",
    "css selector를 사용하면 행은 'tr', 셀은 'td'로 검색한다.\n",
    "특정 항목을 선택할 때는 BeautifulSoup은 'nth-child'는 지원하지 않으므로, 'nth-of-type'을 사용한다.\n",
    "\n",
    "구분 | css selector\n",
    "-----|-----\n",
    "테이블 행 검색 | tbody tr\n",
    "테이블 첫행 검색 | tbody tr:nth-of-type(1)\n",
    "테이블 셀 검색 | tbody tr td\n",
    "테이블 첫셀 검색 | tbody tr td:nth-of-type(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "expecting Cell 11 ->  [<td>Cell 11</td>]\n",
      "\n",
      "expecting Cell 11 12 13 ->  [<tr>\\n<td>Cell 11</td>\\n<td>Cell 12</td>\\n<td>Cell 13</td>\\n</tr>]\n",
      "\n",
      "Cell 11\n",
      "Cell 12\n",
      "Cell 13\n",
      "\n",
      "Num Table Rows: 3\n",
      " Cell 11 Cell 12 Cell 13   Cell 21 Cell 22 Cell 23   \n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_5_testTable.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "tableHtml=\"\"\"\n",
    "<table id='thetable'>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Head 1</th>\n",
    "            <th>Head 2</th>\n",
    "            <th>Head 3</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Cell 11</td>\n",
    "            <td>Cell 12</td>\n",
    "            <td>Cell 13</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Cell 21</td>\n",
    "            <td>Cell 22</td>\n",
    "            <td>Cell 23</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "\"\"\"\n",
    "\n",
    "def do():\n",
    "    soup=BeautifulSoup(tableHtml,\"html.parser\")\n",
    "    my1=soup.select(\"#thetable tbody tr td:nth-of-type(1)\")\n",
    "    print \"\\nexpecting Cell 11 -> \", my1\n",
    "    my2=soup.select(\"#thetable > tbody > tr:nth-of-type(1)\")\n",
    "    print \"\\nexpecting Cell 11 12 13 -> \", my2\n",
    "    for e in my2:\n",
    "        #print e.string -> does not print\n",
    "        print e.text\n",
    "    my3=soup.select(\"#thetable tbody tr\")\n",
    "    print \"Num Table Rows:\", len(my3)\n",
    "    for e in my3:\n",
    "        row=e.get_text().split('\\n')\n",
    "        for cell in row:\n",
    "            print cell,  \n",
    "\n",
    "def main():\n",
    "    do()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-2: python.org 페이지가 가지고 있는 http url 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "파이썬 홈페이지 'www.python.org' 가 포함하는 링크를 찾아 보려고 한다.\n",
    "웹브라우저를 열고 'python.org'라고 입력해 보자.\n",
    "마우스를 가져가면 하이퍼링크가 활성화된다. 이런 링크를 가져오는 것이 문제이다.\n",
    "링크는 문서내의 다른 장소로 이동하거나 다른 웹페이지로 이동하는 기능을 제공한다.\n",
    "다른 페이지로 이동하는 링크만 출력한다.\n",
    "* 전체 링크의 갯수\n",
    "* 다른 페이지로 가는 링크 목록\n",
    "\n",
    "웹브라우저 메뉴에서 소스보기를 클릭하면 html 소스를 볼 수 있다. 하나씩 세어도 답을 할 수 있지만 프로그램으로 하면 시간, 노력, 오류를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 풀이\n",
    "\n",
    "주소창에 url을 입력하고 웹페이지를 요청하는 것과 같이 Python.org페이지를 크롤링해 온다. 다음 방식으로 해 본다.\n",
    "* BeautifulSoup\n",
    "* regex\n",
    "* xpath\n",
    "* css selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "* requests로 url의 페이지를 가져와서, 그 페이지를 BeautifulSoup으로 parsing한다.\n",
    "* 위 예제, p 태그의 처음에 있는 strong 태그 가져오기\n",
    "* 파서 'lxml'을 넣어서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "_html=r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#soup = BeautifulSoup(_html,\"html.parser\")\n",
    "soup=BeautifulSoup(_html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" dir=\"ltr\" lang=\"en\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <link href=\"//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.mi\n"
     ]
    }
   ],
   "source": [
    "print soup.prettify()[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* BeautifulSoup find_all('a') 함수로 'a' 태그를 가져온다.\n",
    "* 'a' 태그가 수 백개가 되므로, 20개만 출력한다. 전체 개수는 맨 마지막 줄에 출력한다.\n",
    "* 'a href'의 출력을 살펴 보자.\n",
    "    * #, javascript 함수, local links, external links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 #content\n",
      "1 #python-network\n",
      "2 /\n",
      "3 /psf-landing/\n",
      "4 https://docs.python.org\n",
      "5 https://pypi.python.org/\n",
      "6 /jobs/\n",
      "7 /community/\n",
      "8 #top\n",
      "9 /\n",
      "10 #site-map\n",
      "11 #\n",
      "12 javascript:;\n",
      "13 javascript:;\n",
      "14 javascript:;\n",
      "15 #\n",
      "16 http://plus.google.com/+Python\n",
      "17 http://www.facebook.com/pythonlang?fref=ts\n",
      "18 http://twitter.com/ThePSF\n",
      "19 /community/irc/\n"
     ]
    }
   ],
   "source": [
    "for counter,link in enumerate(soup.find_all('a')):\n",
    "    if(counter<20):\n",
    "        print counter,link.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /wiki/Wikipedia:Protection_policy#semi\n",
      "1 #mw-head\n",
      "2 #p-search\n",
      "3 /wiki/HTM_(disambiguation)\n",
      "4 /wiki/Help:HTML_in_wikitext\n",
      "5 /wiki/File:HTML.svg\n",
      "6 /wiki/Filename_extension\n",
      "7 /wiki/Media_type\n",
      "8 /wiki/Type_code\n",
      "9 /wiki/World_Wide_Web_Consortium\n",
      "10 /wiki/WHATWG\n",
      "11 /wiki/Software_release_life_cycle\n",
      "12 /wiki/HTML5\n",
      "13 #cite_note-1\n",
      "14 /wiki/Document_file_format\n",
      "15 /wiki/Standard_Generalized_Markup_Language\n",
      "16 /wiki/XHTML\n",
      "17 /wiki/International_standard\n",
      "18 http://www.w3.org/TR/html/\n",
      "19 http://whatwg.org/html\n",
      "Total:  1761\n"
     ]
    }
   ],
   "source": [
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "#_html = urlopen(\"http://en.wikipedia.org/wiki/Kevin_Bacon\")\n",
    "_html = urlopen(\"http://en.wikipedia.org/wiki/HTML\").read()\n",
    "tree = BeautifulSoup(_html, \"lxml\")\n",
    "counter=0\n",
    "for link in tree.findAll(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        if counter<20:\n",
    "            print counter, link.attrs['href']\n",
    "        counter+=1\n",
    "print \"Total: \", counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 파일 버전\n",
    "\n",
    "* r.text는 unicode, r.content는 bytes로 Response를 받아온다.\n",
    "* 페이지를 읽을 경우, 발생오류에 대한 예외처리 try-except를 넣었다.\n",
    "* href link만 세어서 출력한다. 2018년 4월 205개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of links: 205\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds2_1_crawlLink.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readPythonOrg():\n",
    "    try:\n",
    "        r = requests.get(u'http://python.org/')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    soup=BeautifulSoup(r.content,\"lxml\")\n",
    "    my=soup.select(\"a\")\n",
    "    ahref=soup.find_all('a', href=True)\n",
    "    print \"total number of links:\",len(my)\n",
    "\n",
    "\n",
    "def main():\n",
    "    readPythonOrg()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### regex\n",
    "\n",
    "문자열에 포함된 패턴으로 태그 또는 추출할 데이터를 인식할 수 있다.\n",
    "HTML 파서를 사용하여 태그를 추출하는 것에 비해 불편하다.\n",
    "'http://' 패턴을 추출하므로 결과가 다를 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http url은 몇 개? 43\n",
      "0 http://www.ie6countdown.com/\n",
      "1 http://browsehappy.com/\n",
      "2 http://www.google.com/chromeframe/?redirect=true\n",
      "3 http://plus.google.com/+Python\n",
      "4 http://www.facebook.com/pythonlang?fref=ts\n",
      "5 http://twitter.com/ThePSF\n",
      "6 http://brochure.getpython.info/\n",
      "7 http://wiki.python.org/moin/Languages\n",
      "8 http://python.org/dev/peps/\n",
      "9 http://planetpython.org/\n",
      "10 http://pyfound.blogspot.com/\n",
      "11 http://pycon.blogspot.com/\n",
      "12 http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
      "13 http://blog.python.org\n",
      "14 http://feedproxy.google.com/~r/PythonInsider/~3/pUndlLcEcKE/python-337rc1-is-now-available-prior-to.html\n",
      "15 http://feedproxy.google.com/~r/PythonInsider/~3/pe2Ug4MA0Lg/python-2714-release-candidate-1.html\n",
      "16 http://feedproxy.google.com/~r/PythonInsider/~3/vY72b719CGk/python-354-and-python-347-are-now.html\n",
      "17 http://feedproxy.google.com/~r/PythonInsider/~3/ry7faTWPZiY/python-354rc1-and-python-347rc1-are-now.html\n",
      "18 http://feedproxy.google.com/~r/PythonInsider/~3/xgmAIcE1Wes/python-362-is-now-available.html\n",
      "19 http://www.djangoproject.com/\n",
      "20 http://www.pylonsproject.org/\n",
      "21 http://bottlepy.org\n",
      "22 http://tornadoweb.org\n",
      "23 http://flask.pocoo.org/\n",
      "24 http://www.web2py.com/\n",
      "25 http://wiki.python.org/moin/TkInter\n",
      "26 http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
      "27 http://www.wxpython.org/\n",
      "28 http://www.scipy.org\n",
      "29 http://pandas.pydata.org/\n",
      "30 http://ipython.org\n",
      "31 http://buildbot.net/\n",
      "32 http://trac.edgewall.org/\n",
      "33 http://roundup.sourceforge.net/\n",
      "34 http://www.ansible.com\n",
      "35 http://www.saltstack.com\n",
      "36 http://brochure.getpython.info/\n",
      "37 http://wiki.python.org/moin/Languages\n",
      "38 http://python.org/dev/peps/\n",
      "39 http://planetpython.org/\n",
      "40 http://pyfound.blogspot.com/\n",
      "41 http://pycon.blogspot.com/\n",
      "42 http://docs.python.org/devguide/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#p=re.compile('http://.+\"')\n",
    "p=re.compile('href=\"(http://.*?)\"')\n",
    "nodes=p.findall(_html)\n",
    "print \"http url은 몇 개?\",len(nodes)\n",
    "for i, node in enumerate(nodes):\n",
    "    print i, node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* regex를 사용해서 h1, p 태그 값을 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Defined\n",
      "Compound Data Types\n",
      "Intuitive Interpretation\n",
      "Quick &amp; Easy to Learn\n",
      "All the Flow You&rsquo;d Expect\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "p=re.compile('<h1>(.*?)</h1>')\n",
    "h1tags=p.findall(_html)\n",
    "for tag in h1tags:\n",
    "    print tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "p=re.compile('<p>(.*?)</p>')\n",
    "ptags=p.findall(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print len(ptags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<strong>Notice:</strong> While Javascript is not essential for this website, your interaction with the content will be limited. Please turn Javascript on for the full experience. \n"
     ]
    }
   ],
   "source": [
    "print ptags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### xpath로 해보기\n",
    "\n",
    "* lxml.etree를 사용해 html을 파싱해서 자료 가져오기 (위에서 읽어온 html 변수를 사용)\n",
    "* xpath\n",
    "```\n",
    "$x('//*[@href]')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print type(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319299\n"
     ]
    }
   ],
   "source": [
    "print len(_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* lxml.etree.HTML()\n",
    "    * lxml.etree는 XML, HTML 모두 파싱할 수 있지만 사용하는 파서를 XMLParser(), HTMLParser()로 사전에 설정해야 오류가 발생하지 않는다.\n",
    "    * lxml.etree 대신 Python으로 만들어진 lxml.html을 사용하여 HTML을 처리할 수도 있다. \n",
    "\n",
    "문자를 읽는 함수 | 설명\n",
    "-----|-----\n",
    "etree.HTML() | html 문자열을 처리하는 경우 사용한다. 이러한 점에서 etree.fromstring()과 비슷하지만 HTMLParser()로 파싱을 하게 된다.\n",
    "etree.fromstring() | etree는 XML을 처리하는 객체. etree.fromstring()은 HTML 태그를 읽으면 오류를 발생하게 된다 (아래 참조).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "etree.fromstring()으로 HTML을 읽으면 오류가 발생한다.\n",
    "etree.HTML()으로 읽어야 한다. 읽고 결과를 tostring()으로 써본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "StartTag: invalid element name, line 1, column 2 (line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m StartTag: invalid element name, line 1, column 2\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "_htmlTree = etree.fromstring(_html)   # error for reading html from lxml.etree\n",
    "result = etree.tostring(_htmlTree, pretty_print=True, method=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "_htmlTree = etree.HTML(_html)\n",
    "result = etree.tostring(_htmlTree, pretty_print=True, method=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'href': '//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js', 'rel': 'prefetch'}\n",
      "1 {'href': '/static/stylesheets/style.css', 'type': 'text/css', 'rel': 'stylesheet', 'title': 'default'}\n",
      "2 {'media': 'not print, braille, embossed, speech, tty', 'href': '/static/stylesheets/mq.css', 'type': 'text/css', 'rel': 'stylesheet'}\n",
      "3 {'href': '/static/favicon.ico', 'type': 'image/x-icon', 'rel': 'icon'}\n",
      "4 {'href': '/static/apple-touch-icon-144x144-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '144x144'}\n",
      "5 {'href': '/static/apple-touch-icon-114x114-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '114x114'}\n",
      "6 {'href': '/static/apple-touch-icon-72x72-precomposed.png', 'rel': 'apple-touch-icon-precomposed', 'sizes': '72x72'}\n",
      "7 {'href': '/static/apple-touch-icon-precomposed.png', 'rel': 'apple-touch-icon-precomposed'}\n",
      "8 {'href': '/static/apple-touch-icon-precomposed.png', 'rel': 'apple-touch-icon'}\n",
      "9 {'href': '/static/humans.txt', 'rel': 'author'}\n",
      "10 {'href': 'https://www.python.org/dev/peps/peps.rss/', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Enhancement Proposals'}\n",
      "11 {'href': 'https://www.python.org/jobs/feed/rss/', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Job Opportunities'}\n",
      "12 {'href': 'https://feeds.feedburner.com/PythonSoftwareFoundationNews', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Software Foundation News'}\n",
      "13 {'href': 'https://feeds.feedburner.com/PythonInsider', 'type': 'application/rss+xml', 'rel': 'alternate', 'title': 'Python Insider'}\n",
      "14 {'href': '#content', 'title': 'Skip to content'}\n",
      "15 {'href': '#python-network', 'aria-hidden': 'true', 'id': 'close-python-network', 'class': 'jump-link'}\n",
      "16 {'href': '/', 'class': 'current_item selectedcurrent_branch selected', 'title': 'The Python Programming Language'}\n",
      "17 {'href': '/psf-landing/', 'title': 'The Python Software Foundation'}\n",
      "18 {'href': 'https://docs.python.org', 'title': 'Python Documentation'}\n",
      "19 {'href': 'https://pypi.python.org/', 'title': 'Python Package Index'}\n"
     ]
    }
   ],
   "source": [
    "nodes=_htmlTree.xpath('//*[@href]')\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    if i<20:\n",
    "        print i, node.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### css selector\n",
    "\n",
    "* css select\n",
    "    ```\n",
    "    $$('a[href]')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "r = requests.get('http://python.org/')\n",
    "\n",
    "html = lxml.html.fromstring(r.text)\n",
    "sel=CSSSelector('a[href]')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "0 #content Skip to content\n",
      "1 #python-network \n",
      "                    \n",
      "2 / Python\n",
      "3 /psf-landing/ PSF\n",
      "4 https://docs.python.org Docs\n",
      "5 https://pypi.python.org/ PyPI\n",
      "6 /jobs/ Jobs\n",
      "7 /community/ Community\n",
      "8 #top \n",
      "                    \n",
      "9 / None\n",
      "10 #site-map None\n",
      "11 # None\n",
      "12 javascript:; Smaller\n",
      "13 javascript:; Larger\n",
      "14 javascript:; Reset\n",
      "15 # Socialize\n",
      "16 http://plus.google.com/+Python None\n",
      "17 http://www.facebook.com/pythonlang?fref=ts None\n",
      "18 http://twitter.com/ThePSF None\n",
      "19 /community/irc/ None\n"
     ]
    }
   ],
   "source": [
    "print len(nodes)\n",
    "for i,node in enumerate(nodes):\n",
    "    #print lxml.html.tostring(item)\n",
    "    if i<20:\n",
    "        print i, node.get('href'), node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-3: 위키에서 'python'을 검색해서 http url을 출력하기\n",
    "\n",
    "### 문제\n",
    "\n",
    "위키페이지는 집단지성을 대표하는 사이트이다. Python 페이지로 가서 다음을 출력한다.\n",
    "* 소개글\n",
    "* 다른 페이지로 가는 링크 목록\n",
    "\n",
    "웹브라우저 메뉴에서 소스보기를 클릭하면 html 소스를 볼 수 있다. 하나씩 세어도 답을 할 수 있지만 프로그램으로 하면 시간, 노력, 오류를 줄일 수 있다.\n",
    "\n",
    "### 해결\n",
    "\n",
    "* BeautifulSoup, lxml 라이브러리를 사용해 csss selector 첫째 문단과 링크 목록을 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "위키에서 검색결과를 가져온다.\n",
    "결과페이지에서 데이터 추출에 필요한 css selector를 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(r.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 소스보기를 해서 가져오려는 태그의 css selector를 찾는다.\n",
    "* Chrome javascript console > 태그 하이라이트 > '...'에서 오른쪽 버튼 > copy > copy selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results=soup.select('div #mw-content-text p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가져온 문단은 78개, 그 가운데 5개만 출력해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs:  78\n",
      "Python is a widely used high-level programming language for general-purpose programming, created by Guido van Rossum and first released in 1991. An interpreted language, Python has a design philosophy that emphasizes code readability (notably using whitespace indentation to delimit code blocks rather than curly brackets or keywords), and a syntax that allows programmers to express concepts in fewer lines of code than might be used in languages such as C++ or Java.[23][24] The language provides constructs intended to enable writing clear programs on both a small and large scale.[25]\n",
      "Python features a dynamic type system and automatic memory management and supports multiple programming paradigms, including object-oriented, imperative, functional programming, and procedural styles. It has a large and comprehensive standard library.[26]\n",
      "Python interpreters are available for many operating systems, allowing Python code to run on a wide variety of systems. CPython, the reference implementation of Python, is open source software[27] and has a community-based development model, as do nearly all of its variant implementations. CPython is managed by the non-profit Python Software Foundation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Number of paragraphs: \", len(results)\n",
    "for e in results[0:5]:\n",
    "    print e.get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* http 링크를 검색한다. css a[href^=\"http\"]를 사용한다. 즉 http로 시작하는 문자열 값을 가진 href를 의미한다.\n",
    "여기서 따옴표를 지키도록 한다. \"a[href^='http']\"는 틀린 문법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links=soup.select('a[href^=\"http\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 위키에서 lxml css.selector\n",
    "\n",
    "lxml.html.fromstring() 함수로 HTML을 파싱하고, cssselect()로 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "# build the DOM Tree\n",
    "tree = lxml.html.fromstring(r.text)\n",
    "# print the parsed DOM Tree\n",
    "#print lxml.html.tostring(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results=tree.cssselect('div #mw-content-text p') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Python interpreters are available for many <a href=\"/wiki/Operating_system\" title=\"Operating system\">operating systems</a>, allowing Python code to run on a wide variety of systems. <a href=\"/wiki/CPython\" title=\"CPython\">CPython</a>, the <a href=\"/wiki/Reference_implementation\" title=\"Reference implementation\">reference implementation</a> of Python, is <a href=\"/wiki/Open_source\" class=\"mw-redirect\" title=\"Open source\">open source</a> software<sup id=\"cite_ref-27\" class=\"reference\"><a href=\"#cite_note-27\">[27]</a></sup> and has a community-based development model, as do nearly all of its variant implementations. CPython is managed by the non-profit <a href=\"/wiki/Python_Software_Foundation\" title=\"Python Software Foundation\">Python Software Foundation</a>.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the HTML for the first result.\n",
    "match = results[2]\n",
    "print lxml.html.tostring(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreters are available for many \n"
     ]
    }
   ],
   "source": [
    "# print the text of the first result.\n",
    "print match.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전\n",
    "* 2018년 4월 81개의 문단을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load src/ds3_3_readWiki.py\n",
    "#!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html\n",
    "#from lxml.cssselect import CSSSelector\n",
    "\n",
    "# build the DOM Tree\n",
    "# print the parsed DOM Tree\n",
    "#print lxml.html.tostring(tree)\n",
    "\n",
    "def readWikiLxml():\n",
    "    try:\n",
    "        r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    tree = lxml.html.fromstring(r.text)\n",
    "    results=tree.cssselect('div #mw-content-text p')\n",
    "    print \"Number of paragraphs: \", len(results)\n",
    "    for e in results:\n",
    "        print e.text\n",
    "\n",
    "def readWikiBS():\n",
    "    try:\n",
    "        r = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    soup=BeautifulSoup(r.text,\"lxml\")\n",
    "    results=soup.select('div #mw-content-text p')\n",
    "    print \"Number of paragraphs: \", len(results)\n",
    "    for e in results:\n",
    "        print e.get_text().strip()\n",
    "    links=soup.select('a[href^=\"http\"]')\n",
    "    #links=soup.select(\"a[href^='http']\") -> not working\n",
    "    print \"total links: \",len(links)\n",
    "    for e in links:\n",
    "        print e\n",
    "\n",
    "def main():\n",
    "    #readWikiLxml()\n",
    "    readWikiBS()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-4: 한국 포털사이트에서 노래제목을 검색해서 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "노래는 개인의 선호가 뚜렸하고 '좋아하는 노래'가 있기 마련이다. 개인이 선호하는 또는 행사에 어울리는 노래를 골라주는 '추천' 알고리즘이 사용되기도 한다. 이런 추천기술은 다음에 배우기로 하고, 여기서는 '비 오는' 단어를 포하하는 노래를 검색하기로 한다.\n",
    "주의: 음악에는 저작권이 있다. 이 예제는 교육을 목적으로 하는 실습이다. 상업용으로 사용할 경우는 저작권을 위반하지 않아야 한다.\n",
    "\n",
    "### 해결\n",
    "\n",
    "* 노래 검색 사이트 url을 정한다. 네이버음악 사이트 http://music.naver.com/ 를 사용한다.\n",
    "* 검색어를 정하고, 검색결과를 가져온다.\n",
    "* css selector를 정해서 검색결과로부터 데이터 항목을 추출한다. 각 노래에 대해 제목, 가수, 앨범, 인기도, 가사 항목이 게시판으로 구성되어 있다. 게시판은 pagination이라고 하는 기능이 있어 여러 페이지를 반복해서 가져와야 한다.\n",
    "\n",
    "> pagination은 검색결과가 여러 페이지일 경우 사용하는 기능이다. 검색결과가 150건 일 경우, 10개로 나누어 15페이지가 제공되는 예를 들 수 있다. '더보기', '목록번호', '맨 앞으로 이동', '맨 뒤로 이동' 등의 버튼이 제공되고 이를 사용해서 데이터를 조회할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음악 검색결과 가져오기\n",
    "\n",
    "'네이버뮤직'에서 제공하는 검색기능을 사용해서 데이터를 가져온다.\n",
    "url은 http://music.naver.com/search/search.nhn, 여기에 검색어를 넣어준다.\n",
    "그 결과 15건의 노래가 검색된다.\n",
    "주소창에 나타나는 url을 참조해서 프로그램에 사용하자. 여기서는 urllib대신, requests를 사용해서 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "p = {\"query\": \"비오는\"}\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn\"\n",
    "r=requests.get(naverUrl,params=p)\n",
    "rainPage = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 검색결과 rainPage의 전체길이와 노래제목이 있는 위치를 알아 본다.\n",
    "* 개발자도구를 열어서, HTML 소스를 펼친 후 노래목록이 출력된 부분의 css selector를 선정한다. 노래제목이 출력된 부분의 문자패턴을 집어낸다.\n",
    "* 문자열 찾기 기능 find()를 사용해본다.\n",
    "* 30653, 30670 사이 노래제목 1건을 출력하였다. 노래제목은 공백을 포함하여 7자이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total length: 127905\n"
     ]
    }
   ],
   "source": [
    "print \"total length:\", len(rainPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30663 and 30670: 비 오는 거리\n"
     ]
    }
   ],
   "source": [
    "pos = rainPage.find(u\"트랙 리스트\")\n",
    "if (pos>0):\n",
    "    pos = rainPage.find(\"_title title NPI=\", pos);\n",
    "    pos = rainPage.find(\"title=\",pos+20)\n",
    "    pos2 = rainPage.find(\"\\\"\", pos+7)\n",
    "    print u\"found {0} and {1}: {2}\".format(pos+7, pos2, rainPage[pos+7:pos2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### css selector\n",
    "\n",
    "* 웹브라우저 자바스크립트 창을 열어서 css selector를 살펴본다.\n",
    "* table '트랙 리스트'에 검색결과가 출력되어 있다.\n",
    "\n",
    "CSS selectors | 설명\n",
    "----------|----------\n",
    "#content | id가 content인 element를 선택\n",
    "#content > div:nth-child(4)' | 상위 #content의 4번째 div를 선택\n",
    "div._tracklist_mytrack | div아래 _tracklist_mytrack 클래스를 선택\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 이번에는 css selector를 정리하여 사용해 본다. 자바스크립트 창에서 테스트를 해보면서 정리하는 것이 쉽다.\n",
    "\n",
    "CSS selectors | 설명 | 의미\n",
    "----------|----------|----------\n",
    "._tracklist_move | 테이블 행을 선택 (table '트랙 리스트' tbody에 있는) | 'track' 목록\n",
    ".name > a.title | 클래스 .name에 있는 a link의 title을 선택 | 노래제목\n",
    ".artist | 클래스 .artist | 아티스트 (가수)\n",
    "-album | 클래스 .album | 앨범"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "* 페이지에서 css selector를 넣어서 노래제목, 아티스트, 앨범 등을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(rainPage,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 제목 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비오는 날 수채화\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 금요일\n",
      "비오는 압구정\n",
      "비오는 거리\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 거리\n",
      "비 오는 날\n",
      "비오는 날엔\n",
      "비 오는 거리에서\n",
      "비오는 압구정\n",
      "비오는 날, 산책\n",
      "비 오는 날\n"
     ]
    }
   ],
   "source": [
    "for title in soup.select('._tracklist_move > .name > a.title'):\n",
    "    print title.get_text().strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 검색결과가 유니코드 문자를 포함하는 것은 오류가 아니다. print문이 유니코드 출력을 지원하면 한글이 출력된다.\n",
    "* 아래 'for문'은 제목을 추출해서 리스트에 추가하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44\\uc624\\ub294 \\ub0a0 \\uc218\\ucc44\\ud654', u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44 \\uc624\\ub294 \\uc774\\ub7f0 \\ub0a0\\uc5d0', u'\\ube44\\uc624\\ub294 \\uae08\\uc694\\uc77c', u'\\ube44\\uc624\\ub294 \\uc555\\uad6c\\uc815', u'\\ube44\\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac  (Feat. \\ud56b\\ud3a0\\ud2b8)', u'\\ube44\\uc624\\ub294 \\uac70\\ub9ac', u'\\ube44 \\uc624\\ub294 \\ub0a0', u'\\ube44\\uc624\\ub294 \\ub0a0\\uc5d4', u'\\ube44 \\uc624\\ub294 \\uac70\\ub9ac\\uc5d0\\uc11c', u'\\ube44\\uc624\\ub294 \\uc555\\uad6c\\uc815', u'\\ube44\\uc624\\ub294 \\ub0a0, \\uc0b0\\ucc45', u'\\ube44 \\uc624\\ub294 \\ub0a0']\n"
     ]
    }
   ],
   "source": [
    "_selName=list()\n",
    "for title in soup.select('._tracklist_move > .name > a.title'):\n",
    "    _selName.append(title.get_text().strip())\n",
    "print _selName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "위 'for문'에서 제목을 추출해서 리스트로 만드는 3줄을 1줄로 단축할 수 있다. Python의 특징을 잘 보여주고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 15\n",
      "{ARTIST} --- 비 오는 거리 --- 앨범\n",
      "이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n"
     ]
    }
   ],
   "source": [
    "_selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "_selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "_selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "print \"total number of items:\",len(_selName) \n",
    "for i in range(len(_selName)):\n",
    "    print _selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "목록에서 '곡 더보기'를 찾아서 버튼을 눌러 본다. 주소창의 url과 params이 어떻게 변경되었는지 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "r = requests.get(naverUrl,params=p)\n",
    "soup=BeautifulSoup(r.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 50\n",
      "{ARTIST} --- 비 오는 거리 --- 앨범\n",
      "이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n",
      "김봄 --- 비오는 아침 --- 비 오는 날\n",
      "재주소년 --- 비오는 압구정 --- 1집 재주소년 (才洲少年)\n",
      "서영은 --- 비오는 날 --- Unforgettable No.2\n",
      "루싸이트 토끼 --- 비 오는 거리에서 --- 1집 Twinkle Twinkle\n",
      "이승철 --- 비오는 날엔 파전 (Feat. Wonny) --- 시간 참 빠르다\n",
      "비트코인(BEATCOIN) --- 비오는 날 --- 비오는 날엔 파전\n",
      "오은영 --- 비오는 날은 푸르다 --- 비오는 날\n",
      "하이니(Hi.ni) --- 비 오는 날의 수채화 --- 비오는 날은 푸르다\n",
      "SG 워너비 --- 비오는 거리 --- Classic Odyssey\n",
      "이금성 --- 비 오는 거리 --- 비오는 거리\n",
      "SG 워너비 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Classic Odyssey\n",
      "럼블 피쉬 --- 비오는 날엔 막걸리 (Feat. 신승열) --- Memory For You\n",
      "레미 --- 비오는 이른 새벽 자장가 --- 비오는 날엔 막걸리\n",
      "롤러코스터 --- 비 오는 경리단길 (Feat. 양은선) --- 1집 내게로 와\n",
      "로만티코(Romantico) --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Diminished Part 1\n",
      "Flower Singers --- 비오는 밤 --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "도나웨일(Donawhale) --- 비오는 날의 수채화 --- 1집 Donawhale\n",
      "박정현 --- 비오는 밤 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "서효린 --- 비오는 밤 --- 가을동화\n",
      "최설아 --- Rainy Day (비오는 날) --- 비오는 밤\n",
      "김광민 --- 비 오는 밤 --- 1집 Letter From The Earth\n",
      "어프로그레시브 피아노 --- 드뷔시 - 비 오는 정원 --- One Day\n",
      "Various Artists --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- Rain Piano : 비오는 날, 듣기 좋은 피아노\n",
      "노블레스 --- 자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기... --- 7집 Growing Pains\n",
      "자장가 --- 비오는 날의 수채화 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "권인하 --- 비 오는 날 --- 첫사랑\n",
      "민티 --- 비오는 골목 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "김윤아 --- 비오는 일요일 --- 비오는 골목\n",
      "온음 --- 자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가) --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "자장가 --- 비 오는 날 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "명상피아노 --- 비 오는 날 카페에 앉아 --- 비 오는 날\n",
      "디오티마 --- 비오는 거리 (빗속에서) --- 비 오는 날 카페에 앉아\n",
      "레드 페이스(Red Face) --- 자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가) --- 喜入合 (희입합)\n",
      "자장가 --- 자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "자장가 --- 비 오는 거리에서 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "_selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "_selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "_selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "print \"total number of items:\",len(_selName) \n",
    "for i in range(len(_selName)):\n",
    "    print _selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 연속\n",
    "    * params에 track, pageNo를 추가하기\n",
    "    https://www.url-encode-decode.com/에서 encode, decode기능을 제공\n",
    "    * naver의 url을 관찰하면 p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "    '%27%eb%b9%84%ec%98%a4%eb%8a%94%27'는 '비오는'이라는 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "urllib.urlencode({'query':u'비오는'.encode('utf-8')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 50\n",
      "0 --- {ARTIST} --- 비 오는 거리 --- 앨범\n",
      "0 --- 이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "0 --- 강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "0 --- 소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "0 --- 은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "0 --- 비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "0 --- 브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "0 --- 유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "0 --- 베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "0 --- 서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "0 --- 오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "0 --- 소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "0 --- 아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "0 --- 브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "0 --- 모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n",
      "0 --- 김봄 --- 비오는 아침 --- 비 오는 날\n",
      "0 --- 재주소년 --- 비오는 압구정 --- 1집 재주소년 (才洲少年)\n",
      "0 --- 서영은 --- 비오는 날 --- Unforgettable No.2\n",
      "0 --- 루싸이트 토끼 --- 비 오는 거리에서 --- 1집 Twinkle Twinkle\n",
      "0 --- 이승철 --- 비오는 날엔 파전 (Feat. Wonny) --- 시간 참 빠르다\n",
      "0 --- 비트코인(BEATCOIN) --- 비오는 날 --- 비오는 날엔 파전\n",
      "0 --- 오은영 --- 비오는 날은 푸르다 --- 비오는 날\n",
      "0 --- 하이니(Hi.ni) --- 비 오는 날의 수채화 --- 비오는 날은 푸르다\n",
      "0 --- SG 워너비 --- 비오는 거리 --- Classic Odyssey\n",
      "0 --- 이금성 --- 비 오는 거리 --- 비오는 거리\n",
      "0 --- SG 워너비 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Classic Odyssey\n",
      "0 --- 럼블 피쉬 --- 비오는 날엔 막걸리 (Feat. 신승열) --- Memory For You\n",
      "0 --- 레미 --- 비오는 이른 새벽 자장가 --- 비오는 날엔 막걸리\n",
      "0 --- 롤러코스터 --- 비 오는 경리단길 (Feat. 양은선) --- 1집 내게로 와\n",
      "0 --- 로만티코(Romantico) --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Diminished Part 1\n",
      "0 --- Flower Singers --- 비오는 밤 --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "0 --- 도나웨일(Donawhale) --- 비오는 날의 수채화 --- 1집 Donawhale\n",
      "0 --- 박정현 --- 비오는 밤 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "0 --- 서효린 --- 비오는 밤 --- 가을동화\n",
      "0 --- 최설아 --- Rainy Day (비오는 날) --- 비오는 밤\n",
      "0 --- 김광민 --- 비 오는 밤 --- 1집 Letter From The Earth\n",
      "0 --- 어프로그레시브 피아노 --- 드뷔시 - 비 오는 정원 --- One Day\n",
      "0 --- Various Artists --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- Rain Piano : 비오는 날, 듣기 좋은 피아노\n",
      "0 --- 노블레스 --- 자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기... --- 7집 Growing Pains\n",
      "0 --- 자장가 --- 비오는 날의 수채화 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "0 --- 권인하 --- 비 오는 날 --- 첫사랑\n",
      "0 --- 민티 --- 비오는 골목 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "0 --- 김윤아 --- 비오는 일요일 --- 비오는 골목\n",
      "0 --- 온음 --- 자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가) --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "0 --- 자장가 --- 비 오는 날 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "0 --- 명상피아노 --- 비 오는 날 카페에 앉아 --- 비 오는 날\n",
      "0 --- 디오티마 --- 비오는 거리 (빗속에서) --- 비 오는 날 카페에 앉아\n",
      "0 --- 레드 페이스(Red Face) --- 자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가) --- 喜入合 (희입합)\n",
      "0 --- 자장가 --- 자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "0 --- 자장가 --- 비 오는 거리에서 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "total number of items: 50\n",
      "1 --- {ARTIST} --- 비 오는 거리 --- 앨범\n",
      "1 --- 이승훈 --- 비오는 날 수채화 --- 1집 비오는 거리\n",
      "1 --- 강인원 --- 비 오는 거리 --- 비오는 날 수채화 1 OST\n",
      "1 --- 소울스타 (SoulstaR) --- 비 오는 이런 날에 --- 비 오는 거리\n",
      "1 --- 은가은 --- 비오는 금요일 --- 비 오는 이런 날에\n",
      "1 --- 비오는 금요일 --- 비오는 압구정 --- 비오는 금요일\n",
      "1 --- 브라운 아이즈 --- 비오는 거리 --- 2집 Reason 4 Breathing?\n",
      "1 --- 유리상자 --- 비 오는 거리  (Feat. 핫펠트) --- 유ㄹish.1 - 비오는 거리\n",
      "1 --- 베이빌론(Babylon) --- 비오는 거리 --- BETWEEN US\n",
      "1 --- 서영은 --- 비 오는 날 --- 1집 Romantic 1\n",
      "1 --- 오소연 --- 비오는 날엔 --- 비 오는 날\n",
      "1 --- 소심한 오빠들 --- 비 오는 거리에서 --- 비오는 날엔\n",
      "1 --- 아스트로피아노 --- 비오는 압구정 --- 비 오는 거리에서\n",
      "1 --- 브라운 아이즈 --- 비오는 날, 산책 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "1 --- 모모캣츠(Momocats) --- 비 오는 날 --- 비오는 날, 산책\n",
      "1 --- 김봄 --- 비오는 아침 --- 비 오는 날\n",
      "1 --- 재주소년 --- 비오는 압구정 --- 1집 재주소년 (才洲少年)\n",
      "1 --- 서영은 --- 비오는 날 --- Unforgettable No.2\n",
      "1 --- 루싸이트 토끼 --- 비 오는 거리에서 --- 1집 Twinkle Twinkle\n",
      "1 --- 이승철 --- 비오는 날엔 파전 (Feat. Wonny) --- 시간 참 빠르다\n",
      "1 --- 비트코인(BEATCOIN) --- 비오는 날 --- 비오는 날엔 파전\n",
      "1 --- 오은영 --- 비오는 날은 푸르다 --- 비오는 날\n",
      "1 --- 하이니(Hi.ni) --- 비 오는 날의 수채화 --- 비오는 날은 푸르다\n",
      "1 --- SG 워너비 --- 비오는 거리 --- Classic Odyssey\n",
      "1 --- 이금성 --- 비 오는 거리 --- 비오는 거리\n",
      "1 --- SG 워너비 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Classic Odyssey\n",
      "1 --- 럼블 피쉬 --- 비오는 날엔 막걸리 (Feat. 신승열) --- Memory For You\n",
      "1 --- 레미 --- 비오는 이른 새벽 자장가 --- 비오는 날엔 막걸리\n",
      "1 --- 롤러코스터 --- 비 오는 경리단길 (Feat. 양은선) --- 1집 내게로 와\n",
      "1 --- 로만티코(Romantico) --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Diminished Part 1\n",
      "1 --- Flower Singers --- 비오는 밤 --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "1 --- 도나웨일(Donawhale) --- 비오는 날의 수채화 --- 1집 Donawhale\n",
      "1 --- 박정현 --- 비오는 밤 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "1 --- 서효린 --- 비오는 밤 --- 가을동화\n",
      "1 --- 최설아 --- Rainy Day (비오는 날) --- 비오는 밤\n",
      "1 --- 김광민 --- 비 오는 밤 --- 1집 Letter From The Earth\n",
      "1 --- 어프로그레시브 피아노 --- 드뷔시 - 비 오는 정원 --- One Day\n",
      "1 --- Various Artists --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- Rain Piano : 비오는 날, 듣기 좋은 피아노\n",
      "1 --- 노블레스 --- 자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기... --- 7집 Growing Pains\n",
      "1 --- 자장가 --- 비오는 날의 수채화 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "1 --- 권인하 --- 비 오는 날 --- 첫사랑\n",
      "1 --- 민티 --- 비오는 골목 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "1 --- 김윤아 --- 비오는 일요일 --- 비오는 골목\n",
      "1 --- 온음 --- 자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가) --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "1 --- 자장가 --- 비 오는 날 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "1 --- 명상피아노 --- 비 오는 날 카페에 앉아 --- 비 오는 날\n",
      "1 --- 디오티마 --- 비오는 거리 (빗속에서) --- 비 오는 날 카페에 앉아\n",
      "1 --- 레드 페이스(Red Face) --- 자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가) --- 喜入合 (희입합)\n",
      "1 --- 자장가 --- 자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가) --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n",
      "1 --- 자장가 --- 비 오는 거리에서 --- 자장가 (비오는 소리와 함께 편안한 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "for pageNo in range(2):\n",
    "    p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "    r = requests.get(naverUrl,params=p)\n",
    "    soup=BeautifulSoup(r.text,\"lxml\")\n",
    "    _selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "    _selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "    _selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "    print \"total number of items:\",len(_selName) \n",
    "    for i in range(len(_selName)):\n",
    "        print pageNo,'---',_selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### lxml로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = lxml.html.fromstring(r.text)\n",
    "nodes=html.cssselect('._tracklist_move > .name > a.title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비오는 날 수채화\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 금요일\n",
      "비오는 압구정\n",
      "비오는 거리\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 거리\n",
      "비 오는 날\n",
      "비오는 날엔\n",
      "비 오는 거리에서\n",
      "비오는 압구정\n",
      "비오는 날, 산책\n",
      "비 오는 날\n"
     ]
    }
   ],
   "source": [
    "for e in nodes:\n",
    "    print e.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import requests\n",
    "\n",
    "#p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\"}\n",
    "r = requests.get(naverUrl,params=p)\n",
    "_html = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* html을 보려면\n",
    "    * r.text로 보거나\n",
    "    * lxml.html.tostring(_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lxml.html.tostring(_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes=_html.cssselect('._tracklist_move > .name > a.title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* item.text()는 한글 문자 출력 오류\n",
    "* item.text_content()를 사용해서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "비 오는 거리\n",
      "비 오는 이런 날에\n",
      "비오는 압구정\n",
      "비 오는 거리  (Feat. 핫펠트)\n",
      "비오는 날 수채화\n",
      "비오는 거리\n",
      "비오는 거리\n",
      "비오는 압구정\n",
      "비 오는 날\n",
      "비오는 아침\n",
      "비오는 날엔\n",
      "비오는 날\n",
      "비 오는 거리에서\n",
      "비 오는 거리에서\n",
      "비오는 날, 산책\n",
      "비 오는 날\n",
      "비 오는 경리단길 (Feat. 양은선)\n",
      "비오는 압구정\n",
      "비오는 날\n",
      "7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기)\n",
      "비오는날의 수채화 (Feat. 정혜민, Misty)\n",
      "비오는 밤\n",
      "비오는 날의 수채화\n",
      "비 오는 날의 수채화\n",
      "비 오는 거리\n",
      "비오는 날은 푸르다\n",
      "비오는 이른 새벽 자장가\n",
      "Rainy Day (비오는 날)\n",
      "비오는 금요일\n",
      "I'd Love You To Want Me (CF '코업레지던스', 영화...\n",
      "Rhythm Of The Rain (빗줄기의 리듬 : CF 'LG 정유...\n",
      "자장가 (비오는 소리와 함께하는 아베마리아 아기 자장가)\n",
      "자장가 (비오는 소리와 함께하는 고요한 밤 거룩한 밤 아기...\n",
      "비오는 거리\n",
      "비오는 날엔 (Feat. 어쿠스틱 콜라보)\n",
      "Rain (호세 펠라치아노의 대표곡 : 레인)\n",
      "House Of The Rising Sun (해뜨는 집, 드라마 '올인' OST)\n",
      "California Dreamin' (캘리포니아 드림 - 영화...\n",
      "비 오는 밤\n",
      "자장가 (비오는 소리와 함께하는 슈베르트 아기 자장가)\n",
      "비오는 일요일\n",
      "자장가 (비오는 소리와 함께하는 울면 안돼 아기 자장가)\n",
      "비오는 날엔\n",
      "비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가)\n",
      "자장가 (비오는 소리와 함께하는 모차르트 아기 자장가)\n",
      "비오는 날의 수채화\n",
      "비오는 날엔 막걸리 (Feat. 신승열)\n",
      "Evergreen\n",
      "자장가 (비오는 소리와 함께하는 위안 아기 자장가)\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    print node.text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 곡명, 아티스트, 앨범 모두 가져오기\n",
    "    * html이 정형적이지 않아서 어렵다.\n",
    "    * 2단계 작업.\n",
    "        * 곡명, 아티스트, 앨범 항목을 가지고 있는 상위 태그를 먼저 선정하고, 그 안의 개별 항목을 선정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr class=\"_tracklist_move {TRACK_TYPE}\" style=\"display:none;\" trackdata=\"{TRACK_DATA}\">\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"chk\"><input type=\"checkbox\" title=\"&#49440;&#53469;\" class=\"_chkbox_item input_chk {TRACK_CHECK_NCLICKS}\"> </td>\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"order\">{TRACK_NUM}</td>\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t\t<td class=\"name\">\r\n",
      "\r\n",
      "\t\t\t\t\t\t\t\t{PLAY_TOGGLE}\r\n",
      "\t\t\t\t\t\t\t\t{ADD_TOGGLE}\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\t\t\t\t\t<span class=\"_ico_title ico_title\"><img height=\"18\" width=\"23\" alt=\"TITLE\" src=\"http://static.naver.net/nmusic/201\n"
     ]
    }
   ],
   "source": [
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "sel = CSSSelector('._tracklist_move')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)\n",
    "print lxml.html.tostring(nodes[0])[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 개별 항목의 선정\n",
    "* 우선 1개씩 해 본다.\n",
    "    * results[0]은 제목행이므로, 그 다음을 처리한다.\n",
    "    * 태그가 정형적이지 않으므로, selector가 일정하지 않다는 점에 주의한다.\n",
    "        * Chrome console창을 이용해서 하나씩 작업하므로, selector를 정의하는데 노력이 수반된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "_name=_selName(nodes[1])\n",
    "_artist=_selArtist(nodes[1])\n",
    "_album=_selAlbum(nodes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 오는 거리\n",
      "이승훈\n",
      "1집 비오는 거리\n"
     ]
    }
   ],
   "source": [
    "print _name[0].text_content()\n",
    "print _artist[0].text_content().strip()\n",
    "print _album[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 반복문을 이용하여 모든 노래를 출력한다.\n",
    "    * if문은 노래제목이 없는 경우 제거한다 (제목 행을 제거하는 효과)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "강인원 --- 비오는 날 수채화 --- 비오는 날 수채화 1 OST\n",
      "오소연 --- 비 오는 날 --- 비 오는 날\n",
      "동요시대 --- 비오는날 (동요) (멜로디 MR) --- 동요 MR반주 5\n",
      "서영은 --- 비오는 거리 --- 1집 Romantic 1\n",
      "루드 페이퍼(Rude Paper) --- 비오는 밤에 --- 1집 Paper Spectrum\n",
      "김민우 --- 비오는 날 (Inst.) --- 비오는 날\n",
      "조영순 --- 비오는 남산 --- 무진장 트롯트 골든 1＆2\n",
      "베이빌론(Babylon) --- 비 오는 거리  (Feat. 핫펠트) --- BETWEEN US\n",
      "브라운 아이즈 --- 비오는 압구정 --- 2집 Reason 4 Breathing?\n",
      "하이니(Hi.ni) --- 비오는 날은 푸르다 --- 비오는 날은 푸르다\n",
      "Richard Marx --- One More Time --- 김현주의 비오는 거리\n",
      "SG 워너비 --- 비 오는 날의 수채화 --- Classic Odyssey\n",
      "Romantisch Jazzkapelle --- Yesterday (비틀즈 예스터 데이 : CF `시몬스침대`) --- 뉴에이지 연가 : 비 오는 날의 거리, 추억, 그리고 아름다운 재즈 피아노(Pop 올드 팝, 클래식, 영화 OST 베스트 연주 음악)\n",
      "강윤식 --- 비오는날 수채화 (발라드 Ver.) (With 김명상, 강윤식) --- 1980-2010 리뉴얼 - 내 노래 다시 부르기\n"
     ]
    }
   ],
   "source": [
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    _name=_selName(node)\n",
    "    _artist=_selArtist(node)\n",
    "    _album=_selAlbum(node)\n",
    "    if _name:\n",
    "        print _artist[0].text_content().strip(),\n",
    "        print \"---\",\n",
    "        print _name[0].text_content(),\n",
    "        print \"---\",\n",
    "        print _album[0].text_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이승훈 --- 비 오는 거리 --- 1집 비오는 거리\n",
      "강인원 --- 비오는 날 수채화 --- 비오는 날 수채화 1 OST\n",
      "소울스타 (SoulstaR) --- 비 오는 거리 --- 비 오는 거리\n",
      "브라운 아이즈 --- 비오는 압구정 --- 2집 Reason 4 Breathing?\n",
      "은가은 --- 비 오는 이런 날에 --- 비 오는 이런 날에\n",
      "비트코인(BEATCOIN) --- 비오는 날엔 파전 (Feat. Wonny) --- 비오는 날엔 파전\n",
      "유리상자 --- 비오는 거리 --- 유ㄹish.1 - 비오는 거리\n",
      "서영은 --- 비오는 거리 --- 1집 Romantic 1\n",
      "오소연 --- 비 오는 날 --- 비 오는 날\n",
      "베이빌론(Babylon) --- 비 오는 거리  (Feat. 핫펠트) --- BETWEEN US\n",
      "소심한 오빠들 --- 비오는 날엔 --- 비오는 날엔\n",
      "비오는 금요일 --- 비오는 금요일 --- 비오는 금요일\n",
      "아스트로피아노 --- 비 오는 거리에서 --- 비 오는 거리에서\n",
      "브라운 아이즈 --- 비오는 압구정 --- The Very Best Of Browneyes `Take A Favorite`\n",
      "김광민 --- Rainy Day (비오는 날) --- 1집 Letter From The Earth\n",
      "김봄 --- 비 오는 날 --- 비 오는 날\n",
      "오은영 --- 비오는 날 --- 비오는 날\n",
      "모모캣츠(Momocats) --- 비오는 날, 산책 --- 비오는 날, 산책\n",
      "럼블 피쉬 --- 비오는날의 수채화 (Feat. 정혜민, Misty) --- Memory For You\n",
      "하이니(Hi.ni) --- 비오는 날은 푸르다 --- 비오는 날은 푸르다\n",
      "재주소년 --- 비오는 아침 --- 1집 재주소년 (才洲少年)\n",
      "루싸이트 토끼 --- 비오는 날 --- 1집 Twinkle Twinkle\n",
      "이승철 --- 비 오는 거리에서 --- 시간 참 빠르다\n",
      "이금성 --- 비오는 거리 --- 비오는 거리\n",
      "SG 워너비 --- 비 오는 날의 수채화 --- Classic Odyssey\n",
      "포레스트 엘(Forest L) --- 비 오는 날 (Rainy Day) --- 비 오는 날 (Rainy Day)\n",
      "김윤아 --- 비오는 골목 --- 비오는 골목\n",
      "디오티마 --- 비 오는 날 카페에 앉아 --- 비 오는 날 카페에 앉아\n",
      "노블레스 --- 비오는 날엔 (Feat. 어쿠스틱 콜라보) --- 7집 Growing Pains\n",
      "SG 워너비 --- 비 오는 거리 --- Classic Odyssey\n",
      "서영은 --- 비오는 압구정 --- Unforgettable No.2\n",
      "Flower Singers --- 7080 가요 메들리 (지난날, 비오는 날의 수채화, 보랏빛 향기) --- Flower Singers 7080 세대를 위한 학창시절 추억의 노래\n",
      "서효린 --- 비오는 밤 --- 가을동화\n",
      "백색소음 --- 비 오는 계곡 물소리 (백색소음 화이트 노이즈 자장가) --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "박정현 --- 비오는 날의 수채화 --- 서바이벌 나는 가수다 경연 1 `80년대 명곡 부르기\n",
      "백색소음 --- 비 오는 숲 소리 (백색소음 화이트 노이즈 자장가) --- 백색소음 (15가지 화이트노이즈, 빗소리, 진공청소기소리, 숲소리, 집중력 높이는 법, 명상 자장가)\n",
      "민티 --- 비 오는 날 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "Mr. 페페 --- 비 오는 거리에서 --- 명상 뉴에이지 음악 (비오는 날의 명상)\n",
      "모니카(Monica) --- 비 오는 창가에서 --- 명상음악 아이를 위한 태교 Part 8\n",
      "어프로그레시브 피아노 --- 비 오는 밤 --- One Day\n",
      "권언정 --- 비오는 날마다 (Piano 조은진) --- 비오는 날마다\n",
      "롤러코스터 --- 비오는 이른 새벽 자장가 --- 1집 내게로 와\n",
      "거북이 --- 비오는 날 --- 1집 Go! Boogie!\n",
      "서영은 --- 비 오는 거리 --- 서영은 리메이크 베스트 모음집\n",
      "로만티코(Romantico) --- 비 오는 경리단길 (Feat. 양은선) --- Diminished Part 1\n",
      "레드 페이스(Red Face) --- 비오는 거리 (빗속에서) --- 喜入合 (희입합)\n",
      "권인하 --- 비오는 날의 수채화 --- 첫사랑\n",
      "도나웨일(Donawhale) --- 비오는 밤 --- 1집 Donawhale\n",
      "줄라이(July) --- 비오는 날 (Piano ver.) --- Ending Song (Digital Single)\n",
      "남예지 --- 비오는 저녁 --- 2집 Terra Incognita\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import lxml.html\n",
    "import requests\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":1}\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\"}\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "r = requests.get(naverUrl,params=p)\n",
    "_html = lxml.html.fromstring(r.text)\n",
    "\n",
    "sel = CSSSelector('table[summary] > tbody > ._tracklist_move')\n",
    "# Apply the selector to the DOM tree.\n",
    "nodes = sel(_html)\n",
    "\n",
    "_selName = CSSSelector('.name > a.title')\n",
    "_selArtist = CSSSelector('._artist.artist')\n",
    "_selAlbum= CSSSelector('.album > a')\n",
    "for node in nodes:\n",
    "    #print lxml.html.tostring(item)\n",
    "    _name=_selName(node)\n",
    "    _artist=_selArtist(node)\n",
    "    _album=_selAlbum(node)\n",
    "    if _name:\n",
    "        print _artist[0].text_content().strip(),\n",
    "        print \"---\",\n",
    "        print _name[0].text_content(),\n",
    "        print \"---\",\n",
    "        print _album[0].text_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load src/ds3_4_naverMusic.py\n",
    "#!\n",
    "import lxml.html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "#keyword='비오는'\n",
    "#p = {'query': '비오는', '&x': 0, '&y':0}\n",
    "pageNo=1\n",
    "p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "#r = requests.get(\"http://music.naver.com/search/search.nhn?query=\"+keyword+\"&x=0&y=0\")\n",
    "naverUrl=\"http://music.naver.com/search/search.nhn?\"\n",
    "def readMusicLxml():\n",
    "    try:\n",
    "        r = requests.get(naverUrl,params=p)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    _html = lxml.html.fromstring(r.text)\n",
    "    #sel = CSSSelector('table[summary] > tbody > ._tracklist_move')\n",
    "    sel = CSSSelector('._tracklist_move')\n",
    "    # Apply the selector to the DOM tree.\n",
    "    nodes = sel(_html)\n",
    "    _selName = CSSSelector('.name > a.title')\n",
    "    _selArtist = CSSSelector('._artist.artist')\n",
    "    _selAlbum= CSSSelector('.album > a')\n",
    "    for node in nodes:\n",
    "        #print lxml.html.tostring(item)\n",
    "        _name=_selName(node)\n",
    "        _artist=_selArtist(node)\n",
    "        _album=_selAlbum(node)\n",
    "        if _name:\n",
    "            print _artist[0].text_content().strip(),\n",
    "            print \"---\",\n",
    "            print _name[0].text_content(),\n",
    "            print \"---\",\n",
    "            print _album[0].text_content()\n",
    "\n",
    "def readMusicBS():\n",
    "    try:\n",
    "        #pageNo=1\n",
    "        for pageNo in range(10):\n",
    "            p = {\"query\": u\"비오는\",\"target\":\"track\", \"page\":pageNo}\n",
    "            r = requests.get(naverUrl,params=p)\n",
    "            #if r.text is not '':\n",
    "            soup=BeautifulSoup(r.text,\"lxml\")\n",
    "            _selName = [title.get_text().strip() for title in soup.select('._tracklist_move > .name > a.title')]\n",
    "            _selArtist = [artist.get_text().strip() for artist in soup.select('._artist.artist')]\n",
    "            _selAlbum= [album.get_text().strip() for album in soup.select('.album > a')]\n",
    "            print \"total number of items:\",len(_selName)\n",
    "            for i in range(len(_selName)):\n",
    "                print pageNo,'---',_selArtist[i],'---',_selName[i],'---',_selAlbum[i]\n",
    "            #pageNo+=1\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "\n",
    "def main():\n",
    "    readMusicLxml()\n",
    "    readMusicBS() #bug - print header and no last line \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds3_4_naverMusic.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 해보기\n",
    "\n",
    "* 각 노래마다 가사를 새로운 창으로 띄우고 있다. 이 가사를 가져오기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-5 : 국제학회 목록을 가져오기\n",
    "\n",
    "* IEEE 학회를 검색하는 url\n",
    "```\n",
    "http://www.ieee.org/conferences_events/conferences/search/index.html\n",
    "```\n",
    "\n",
    "* 크롬 브라우저 > 보기 > 개발자 정보 > javascript console\n",
    "    * Elements 창에서 검색을 하면 원하는 문자열을 찾을 수 있다.\n",
    "    * css로 태그를 찾아 본다.\n",
    "        ```\n",
    "        'div.content-r-full table.nogrid-nopad tr'\n",
    "        ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "r = requests.get('http://www.ieee.org/conferences_events/conferences/search/index.html')\n",
    "\n",
    "html = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en-us\" xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en-us\">\r\n",
      "<head><meta http-equiv=\"c\n"
     ]
    }
   ],
   "source": [
    "print lxml.html.tostring(html)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 66개의 데이터를 가지고 있다. 페이지를 열어서 비교해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "sel=CSSSelector('div.content-r-full table.nogrid-nopad tr p>a[href]')\n",
    "nodes = sel(html)\n",
    "print len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "2029 IEEE/MTT-S International Microwave Symposium - IMS 2029\n",
      "----------\n",
      "31 May - 08 Jun 2029\n",
      "----------\n",
      "Boston Convention and Exhibition Center\n",
      "----------\n",
      "2025 IEEE/MTT-S International Microwave Symposium - IMS 2025\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for node in nodes[:10]:\n",
    "    print node.text\n",
    "    print \"----------\"\n",
    "    #print lxml.html.tostring(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```\n",
    "\n",
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds_web_crawl_ieee.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  142204\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "None\n",
      "----------\n",
      "2036 IEEE/MTT-S International Microwave Symposium - IMS 2036\n",
      "----------\n",
      "01 Jun - 06 Jun 2036\n",
      "----------\n",
      "Boston Convention and Exhibition Center (BCEC)\n",
      "----------\n",
      "2031 IEEE/MTT-S International Microwave Symposium - IMS 2031\n",
      "----------\n",
      "01 Jun - 06 Jun 2031\n",
      "----------\n",
      "Boston Convention and Exhibition Center (BCEC)\n",
      "----------\n",
      "2029 IEEE/MTT-S International Microwave Symposium - IMS 2029\n",
      "----------\n",
      "31 May - 08 Jun 2029\n",
      "----------\n",
      "Boston Convention and Exhibition Center\n",
      "----------\n",
      "2026 IEEE/MTT-S International Microwave Symposium - IMS 2026\n",
      "----------\n",
      "07 Jun - 12 Jun 2026\n",
      "----------\n",
      "Boston Convention and Exhibition Center (BCEC)\n",
      "----------\n",
      "2025 IEEE/MTT-S International Microwave Symposium - IMS 2025\n",
      "----------\n",
      "15 Jun - 20 Jun 2025\n",
      "----------\n",
      "Moscone Convention Center\n",
      "----------\n",
      "2024 IEEE/MTT-S International Microwave Symposium - IMS 2024\n",
      "----------\n",
      "16 Jun - 21 Jun 2024\n",
      "----------\n",
      "Walter E. Washington Convention Center\n",
      "----------\n",
      "S4XXX Test\n",
      "----------\n",
      "04 Sep - 07 Sep 2023\n",
      "----------\n",
      "tbd\n",
      "----------\n",
      "2023 Annual International Conference of the IEEE Engineering in Medicine & Biology Conference (EMBC)\n",
      "----------\n",
      "25 Jul - 29 Jul 2023\n",
      "----------\n",
      "International Convention Centre Sydney (ICC Sydney)\n",
      "----------\n",
      "2023 IEEE/MTT-S International Microwave Symposium - IMS 2023\n",
      "----------\n",
      "11 Jun - 16 Jun 2023\n",
      "----------\n",
      "San Diego Convention Center\n",
      "----------\n",
      "2023 IEEE International Solid- State Circuits Conference (ISSCC)\n",
      "----------\n",
      "14 Feb - 26 Feb 2023\n",
      "----------\n",
      "Marriott Marquis\n",
      "----------\n",
      "2022 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC)\n",
      "----------\n",
      "26 Sep - 29 Sep 2022\n",
      "----------\n",
      "Sheraton Denver Downtown\n",
      "----------\n",
      "2022 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\n",
      "----------\n",
      "25 Jul - 29 Jul 2022\n",
      "----------\n",
      "raleigh CC\n",
      "----------\n",
      "2022  IEEE/MTT-S International Microwave Symposium - IMS 2022\n",
      "----------\n",
      "12 Jun - 17 Jun 2022\n",
      "----------\n",
      "Colorado Convention Center\n",
      "----------\n",
      "2022 59th ACM/EDAC/IEEE Design Automation Conference (DAC)\n",
      "----------\n",
      "06 Jun - 10 Jun 2022\n",
      "----------\n",
      "Moscone Center\n",
      "----------\n",
      "2022 IEEE International Solid- State Circuits Conference (ISSCC)\n",
      "----------\n",
      "15 Feb - 27 Feb 2022\n",
      "----------\n",
      "Marriott Marquis\n",
      "----------\n",
      "2022 Annual Conference on Magnetism and Magnetic Materials (MMM)\n",
      "----------\n",
      "10 Jan - 14 Jan 2022\n",
      "----------\n",
      "Hyatt Regency New Orleans\n",
      "----------\n",
      "2021 IEEE International Electron Devices Meeting (IEDM)\n",
      "----------\n",
      "13 Dec - 15 Dec 2021\n",
      "----------\n",
      "Hilton San Francisco Union Square\n",
      "----------\n",
      "2021 IEEE International Conference on Image Processing (ICIP)\n",
      "----------\n",
      "19 Sep - 22 Sep 2021\n",
      "----------\n",
      "DENA'INA Civic and Convention Center\n",
      "----------\n",
      "2021 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC)\n",
      "----------\n",
      "13 Sep - 16 Sep 2021\n",
      "----------\n",
      "San Antonio Marriott Rivercenter\n",
      "----------\n",
      "2021 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\n",
      "----------\n",
      "27 Jul - 31 Jul 2021\n",
      "----------\n",
      "Raleigh convention center\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# %load src/ds3_5_readIEEE.py\n",
    "#!\n",
    "\n",
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests\n",
    "\n",
    "def readIEEE():\n",
    "    try:\n",
    "        r = requests.get('http://www.ieee.org/conferences_events/conferences/search/index.html')\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    page=r.text\n",
    "    print \"length: \",len(page)\n",
    "    html = lxml.html.fromstring(page)\n",
    "    sel=CSSSelector('div.content-r-full table.nogrid-nopad tr p>a[href]')\n",
    "    nodes = sel(html)\n",
    "    for node in nodes:\n",
    "        print node.text\n",
    "        print \"----------\"\n",
    "\n",
    "def main():\n",
    "    readIEEE()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "None\r\n",
      "----------\r\n",
      "2029 IEEE/MTT-S International Microwave Symposium - IMS 2029\r\n",
      "----------\r\n",
      "31 May - 08 Jun 2029\r\n",
      "----------\r\n",
      "Boston Convention and Exhibition Center\r\n",
      "----------\r\n",
      "2025 IEEE/MTT-S International Microwave Symposium - IMS 2025\r\n",
      "----------\r\n",
      "15 Jun - 20 Jun 2025\r\n",
      "----------\r\n",
      "Moscone Convention Center\r\n",
      "----------\r\n",
      "2024 IEEE/MTT-S International Microwave Symposium - IMS 2024\r\n",
      "----------\r\n",
      "16 Jun - 21 Jun 2024\r\n",
      "----------\r\n",
      "Walter E. Washington Convention Center\r\n",
      "----------\r\n",
      "2023 Annual International Conference of the IEEE Engineering in Medicine & Biology Conference (EMBC)\r\n",
      "----------\r\n",
      "25 Jul - 29 Jul 2023\r\n",
      "----------\r\n",
      "International Convention Centre Sydney (ICC Sydney)\r\n",
      "----------\r\n",
      "2023 IEEE/MTT-S International Microwave Symposium - MTT 2023\r\n",
      "----------\r\n",
      "11 Jun - 16 Jun 2023\r\n",
      "----------\r\n",
      "San Diego Convention Center\r\n",
      "----------\r\n",
      "2022 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\r\n",
      "----------\r\n",
      "25 Jul - 29 Jul 2022\r\n",
      "----------\r\n",
      "raleigh CC\r\n",
      "----------\r\n",
      "2022 IEEE/MTT-S International Microwave Symposium - MTT 2022\r\n",
      "----------\r\n",
      "12 Jun - 17 Jun 2022\r\n",
      "----------\r\n",
      "Colorado Convention Center\r\n",
      "----------\r\n",
      "2022 59th ACM/EDAC/IEEE Design Automation Conference (DAC)\r\n",
      "----------\r\n",
      "06 Jun - 10 Jun 2022\r\n",
      "----------\r\n",
      "Moscone Center\r\n",
      "----------\r\n",
      "2022 Annual Conference on Magnetism and Magnetic Materials (MMM)\r\n",
      "----------\r\n",
      "10 Jan - 14 Jan 2022\r\n",
      "----------\r\n",
      "Hyatt Regency New Orleans\r\n",
      "----------\r\n",
      "2021 IEEE International Electron Devices Meeting (IEDM)\r\n",
      "----------\r\n",
      "13 Dec - 15 Dec 2021\r\n",
      "----------\r\n",
      "Hilton San Francisco Union Square\r\n",
      "----------\r\n",
      "2021 IEEE International Symposium on Electromagnetic Compatibility & Signal/Power Integrity (EMCSI)\r\n",
      "----------\r\n",
      "27 Jul - 31 Jul 2021\r\n",
      "----------\r\n",
      "Raleigh convention center\r\n",
      "----------\r\n",
      "2021 IEEE International Conference on Plasma Science (ICOPS)\r\n",
      "----------\r\n",
      "20 Jun - 25 Jun 2021\r\n",
      "----------\r\n",
      "Harvey's & Harrah's\r\n",
      "----------\r\n",
      "2021 IEEE/MTT-S International Microwave Symposium - MTT 2021\r\n",
      "----------\r\n",
      "20 Jun - 24 Jun 2021\r\n",
      "----------\r\n",
      "Georgia World Congress Center\r\n",
      "----------\r\n",
      "2021 58th ACM/EDAC/IEEE Design Automation Conference (DAC)\r\n",
      "----------\r\n",
      "07 Jun - 11 Jun 2021\r\n",
      "----------\r\n",
      "Moscone Center\r\n",
      "----------\r\n",
      "2021 IEEE Pulsed Power Conference (PPC)\r\n",
      "----------\r\n",
      "01 Jun - 04 Jun 2021\r\n",
      "----------\r\n",
      "Sheraton Denver Downtown Hotel\r\n",
      "----------\r\n",
      "2021 IEEE 71st Electronic Components and Technologies Conference (ECTC)\r\n",
      "----------\r\n",
      "01 Jun - 04 Jun 2021\r\n",
      "----------\r\n",
      "Sheraton San diego Hotel & Marina\r\n",
      "----------\r\n",
      "2021 IEEE Symposium on Security and Privacy (SP)\r\n",
      "----------\r\n",
      "23 May - 27 May 2021\r\n",
      "----------\r\n",
      "Hyatt Regency San Francisco\r\n",
      "----------\r\n",
      "2021 IEEE International Workshop Technical Committee on Communications Quality and\r\n",
      "Reliability (CQR 2021)\r\n",
      "----------\r\n",
      "09 May - 14 May 2021\r\n",
      "----------\r\n",
      "Naples Beach Hotel & Golf Club\r\n",
      "----------\r\n",
      "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\r\n",
      "----------\r\n",
      "25 Apr - 30 Apr 2021\r\n",
      "----------\r\n",
      "Metro Toronto Convention Centre\r\n",
      "----------\r\n",
      "2020 IEEE International Electron Devices Meeting (IEDM)\r\n",
      "----------\r\n",
      "10 Dec - 18 Dec 2020\r\n",
      "----------\r\n",
      "Hilton San Francisco\r\n",
      "----------\r\n"
     ]
    }
   ],
   "source": [
    "!python src/ds3_5_readIEEE.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* 학회를 검색하는 폼에 입력하면, 검색문자열을 생성한다. 다음은 검색문자열이 포함된 url이다. 검색을 하는 경우 크롤링을 해본다.\n",
    "```\n",
    "http://www.ieee.org/conferences_events/conferences/search/index.html?\n",
    "RANGE_FROM_DATE=2017-01-01&RANGE_TO_DATE=2030-12-31&\n",
    "KEYWORDS=&\n",
    "COUNTRY=ALL&STATE=ALL&CITY=ALL&REGION=ALL&\n",
    "RECORD_NUM=ALL&SPONSOR=ALL&EXHIBIT=ALL&TUTORIALS=ALL&\n",
    "RowsPerPage=10&PageLinkNum=10&ActivePage=1&\n",
    "SORTORDER=asc&SORTFIELD=start_date&ROWSTART=0&CONF_SRCH_RDO=conf_date&\n",
    "utm_source=mm_link&utm_campaign=upcom&utm_medium=conf&utm_term=upcoming%20conferences\n",
    "```\n",
    "\n",
    "* 학회명, 학회일시, 학회장소를 구분해서 추출해 본다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-6: 한국 프로야구 팀 순위 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "최근 스포츠에 과학기법을 많이 활용하고 있다. 세밀한 차이가 승패를 좌우하는 까닭에 실시간으로 데이터를 분석해 보다 과학적으로 순간 순간의 결정에 활용하고 있다. 야구가 좋은 예이다. 많은 데이터를 가지고, 특정 투수에 대한 선수의 약점, 선수에 대한 필드의 배치를 결정하기도 한다.\n",
    "한국 프로야구 팀의 순위를 가져오기로 한다.\n",
    "\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지로 가서 소스보기를 해본다. \n",
    "기록이 테이블 형식으로 구성되어 있다.\n",
    "야구선수 또는 팀은 한글이다. 검색하려면 unicode로 패턴 찾는다. 한글 앞에 unicode를 의미하는 u'타자'라고 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kbreport.com/leader/main?rows=20&order=oWAR&orderType=DESC&teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import requests\n",
    "urlbase=\"http://www.kbreport.com/leader/main?\"\n",
    "url1=\"rows=20&order=oWAR&orderType=DESC&\"\n",
    "url2=\"teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\"\n",
    "urlbaseball=urlbase+url1+url2\n",
    "print urlbaseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kbreport.com/leader/main?rows=20&order=oWAR&orderType=DESC&teamId=1&defense_no=2&year_from=2015&year_to=2015&split01=&split02_1=&split02_2=&r_tpa_count=&tpa_count=0\n",
      " href=\"/history/main\"><li>역대기록</li></a>\n",
      "\t\t\t\t\t<a href=\"/statDic/main\"><li id=\"nav4\">STAT Dic</li></a>\n",
      "\t\t\t\t\t<a href=\"/event/hitProbabilityPerGame\"><li>투수 VS 타자</li></a>\n",
      "\t\t\t\t\t<!-- \n",
      "\t\t\t\t\t<a href=\"score.html\"><li id=\"nav1\">경기결과</li></a>\n",
      "\t\t\t\t\t<a href=\"/statBuzz/main\"><li id=\"nav2\">STAT BUZZ</li></a>\n",
      "\t\t\t\t\t<a href=\"depth.html\"><li>팀구성도</li></a>\n",
      "\t\t\t\t\t<a href=\"trade.html\"><li>선수이동내역</li></a>\n",
      "\t\t\t\t\t<a href=\"/leader/main\"><li>개인순위</li></a>\n",
      "\t\t\t\t\t<a href=\"team.html\"><li>팀순위</li></a>\n",
      "\t\t\t\t\t<a href=\"awa\n"
     ]
    }
   ],
   "source": [
    "data=requests.get(urlbaseball).text\n",
    "print data[6000:6500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6340\n",
      "8353\n"
     ]
    }
   ],
   "source": [
    "print data.find('top-score-top')\n",
    "print data.find('top-score end')\n",
    "\n",
    "#import re\n",
    "#p=re.compile('NC\\w+')\n",
    "#res=re.search('<title>', data)\n",
    "#res=re.search(u'타자.+', data)\n",
    "#res=re.search(u'야구.통계.+', data)\n",
    "#print res.group()\n",
    "\n",
    "#data.encode('utf-8')\n",
    "#print data\n",
    "#from BeautifulSoup import BeautifulSoup\n",
    "#BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r', u'(\\uc2b9) \\uc774\\ud638\\uc131 (\\ud328) \\uc815\\uc218\\uadfc (\\uc138) \\uc784\\ucc3d\\uc6a9 (\\ud648\\ub7f0) \\uae40\\ubc14\\uc704</p>\\r']\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n",
      "(승) 이호성 (패) 정수근 (세) 임창용 (홈런) 김바위</p>\r\n"
     ]
    }
   ],
   "source": [
    "mydata=data[6340:8353+len('top-score end')]\n",
    "import re\n",
    "p=re.compile(u'.승.+')\n",
    "#p=re.compile(u'.두산.')\n",
    "#res=p.search(data)\n",
    "found=p.findall(mydata)\n",
    "print found\n",
    "for item in found:\n",
    "    print item\n",
    "#print res.group()\n",
    "#findall?\n",
    "#print res.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## xpath\n",
    "\n",
    "* url\n",
    "http://www.kbreport.com/main\n",
    "\n",
    "* 경기결과의 표 구성: 11줄 (표 제목 포함)\n",
    "    * 표 제목 (table header) th\n",
    "    * 표 행 (table row ) tr\n",
    "    * 표 셀 (table cell) td\n",
    "\n",
    "순위 | 팀명 | 승 | 무 |  |  |  |  |  |  | 연속\n",
    "----|-----|---|---|--|--|--|--|--|--|--\n",
    "1   |     |   |   |  |  |  |  |  |  | 2승\n",
    "2   |     |   |   |  |  |  |  |  |  | 2패\n",
    "\n",
    "* selector\n",
    "\n",
    "xpath | 결과\n",
    "-----|-----\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")``` | 표 11줄\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td\")``` | 100개\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td[@class='center']\")``` | 20개\n",
    "```$x(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr/td//a\")``` | 팀명 10개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* requests를 사용해서 url을 읽어온다.\n",
    "* 전체 길이를 len()을 사용해서 알 수 있다.\n",
    "* lxml을 사용해서 tree 구조를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://www.kbreport.com/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50011"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "_htmlTree = lxml.etree.HTML(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* tree에서 전체 행 11개를 가져온다.\n",
    "* 행의 셀이 서로 구조가 다르다. 잘 읽어 오는지 확인한다.\n",
    "    * 팀명은 a href로 구성되어 있고, 결과는 배열이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 [] [] Next Row\n",
      "1 [u'\\ub450\\uc0b0'] [] Next Row\n",
      "2 ['NC'] [] Next Row\n",
      "3 [u'\\ub125\\uc13c'] [] Next Row\n",
      "4 ['LG'] [] Next Row\n",
      "5 ['KIA'] [] Next Row\n",
      "6 ['SK'] [] Next Row\n",
      "7 [u'\\ud55c\\ud654'] [] Next Row\n",
      "8 [u'\\ub86f\\ub370'] [] Next Row\n",
      "9 [u'\\uc0bc\\uc131'] [] Next Row\n",
      "10 ['kt'] [] Next Row\n"
     ]
    }
   ],
   "source": [
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    print teams[0].text, teams[1].xpath('.//a/text()'), teams[2].xpath('.//a/text()'),\n",
    "    print \"Next Row\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* nodes는 결과가 여러 개 목록이므로 배열\n",
    "* 배열 nodes의 개별 요소 teams는 '_Element'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'lxml.etree._Element'>\n"
     ]
    }
   ],
   "source": [
    "print type(nodes)\n",
    "print type(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0번째 행:  tr\n",
      "-- 1번째 행, 태그: [<Element th at 0x7fbe8504b368>, <Element th at 0x7fbe84facf80>, <Element th at 0x7fbe84fac908>, <Element th at 0x7fbe84fac9e0>, <Element th at 0x7fbe84fac950>, <Element th at 0x7fbe84fac878>, <Element th at 0x7fbe84faca28>, <Element th at 0x7fbe84facdd0>, <Element th at 0x7fbe84facb00>, <Element th at 0x7fbe84facb48>]\n",
      "-- 2번째 행, 태그 2번째 (팀명): 두산\n",
      "-- 2번째 행, 태그 3번째 문자열: 93\n",
      "-- 2번째 행, 태그 3번째 태그: td\n"
     ]
    }
   ],
   "source": [
    "print \"-- 0번째 행: \", nodes[0].tag\n",
    "print \"-- 1번째 행, 태그:\", nodes[0].getchildren()\n",
    "print \"-- 2번째 행, 태그 2번째 (팀명):\", nodes[1].getchildren()[1].xpath(\".//a\")[0].text\n",
    "print \"-- 2번째 행, 태그 3번째 문자열:\", nodes[1].getchildren()[2].text\n",
    "print \"-- 2번째 행, 태그 3번째 태그:\", nodes[1].getchildren()[2].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 연습 후, if문으로 a link와 아닌 경우로 나누어 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\n"
     ]
    }
   ],
   "source": [
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    for cols in teams:\n",
    "        if cols.xpath('.//a/text()'):\n",
    "            print cols.xpath('.//a/text()')[0],\n",
    "        else:\n",
    "            print cols.text.strip(),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 프로그램으로 실행\n",
    "\n",
    "* 지금까지 실행했던 명령어를 정리하여 프로그램으로 작성한다.\n",
    "* 파일은 src 디렉토리에 .py 확장자로 저장한다.\n",
    "* 검색어가 한글이 포함되어 있어 인코딩을 정한다. 첫째줄에 utf-8을 적어준다.\n",
    "```\n",
    "# coding: utf-8\n",
    "```\n",
    "\n",
    "* 명령창을 열고 실행한다:\n",
    "```\n",
    "$ python src/ds_web_crawl_kbaseball.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lxml.etree\n",
    "\n",
    "r = requests.get('http://www.kbreport.com/main')\n",
    "_htmlTree = lxml.etree.HTML(r.text)\n",
    "nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "print \"테이블 행 갯수: \", len(nodes)\n",
    "counter=0\n",
    "for teams in nodes:\n",
    "    for cols in teams:\n",
    "        if cols.xpath('.//a/text()'):\n",
    "            print cols.xpath('.//a/text()')[0],\n",
    "        else:\n",
    "            print cols.text.strip(),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 구조를 만들어 프로그램으로 만든다.\n",
    "    * 라이브러로 만들거나,\n",
    "    * 테스트하거나,\n",
    "    * 시작 점을 분명하게 할 수 있다.\n",
    "* main() 함수\n",
    "    * ```if __name__ == \"__main__\"```는 명령창에서 실행할 경우, 처음 실행되는 main()함수 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ds_web_crawl_kbaseball.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds_web_crawl_kbaseball.py\n",
    "# coding: utf-8\n",
    "import requests\n",
    "import lxml.etree\n",
    "\n",
    "def getkb():\n",
    "    r = requests.get('http://www.kbreport.com/main')\n",
    "    _htmlTree = lxml.etree.HTML(r.text)\n",
    "    nodes = _htmlTree.xpath(\"//div[@class='team-rank-box']//table[@class='team-rank']//tr\")\n",
    "    print \"테이블 행 갯수: \", len(nodes)\n",
    "    counter=0\n",
    "    for teams in nodes:\n",
    "        for cols in teams:\n",
    "            if cols.xpath('.//a/text()'):\n",
    "                print cols.xpath('.//a/text()')[0],\n",
    "            else:\n",
    "                print cols.text.strip(),\n",
    "        print\n",
    "\n",
    "def main():\n",
    "    getkb()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 행 갯수:  11\r\n",
      "순위 팀명 승 무 패 승률 게임차 득점 실점 연속\r\n",
      "1 두산 93 1 50 0.650 0.0 935 682 2승\r\n",
      "2 NC 83 3 58 0.589 9.0 857 690 2패\r\n",
      "3 넥센 77 1 66 0.538 16.0 813 757 3패\r\n",
      "4 LG 71 2 71 0.500 21.5 786 807 1패\r\n",
      "5 KIA 70 1 73 0.490 23.0 803 785 2패\r\n",
      "6 SK 69 0 75 0.479 24.5 753 784 1승\r\n",
      "7 한화 66 3 75 0.468 26.0 826 908 3승\r\n",
      "8 롯데 66 0 78 0.458 27.5 777 865 2승\r\n",
      "9 삼성 65 1 78 0.454 28.0 852 869 1패\r\n",
      "10 kt 53 2 89 0.373 39.5 672 927 2승\r\n"
     ]
    }
   ],
   "source": [
    "!python src/ds_web_crawl_kbaseball.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.9 동적 페이지에서 데이터 수집\n",
    "\n",
    "### 1.9.1 동적 페이지\n",
    "\n",
    "HTML은 정적페이지, Static Web Page이다. 웹페이지가 열리면, 단순히 읽을 수 있기만 가능하다. 열린 페이지는 내용이 변경되지 않는다.\n",
    "\n",
    "동적페이지는 사용자의 요청, 상황에 따라 내용이 변경된다. 클라이언트측 또는 서버측에서 그 페이지를 갱신할 수 있다.\n",
    "클라이언트측에서는 예를 들면 자바스크립트를 사용하여 사용자가 요청하면 내용이 새로 생성되어 웹페이지 변경된다.\n",
    "서버측에서도 내용을 변경하여 클라이언트로 전송할 수 있다. JSP, PHP를 사용하는 것이 좋은 예다.\n",
    "특히 자바스크립트가 포함된 페이지는 추출하려는 내용이 동적으로 생성되기 때문에 문제가 된다. HTML 파서는 정적페이지에서 정보를 추출하기 때문이다. 동적페이지는 자바스크립트를 실행하면서 데이터를 추출해야 한다.\n",
    "\n",
    "구분 | 설명 | 언어\n",
    "-----|-----|-----\n",
    "클라이언트 측 스크립트 | 클라이언트 측에서 내용이 변경된다. 사용자가 웹페이지에서 마우스 클릭 또는 키보드 입력을 하면 클라이언트에서 내용이 생성되어 페이지를 변경한다. | Javascript, Flash\n",
    "서버 측 스크립트 | 서버측에서 내용을 생성하여 전송된다. 웹페이지를 변경하려면 서버로 전송, 처리 결과를 받아서 변경한다.  | JSP, PHP, ASP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.9.2 Selenium\n",
    "\n",
    "GUI화면을 프로그램으로 조작할 수 있는 라이브러리이다. Python, Java, Javascript, Perl, PHP, C# 등 많은 언어를 지원한다. 테스트 또는 스크레이핑할 경우 활용된다.\n",
    "\n",
    "#### Selenium 설치\n",
    "\n",
    "Python에서 사용하므로, pip를 사용하여 설치한다.\n",
    "```\n",
    "pip install selenium\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### webdriver 설치\n",
    "\n",
    "웹드라이버는 웹브라우저를 프로그램에서 호출하여 사용하기 위해 설치한다.\n",
    "설치하고 올바르게 설정하면 selenium에서 웹브라우저가 뜨게 된다.\n",
    "Chrome, FireFox, Internet Explorer 등을 지원한다.\n",
    "\n",
    "* 윈도우에서 설치\n",
    "\n",
    "해당 사이트로 가서 실행파일을 내려받아 설치한다.\n",
    "크롬을 설치해 보자.\n",
    "해당 사이트 [Chrome](http://chromedriver.storage.googleapis.com/index.html)에서 'chromedriver_win32.zip'을 내려받는다.\n",
    "zip을 풀어 놓고, 그 경로에서 호출한다.\n",
    "\n",
    "```\n",
    "from selenium import webdriver\n",
    "webdriver.Chrome(\"path/to/chromedriver\") # exe를 뒤에 안붙여도 된다.\n",
    "```\n",
    "\n",
    "* 리눅스에서 설치\n",
    "\n",
    "```\n",
    "sudo port install ChromeDriver # osx\n",
    "pip install chrome-driver # Ubuntu\n",
    "```\n",
    "\n",
    "경로가 설정되지 않으면 Python에서 경로오류가 발생한다.설치하고 나면 쉘에서 버전을 확인할 수 있다.\n",
    "Python에서 사용하려면, 'webdriver.chrome.driver'를 사전에 설정한다.\n",
    "```\n",
    "os.environ[\"webdriver.chrome.driver\"]=\"/usr/local/bin/chromedriver\"\n",
    "```\n",
    "\n",
    "#### PhantomJS 설치\n",
    "\n",
    "웹브라우저 없이 프로그램에서 driver를 사용할 경우에는 PhantomJS를 사용한다. 이를 headless browser라고 한다.\n",
    "\n",
    "* 윈도우에서 설치\n",
    "http://phantomjs.org/download.html phantomjs-x.x.x-windows.zip을 다운로드, unzip한 후 bin에 있는 실행파일을 사용한다.\n",
    "\n",
    "```\n",
    "from selenium import webdriver\n",
    "webdriver.Chrome(\"path/to/phantomjs\") # exe를 뒤에 안붙여도 된다.\n",
    "```\n",
    "\n",
    "* 리눅스에서 설치\n",
    "\n",
    "아래 패키지를 설치한다. 우분투 apt는 일부 기능만을 설치하므로, npm으로 설치한다.\n",
    "\n",
    "```\n",
    "npm install -g phantomjs(o)\n",
    "apt install phantomjs (x, 부분설치)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromeDriver 2.26.436382 (70eb799287ce4c2208441fc057053a5b07ceabac)\r\n"
     ]
    }
   ],
   "source": [
    "!chromedriver -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.9.3 간단한 명령어\n",
    "\n",
    "\n",
    "#### driver\n",
    "driver.page_source\n",
    "driver.implicitly_wait(30)\n",
    "driver.close() or quit()\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "driver.close() | focus가 있는 웹브라우저 닫기\n",
    "driver.quit() | driver.dispose()를 호출해서, 브라우저 모두 닫고 WebDriver session 끝냄\n",
    "\n",
    "#### form\n",
    "\n",
    "* send_keys()\n",
    "* click() - a link 또는 button을 선택하여 mouse click\n",
    "* submit() - form을 click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### finding elements\n",
    "\n",
    "* WebElement는 size, tag_name, text를 검색할 수 있다. 복수일 경우 elements를 사용한다.\n",
    "finding_element_by_id(), finding_element_by_name(), finding_element_by_class_name(), finding_element_by_tag_name(), finding_element_by_css_selector() 함수를 제공\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python.org에서 검색어를 프로그램에서 정해서 실행을 요청해 보자.\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "find_element_by_name(\"q\") | 'name'이 \"q\"인 태그를 찾는다.\n",
    "send_keys(\"pycon\") | 키보드 입력을 대신한다. \"pycon\"을 입력한다는 의미이다.\n",
    "send_keys(Keys.RETURN) | 'Keys.RETURN' 키보드 엔터를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#driver = webdriver.Chrome()\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "#assert \"No results found.\" not in driver.page_source\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyCon Pakistan\n",
      "Kiwi PyCon 2017\n",
      "PyCon Pune 2018\n",
      "Florida PyCon\n",
      "PyCon Colombia 2018\n",
      "PyCon India 2017\n",
      "PyCon Jamaica 2017\n",
      "PyCon FR 2017\n",
      "PyCon Ireland 2017\n",
      "PyCon Australia 2013\n",
      "PyCon Ireland 2012\n",
      "PyCon Ireland 2016\n",
      "PyCon Uruguay 2013\n",
      "PyCon US 2014\n",
      "PyCon Ukraine 2016\n",
      "Kiwi PyCon 2016\n",
      "PyCon US 2019\n",
      "PyCon UK 2013\n",
      "PyCon Italia 5\n",
      "PyCon CZ 2017\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "_html=driver.page_source\n",
    "soup=BeautifulSoup(_html,\"lxml\")\n",
    "for e in soup.select(\"h3 a\"):\n",
    "    print e.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-7: 로그인이 필요한 사이버강의실에서 강의계획서를 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "사이버강의실은 강의관련 공지, 강의계획서, 강의슬라이드와 같은 자료를 제공한다. 학교의 사이버강의실은 보통 개방되어 있지 않고 사용자의 로그인이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 해결\n",
    "\n",
    "* 사용자이름, 비밀번호를 넣을 수 있는 서식을 찾는다.\n",
    "* 이름, 비밀번호에 값을 넣는다.\n",
    "* 서버요청 버튼을 찾아서 클릭한다.\n",
    "* 여러 교과목 가운데 수강과목을 찾아 클릭한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://ecampus.smu.ac.kr/\")\n",
    "username=driver.find_element_by_id(\"input-username\")\n",
    "username.send_keys(\"myuserid\")\n",
    "password=driver.find_element_by_id(\"input-password\")\n",
    "password.send_keys(\"mypassword\")\n",
    "loginButton=driver.find_element_by_name(\"loginbutton\")\n",
    "loginButton.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* My Page로 가면 교과목 목록을 볼 수 있다.\n",
    "* 교과목 목록에서 \"컴퓨팅사고\" 과목을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mypage=driver.find_element_by_link_text(\"My Page\")\n",
    "mypage.click()\n",
    "mypage=driver.find_element_by_partial_link_text(\"컴퓨팅사고\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 파일 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/ds3_7_ecampus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_7_ecampus.py\n",
    "from selenium import webdriver\n",
    "\n",
    "def readEcampus():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://ecampus.smu.ac.kr/\")\n",
    "    username=driver.find_element_by_id(\"input-username\")\n",
    "    username.send_keys(\"myuserid\")\n",
    "    password=driver.find_element_by_id(\"input-password\")\n",
    "    password.send_keys(\"mypassword\")\n",
    "    loginButton=driver.find_element_by_name(\"loginbutton\")\n",
    "    loginButton.click()\n",
    "\n",
    "    mypage=driver.find_element_by_link_text(\"My Page\")\n",
    "    mypage.click()\n",
    "    mypage=driver.find_element_by_partial_link_text(\"컴퓨팅사고\")\n",
    "\n",
    "def main():\n",
    "    #readWikiLxml()\n",
    "    readWikiBS()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-8: 한국 프로야구 선수 기록 크롤링하기 (1)\n",
    "\n",
    "### 문제\n",
    "\n",
    "앞서 팀순위를 가져오는 프로그램을 만들었다. 선수기록을 가져와보자. 이전에 했던 방식으로 하면 가져올 수 없다는 것을 알게 된다.\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지로 가서 소스보기를 해본다. \n",
    "선수기록은 동적인 페이지로 구성되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 자바스크립트가 포함된 페이지\n",
    "\n",
    "* 야구데이터는 검색엔진을 이용하며, 검색결과가 정적인 HTML로 반환되지 않고 있다. 그래서 자세한 검색에 대한 결과를 스크레이핑 하려면 이 문제를 해결해야 한다.\n",
    "* 동적페이지, javascript가 페이지를 생성하면 크롤링을 할 수 없다.\n",
    "클래스 \".ltb-table\"는 테이블 조회결과이다. 개발자도구 콘솔에서 자바스크립트로 보면 그결과를 볼 수 있지만, BeautifulSoup에서는 불가능하다.\n",
    "\n",
    "http://www.kbreport.com/leader/main페이지를 살펴보면, '#/{{page}}'과 같이 내부 href를 생성하고 있다.\n",
    "\n",
    "```\n",
    "\t$(document).ready(function(){\n",
    "\t\tpaging.action({\n",
    "\t\t\tid : \"paging\"\n",
    "\t\t\t, totalCount : setNumber('284')\n",
    "\t\t\t, page : setNumber('1')\n",
    "\t\t\t, rows : setNumber('20')\n",
    "\t\t\t, allView : true\n",
    "\t\t\t, pageGroup : 5\n",
    "\t\t\t, link : \"#/{{page}}\"\n",
    "\t\t});\n",
    "\t\tswitched=false;\n",
    "\t\tupdateTables();\n",
    "\t});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 더 해보기\n",
    "\n",
    "* '더보기 >>' 버튼의 크롤링\n",
    "* css 크롤링\n",
    "* 검색조건을 넣어서 크롤링\n",
    "    * url 검색 'http://www.kbreport.com/player/list?key=이대호'\n",
    "\n",
    "    * javascript console 창\n",
    "```\n",
    "> $$('.dca-cb-table1 td')[0].innerText\n",
    "\"이대호\"\n",
    "> $$('.dca-cb-table1 td')[1].innerText\n",
    "\"1982-06-21\"\n",
    "> $$('.dca-cb-table1 td')[2].innerText\n",
    "\"2017\"\n",
    "> $$('.dca-cb-table1 td')[3].innerText\n",
    "\"롯데\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-9: 한국 프로야구 선수 기록 크롤링하기 (2)\n",
    "\n",
    "### 문제\n",
    "\n",
    "다른 사이트 www.koreabaseball.com를 스크레이핑해보자.\n",
    "\n",
    "### 해결\n",
    "\n",
    "웹페이지를 가져온다.\n",
    "데이터를 추출한다.\n",
    "단, paging에 javascript이 있어서 추가 작업이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "urlkorbase='http://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx'\n",
    "data=requests.get(urlkorbase).text\n",
    "#print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 문제 웹데이터-10: 다음에서 환율 가져오기\n",
    "\n",
    "### 문제\n",
    "\n",
    "다음에 게시되고 있는 환율을 추출해 보자.\n",
    "자바스크립트가 포함되어 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "미국 (USD)달러1137.00▲3.001156.891117.111148.101125.903.091.00\n",
      "일본 (JPY100)엔1016.72▲7.781034.51998.931026.681006.761.930.89\n",
      "중국 (CNY)위안172.82▲0.65181.46164.18174.54171.106.700.15\n",
      "유로 (EUR)유로1360.14▲8.701387.201333.081373.741346.541.571.20\n",
      "영국 (GBP)파운드1544.27▲12.801574.691513.851559.711528.832.231.36\n",
      "스위스 (CHF)프랑1174.34▲7.971197.471151.211186.081162.601.191.03\n",
      "캐나다 (CAD)달러923.60▲5.20941.79905.41932.83914.373.270.81\n",
      "뉴질랜드 (NZD)달러827.96▼0.94844.27811.65836.23819.694.220.73\n",
      "홍콩 (HKD)달러145.62▲0.33148.48142.76147.07144.172.580.13\n",
      "브라질 (BRL)레알362.36▼0.31399.32333.380.00358.028.580.32\n",
      "멕시코 (MXN)페소63.61-0.0066.1556.6264.2462.989.590.06\n",
      "아랍에미리트 (AED)디르함309.55▲0.81321.93288.20312.64306.463.400.27\n",
      "쿠웨이트 (KWD)디나르3772.40▲11.833923.293470.613810.123734.683.253.32\n",
      "바레인 (BHD)디나르3013.92▲7.563134.472772.813044.052983.794.172.65\n",
      "인도 (INR)루피17.50-0.000.000.000.000.008.220.02\n",
      "사우디아라비아 (SAR)리얄303.18▲0.80315.30282.27306.21300.153.420.27\n",
      "노르웨이 (NOK)크로네145.82▲0.73149.39142.25147.27144.372.920.13\n",
      "덴마크 (DKK)크로나182.78▲1.15187.25178.31184.60180.961.690.16\n",
      "말레이지아 (MYR)링키트270.84▲0.71284.38254.590.00268.145.160.24\n",
      "방글라데시 (BDT)타카13.87▲0.0414.4212.210.000.007.240.01\n",
      "파키스탄 (PKR)루피10.79▲0.0311.229.500.000.007.880.01\n",
      "인도네시아 (IDR100)루피아8.54▼0.029.137.698.628.466.880.01\n",
      "대만 (TWD)달러37.63▲0.1041.0135.000.000.002.520.03\n",
      "필리핀 (PHP)페소22.36▲0.1324.3721.4722.5822.145.240.02\n",
      "스웨덴 (SEK)크로나142.74▲0.75146.23139.25144.16141.321.630.13\n",
      "호주 (AUD)달러901.30▲2.09919.05883.55910.31892.293.980.79\n",
      "싱가포르 (SGD)달러842.72▲3.93859.49825.95851.14834.303.270.74\n",
      "태국 (THB)바트34.35▲0.1336.0632.2934.6934.013.480.03\n",
      "이집트 (EGP)파운드64.38▲0.090.000.000.000.0010.720.06\n",
      "브루나이 (BND)달러842.72▲3.96876.42792.160.000.003.270.74\n",
      "이스라엘 (ILS)쉐캐림324.17▲2.07337.13298.240.000.002.130.29\n",
      "요르단 (JOD)디나르1603.67▲4.231667.811475.380.000.006.711.41\n",
      "베트남 (VND100)동5.00▲0.015.594.415.054.953.670.00\n",
      "러시아 (RUB)루블19.64▲0.1121.0117.4819.8319.4510.650.02\n",
      "헝가리 (HUF)포린트4.39▲0.044.744.044.434.351.790.00\n",
      "폴란드 (PLN)줄러티318.30▲2.78343.76292.84321.80314.803.600.28\n",
      "남아프리카공화국 (ZAR)자르85.72▲0.8090.8678.8786.7484.708.820.08\n",
      "몽골 (MNT)투그릭0.46-0.000.540.380.000.0015.530.00\n",
      "체코 (CZK)코루나52.15▲0.3555.8047.4652.7251.582.230.05\n",
      "카자흐스탄 (KZT)텡게3.35▲0.023.712.990.000.0012.220.00\n",
      "카타르 (QAR)리얄312.30▲0.910.000.000.000.003.420.27\n",
      "터키 (TRY)리라325.16▲1.76351.17299.15328.73321.5915.720.29\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get('http://finance.daum.net/exchange/exchangeMain.daum')\n",
    "soup=BeautifulSoup(driver.page_source, \"lxml\")\n",
    "exchange=soup.select(\"#exchangeTB tbody tr.trData\")\n",
    "print len(exchange)\n",
    "for e in exchange:\n",
    "    print e.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습\n",
    "\n",
    "* 크롤링은 수집하는 데이터가 비구조적이라 쉽지 않다.\n",
    "* 관심있는 웹 사이트를 대상으로 크롤링을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-1: UC Irvine 기계학습 데이터\n",
    "\n",
    "* UC Irvine 기계학습 데이터 banknote authentication Data Set를 프로그래밍으로 가져와서 \n",
    "클래스별로 'entropy of image'의 평균을 구하시오\n",
    "* http://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-2: 기상청 도별 날씨 가져오기\n",
    "\n",
    "### 문제\n",
    "날씨는 다양하게 소비되고 있다. 농사, 스포츠, 야외행사, 그날의 의상 등 많은 경우에 날씨가 적지 않게 영향을 미치고 있다. 날씨는 API를 직접 사용하거나, 웹페이지에서 추출할 수 있다. 기상청 웹페이지에 게시되고 있는 날씨를 가져와 보자.\n",
    "\n",
    "* 기상청 http://www.kma.go.kr/index.jsp의 날씨\n",
    "* css selector\n",
    "    ```\n",
    "    $$('.region_weather_e')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load /home/jsl/Code/git/bb/smu/exam/2017s1/mid/big/201311207/p2.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get('http://www.kma.go.kr/weather/observation/currentweather.jsp')\n",
    "bs = BeautifulSoup(r.text, 'lxml')\n",
    "weather = bs.select('.table_develop3 > tbody > tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(weather)\n",
    "print type(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 서울 구름많음 16.0 8 6 26.2 13.3 73  45 남 2.9 1011.7 \n",
      " 백령도 맑음 20 이상 2 2 21.4 17.3 69  78 남남동 6.2 1010.9 \n",
      " 인천 구름많음 20 이상 6 0 25.7 15.9 73  55 서남서 2.6 1012.2 \n",
      " 수원 구름많음 19.6 6 2 25.9 12.3 72  43 서남서 2.5 1012.2 \n",
      " 동두천  20 이상   25.1 12.6 71  46 남 1.6 1011.8 \n",
      " 파주  20 이상   24.9 14.6 72  53 남서 3.1 1012.1 \n",
      " 강화  16.4   23.4 12.3 70  50 서남서 3.5 1012.5 \n",
      " 양평  20 이상   24.8 11.7 71  44 서 1.6 1012.3 \n",
      " 이천  17.6   25.1 11.2 71  42 서남서 1.6 1012.3 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 북춘천 구름많음 20 이상 7 3 23.3 12.2 70  50 남동 1.5 1012.1 \n",
      " 북강릉 구름많음 20 이상 8 1 22.9 15.4 70  63 동 2.2 1011.5 \n",
      " 울릉도 흐림 20 이상 9 6 22.8 17.9 71  74 동 2.2 1012.2 \n",
      " 속초  20 이상   22.7 15.0 70  62 남동 1.3 1011.5 \n",
      " 철원  20 이상   23.7 10.3 69  43 남 2.3 1011.7 \n",
      " 대관령  20 이상   20.3 10.3 66  53 북서 2.0 1010.2 \n",
      " 춘천  20 이상   23.2 13.3 70  54 서남서 1.7 1012.3 \n",
      " 강릉  20 이상   25.2 13.7 72  49 남남동 2.5 1011.6 \n",
      " 동해  19.8   25.1 17.0 73  61 동남동 3.6 1011.6 \n",
      " 원주  20 이상   23.8 10.8 70  44 서북서 1.5 1011.6 \n",
      " 영월  20 이상   23.8 11.1 70  45 북북서 1.9 1011.3 \n",
      " 인제  20 이상   22.4 11.1 68  49 남서 2.0 1011.6 \n",
      " 홍천  20 이상   24.4 14.7 71  55 북서 1.4 1011.8 \n",
      " 태백  20 이상   22.0 8.8 67  43 남남서 3.5 1009.3 \n",
      " 정선군  16.5   23.9 8.7 69  38 북북동 4.6 1011.0 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 서산 구름조금 20 이상 3 0 24.7 14.4 72  53 서남서 4.0 1013.2 \n",
      " 청주 구름조금 20 이상 5 3 26.2 10.7 72  38 서 1.6 1011.9 \n",
      " 대전 구름조금 20 이상 4 2 26.0 14.1 73  48 서북서 1.6 1012.2 \n",
      " 충주  20 이상   24.6 12.5 71  47 서남서 2.4 1012.2 \n",
      " 추풍령  20 이상   25.3 13.1 72  47 서남서 1.3 1011.5 \n",
      " 홍성(예)     25.2 15.7 73  56 남서 2.9 1012.1 \n",
      " 제천  20 이상   23.9 10.1 70  42 북서 2.5 1011.1 \n",
      " 보은  20 이상   25.2 14.0 72  50 남남서 1.8 1012.1 \n",
      " 천안  20 이상   25.0 6.6 70  31 남서 1.9 1012.1 \n",
      " 보령  19.9   24.4 18.7 73  71 남서 2.3 1012.9 \n",
      " 부여  19.4   25.5 12.3 72  44 서 2.2 1012.5 \n",
      " 금산  20 이상   25.7 12.5 72  44 북 1.7 1011.6 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 전주 구름조금 20 이상 4 4 26.4 14.8 73  49 서남서 2.9 1012.1 \n",
      " 광주 구름조금 20 이상 3 3 26.8 14.5 74  47 서남서 2.0 1012.3 \n",
      " 목포 맑음 18.9 2 2 25.1 19.2 74  70 서북서 3.8 1012.9 \n",
      " 여수 맑음 20 이상 0 0 25.8 14.8 73  51 남 1.9 1011.9 \n",
      " 흑산도 맑음 19.7 2 2 23.0 21.9 73  94 남동 0.6 1012.7 \n",
      " 군산  19.7   25.0 16.1 73  58 서 4.7 1012.8 \n",
      " 완도  18.3   25.6 20.3 75  73 동남동 1.8 1012.3 \n",
      " 고창  17.8   25.2 18.8 74  68 북서 3.4 1012.6 \n",
      " 순천  18.1   25.8 14.8 73  51 서남서 1.6 1011.3 \n",
      " 진도(첨찰산)     23.8 18.4 72  72 북북동 1.7 1011.3 \n",
      " 부안  20 이상   25.5 15.7 73  55 서북서 3.2 1012.9 \n",
      " 임실  17.4   26.1 9.0 71  34 남남서 1.4 1011.7 \n",
      " 정읍  20 이상   26.6 15.3 74  50 서남서 2.6 1012.2 \n",
      " 남원  20 이상   25.8 8.7 71  34 서남서 2.2 1011.8 \n",
      " 장수  20 이상   23.9 9.4 69  40 남 2.9 1010.7 \n",
      " 고창군  20 이상   27.4 14.4 74  45 서남서 1.9 1011.9 \n",
      " 영광군  17.6   25.8 14.2 73  49 북서 3.4 1012.5 \n",
      " 순창군  17.9   25.6 10.6 71  39 서북서 3.4 1012.3 \n",
      " 보성군  20 이상   25.8 14.2 73  49 남 1.4 1012.5 \n",
      " 강진군  17.6   27.8 17.0 76  52 서 1.7 1012.6 \n",
      " 장흥  20 이상   26.1 13.5 73  46 북서 1.3 1011.9 \n",
      " 해남  20 이상   27.7 14.3 75  44 남서 3.1 1012.1 \n",
      " 고흥  19.3   25.3 14.4 72  51 서북서 2.8 1012.0 \n",
      " 광양시  20 이상   25.6 14.3 73  50 남 1.4 1012.0 \n",
      " 진도군  19.1   26.3 18.4 75  62 서남서 2.0 1011.8 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 제주 구름많음 20 이상 7 7 25.7 18.3 74 0.0 64 북동 4.5 1012.5 \n",
      " 고산  19.4   28.1 22.5 79 0.0 72 서북서 5.8 1012.3 \n",
      " 성산  20 이상   25.4 17.5 74 3.3 62 동북동 2.2 1012.1 \n",
      " 서귀포  20 이상   25.7 21.3 76 0.0 77 남 1.8 1012.0 \n",
      " 지점 현재일기 시정 운량 중하운량 현재기온 이슬점온도 불쾌지수 일강수 습도 풍향 풍속 해면기압 \n",
      " 안동 구름조금 20 이상 4 2 25.5 10.5 71  39 서북서 1.8 1011.8 \n",
      " 포항 맑음 20 이상 2 2 23.7 17.8 72  70 북북동 2.8 1012.1 \n",
      " 대구 구름조금 20 이상 3 1 26.3 10.8 72  38 북서 1.8 1011.6 \n",
      " 울산 맑음 20 이상 2 2 25.0 16.4 73  59 동 2.9 1011.5 \n",
      " 창원 맑음 20 이상 1 1 26.6 17.0 75  56 동 2.3 1011.6 \n",
      " 부산 맑음 20 이상 2 2 26.1 17.1 74  58 남동 4.0 1011.6 \n",
      " 울진  20 이상   24.2 17.4 72  66 동 2.9 1012.2 \n",
      " 상주  16.0   26.0 13.4 73  46 남 1.0 1012.0 \n",
      " 통영  18.3   26.2 15.8 74  53 남남동 2.6 1012.0 \n",
      " 진주  20 이상   26.3 10.0 72  36 서북서 1.2 1012.0 \n",
      " 김해시  17.7   27.4 14.4 74  45 남서 1.9 1012.1 \n",
      " 북창원  20 이상   26.9 12.8 73  42 북서 1.2 1011.5 \n",
      " 양산시  20 이상   28.1 13.2 74  40 남남서 1.8 1012.6 \n",
      " 의령군  16.0   27.2 13.8 74  44 동남동 0.5 1011.8 \n",
      " 함양군  20 이상   26.3 15.6 74  52 남남동 0.9 1011.4 \n",
      " 봉화  20 이상   23.7 10.7 70  44 서북서 0.9 1011.1 \n",
      " 영주  19.7   25.1 11.6 71  43 남동 1.7 1011.5 \n",
      " 문경  20 이상   23.4 10.4 69  44 남동 1.1 1012.0 \n",
      " 청송군  20 이상   25.0 12.5 71  46 서북서 1.3 1011.4 \n",
      " 영덕  19.8   25.6 13.7 72  48 동남동 2.1 1012.1 \n",
      " 의성  20 이상   26.4 9.2 72  34 북북서 1.7 1011.8 \n",
      " 구미  19.8   25.0 14.7 72  53 서남서 1.3 1012.1 \n",
      " 영천  20 이상   26.6 9.4 72  34 서북서 1.4 1011.5 \n",
      " 경주시  20 이상   26.7 13.7 73  45 북 1.9 1011.8 \n",
      " 거창  20 이상   24.6 13.7 71  51 동남동 1.1 1010.9 \n",
      " 합천  20 이상   27.1 8.5 72  31 남동 1.0 1011.6 \n",
      " 밀양  20 이상   29.2 8.8 74  28 남 0.8 1011.5 \n",
      " 산청  20 이상   26.7 14.4 74  47 서북서 1.0 1011.3 \n",
      " 거제  19.7   26.2 17.5 74  59 북 1.8 1011.8 \n",
      " 남해  20 이상   26.0 16.2 74  55 북동 1.3 1012.0 \n"
     ]
    }
   ],
   "source": [
    "data=list()\n",
    "for row in weather: \n",
    "    rowList=row.get_text().split('\\n')\n",
    "    data.append(rowList)\n",
    "    for cell in rowList:\n",
    "        print cell,\n",
    "    print \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/ds3_x2_kmaWeather.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_x2_kmaWeather.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def readWeather():\n",
    "    try:\n",
    "        r = requests.get('http://www.kma.go.kr/weather/observation/currentweather.jsp')\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print e\n",
    "        sys.exit(1)\n",
    "    bs = BeautifulSoup(r.text, 'lxml')\n",
    "    weather = bs.select('.table_develop3 > tbody > tr')\n",
    "    data=list()\n",
    "    for row in weather:\n",
    "        rowList=row.get_text().split('\\n')\n",
    "        data.append(rowList)\n",
    "        for cell in rowList:\n",
    "            print cell,\n",
    "        print\n",
    "\n",
    "def main():\n",
    "    readWeather()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-3: 국가통계 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "http://kosis.kr/index/index.jsp\n",
    "kosis='http://kosis.kr/statisticsList/statisticsList_01List.jsp?vwcd=MT_ZTITLE&parentId=A#SubCont'\n",
    "data=requests.get(urlkorbase).text\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-4: 신문 기사 및 댓글 스크레이핑 해보기\n",
    "\n",
    "\n",
    "우리나라 한국은행이 빅데이터를 활용해 경제정책에 반영하는 방안을 마련하고 있다. 세계 여러 나라가 웹에서 수집한 데이터를 활용해 물가, 소비, 경제심리와 관련한 통계 및 분석에 활용하는 추세에 발맞추어 가는 것으로 보인다. 한국은행은 빅데이터 업무를 담당할 '빅데이터통계연구반'을 설치하고 2017년 8월 활동을 시작했다고 한다.\n",
    "SNS, 경제기사에 대한 댓글, 경제관련 기사를 분석하여 경제정책에 반영할 계획으로 알려졌다.\n",
    "* [BIG KINDS-Pro](http://www.bigkinds.or.kr/)\n",
    "    * 2016년 개편 후, 데이터분석 기능을 제공\n",
    "    * 스크레이핑의 params이 검색에 문자열로 붙지 않는 문제가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 연습 웹데이터-5: 영화 리뷰의 분석\n",
    "\n",
    "### 문제\n",
    "\n",
    "'어떤 영화를 볼까?'라고 질문에 댓글을 읽어보고 결정하는 사람들이 꽤 있다.\n",
    "온라인 상에는 상영하고 있는 영화에 댓글을 다는 기능이 있다.\n",
    "댓글에서 의미있는 데이터를 추출하여 영화에 대해 긍정적, 부정적 의견이 어떠한지 분류할 수 있다.\n",
    "댓글을 분석하여 해당 영화의 매출을 예측하기도 한다.\n",
    "영화 리뷰를 분석하여 의미있는 정보를 추출하는 관련 학술 논문이 많다.\n",
    "\n",
    "* http://movielens.org\n",
    "* Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. \"Thumbs up?: sentiment classification using machine learning techniques.\" Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10. Association for Computational Linguistics, 2002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습 웹데이터-6: 댓글\n",
    "\n",
    "### 문제\n",
    "\n",
    "경향신문, \"사라지는 촌지·접대에 '찬성 89%'..업계는 여전히 '3·5·10' 규정 반발\"\n",
    "다음 포털의 댓글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get('http://v.media.daum.net/v/20170926225302536')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 더보기를 클릭하는 수만큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morelink=driver.find_element_by_css_selector(\"a[href='#more']\")\n",
    "morelink.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments=driver.find_element_by_css_selector('.cmt_box .list_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 부정 부패, 청탁 없이는 생존할 수 없는 업종이라면 없어지는게 맞겠지.\n",
      "1 김영란법 찬성! 학교촌지는 예전부터 사라졌었고 학교에서 명절되면 교장교감에게 선물하던 관행없어져 너무 좋다!  월급도 많이 받는 상사들이 왜 아랫사람들에게 선물 받는걸 당연시 여겼던 건지\n",
      "2 았싸 1빠..........왜 자꾸 상향 조정 할라카능겨,,,,, 더 줄이고 싶은디,,,\n",
      "3 후대를 위해서도  반드시 시행되어야한다\n",
      "4 기레기들아 받던거 못받으니까 미쳐돌겠지?\n",
      "5 부정부패 때문에 성업하는 사업이 있다면 \n",
      "\n",
      "망해도 지금 망하는게 훗날\n",
      "\n",
      "더 크게 안망하는 법이다.\n",
      "\n",
      "선물 보다 정말 말한마디, 행동하나 정성을 다해봅시다.\n",
      "\n",
      "말 한마디가 천냥빛도 갚는 다 잖아요\n",
      "6 이런 것이 바로 한국이 얼마나 후진적이며, 부정부패에 절어 있는지를 그대로 보여주는 척도 아니겠는가? 저희들 먹고 살겠다고 국가 전체를 썩게 만들어도 상관없다는 ... ㅉㅉㅉ! 부끄러운 줄도 모르고 ...\n",
      "7 식사 1만원, 선물 1만원, 경조사비  5만원(1·1·5규정)\n",
      "로 바꾸자\n",
      "8 반드시 지켜야한다\n",
      "9 국회의원도 참여해라\n",
      "10 우리 모두 청탁없는 깨끗한 사회 만듭시다. 3/5/10도   2/3/5으로 줄입시다.\n",
      "11 언론인 만 반대가 최고. 이 개시엑끼들은  지들은 ♩♪ 정의로운 척 하는데 뒤 구멍으로는 쓸어 담고 싶어서. 퉤.\n",
      "12 받은개들 전부 쏴주겨라\n",
      "13 학교가 깨끗해지고 있다.\n",
      "\n",
      "이젠 학생들이 주는 커피나 음료 절대 안 받는다.\n",
      "\n",
      "예전엔 성의라고 받아 주었으나 이젠 안받아도 될 김영란법이 있어서 좋다.\n",
      "\n",
      "계속 이렇게 가자! 너무 좋다.\n",
      "14 위에서 아래로주는건 선물\n",
      "아래서 위로주는건  뇌물\n",
      "15 김영란법이후로 학부모 상담 갈때 부담이 사라졌습니다. 예의상 뇌물이 아닌 선물로  쿠키 한상자라도 들고 가야하나 늘 마음이 불편했습니다. 전 직장인으로써도 좋습니다. 정이라고 자꾸 들어오는 커피.빵..간식들 부담스러웠네요..이제 시작인데 없어지면 안됩니다\n",
      "16 참. 어이 상실이다\n",
      "뇌물인정 수위를 낮추어 달라?\n",
      "이 나라가 얼마나 썩어 있었는지\n",
      "17 3/5/10이 아닌라 \n",
      "\n",
      "0/0/0이 바람직하다\n",
      "18 안받고 안주면 되는것을 뇌물을 흥정한다는게\n",
      "참 추접스럽다.\n",
      "19 청탁금지법 때문에\n",
      "타격 입는 산업이 있다면\n",
      "부정부패로 비정상적으로 유지된 산업이므로\n",
      "청렴한 국가로 가기 위해서\n",
      "망해버리거나 강제 구조조정해야 함\n",
      "20 미친 뇌물이 없어져서 망한다는 산업은 원래 경쟁력이 없는거야..♬♪.그냥 망해\n",
      "21 3-5-10이 삼천원 오천원 만원을ㄹ 얘기하는거면 개정찬성.\n",
      "\n",
      "솔직히 자식학교에 선생보러 가는데 빈손은 좀 그렇다.  캔커피 오백원짜리 여섯개묶음 하나 정도는..\n",
      "\n",
      "갑질하는 공무원들한테 솔직히 빈손으로 가기는 좀 그렇다. 박카스 1Box정도는.\n",
      "\n",
      "제발 니들돈으로 사먹고 술마시고 상품사고골프치고 해라. 개베이비들아\n",
      "\n",
      "최소한의 양심의 가책은 느끼며 받아먹으란 말이다.\n",
      "22 아직도 뿌리가 남아있다\n",
      "더강력한 제도 만들어라\n",
      "23 불이익도 있겠지만 투명한 사회를 위해서 꼭 필요하고 농축산등은 앓는 소리보다 김영란벚에 맞는 상품을 개발하고 판매하시는게 합당할 것 같음\n",
      "24 업계들아\n",
      "세상 좋아진다는데\n",
      "뒷다리 잡지 마라.\n",
      "25 난교사꿈꾸는사람이지만선물안받아도하나도안아쉽고.촌지안받아도됌. 진짜로 .월급만받고아이들편지만받아도좋을거같음 . 김영란법완전지지하고 여기저기비리나접대나이런거다사라졌음좋겠음ㅜㅜ!\n",
      "26 바꾸지마 청탁금지법 부정부패로 먹고 살고싶냐\n",
      "27 더 강화해야지..좋은법도 희생이 불가피하다.\n",
      "28 영란언니 최고!!!\n",
      "29 부정을 부추기지 마라\n",
      "부정에 기생하려마라\n",
      "부정없는게 얼마나 정정당당인가?\n",
      "30 기레기들 받아처먹던거 이제 지들 돈주고 사서 처먹어야되니 돈 아까운가보다 ㅋㅋㅋㅋㅋㅋ\n",
      "31 식사 0원, 선물 0원, 경조사비  0원(ㅇㆍㅇㆍ0규정)\n",
      "으로 새로 바꾸세요\n",
      "32 직무관련성이 없으면 한번에 100만원까지 선물할 수 있다 ㅡ  관련성이  없으면  미쳣다고  100만을  주냐\n",
      "이거는  공식적으로  뇌물을 받아  먹겟다는  건가\n",
      "농축산업 당신네들  배 불리려고 나라가 뇌물국으로 가야합니까  어이없네요\n"
     ]
    }
   ],
   "source": [
    "txt=comments.find_elements_by_class_name('desc_txt')\n",
    "for count,e in enumerate(txt):\n",
    "    print count,e.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup으로 가져와서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(driver.page_source,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commentInfo=soup.select('.list_comment .cmt_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAUM 바로가기두기2017.09.26 22:58부정 부패, 청탁 없이는 생존할 수 없는 업종이라면 없어지는게 맞겠지.답글쓰기댓글 찬성하기593댓글 비추천하기5 DAUM 바로가기느티나무2017.09.26 23:01김영란법 찬성! 학교촌지는 예전부터 사라졌었고 학교에서 명절되면 교장교감에게 선물하던 관행없어져 너무 좋다!  월급도 많이 받는 상사들이 왜 아랫사람들에게 선물 받는걸 당연시 여겼던 건지답글쓰기댓글 찬성하기512댓글 비추천하기7 DAUM 바로가기미이2017.09.26 22:58았싸 1빠..........왜 자꾸 상향 조정 할라카능겨,,,,, 더 줄이고 싶은디,,,답글 1댓글 찬성하기386댓글 비추천하기8 DAUM 바로가기qjqantk2017.09.26 23:00후대를 위해서도  반드시 시행되어야한다답글쓰기댓글 찬성하기192댓글 비추천하기4 DAUM 바로가기가오리2017.09.26 23:00기레기들아 받던거 못받으니까 미쳐돌겠지?답글 2댓글 찬성하기190댓글 비추천하기4 DAUM 바로가기21212017.09.26 23:03부정부패 때문에 성업하는 사업이 있다면 \n",
      "\n",
      "망해도 지금 망하는게 훗날\n",
      "\n",
      "더 크게 안망하는 법이다.\n",
      "\n",
      "선물 보다 정말 말한마디, 행동하나 정성을 다해봅시다.\n",
      "\n",
      "말 한마디가 천냥빛도 갚는 다 잖아요답글쓰기댓글 찬성하기160댓글 비추천하기3 DAUM 바로가기밝은하늘2017.09.26 23:04이런 것이 바로 한국이 얼마나 후진적이며, 부정부패에 절어 있는지를 그대로 보여주는 척도 아니겠는가? 저희들 먹고 살겠다고 국가 전체를 썩게 만들어도 상관없다는 ... ㅉㅉㅉ! 부끄러운 줄도 모르고 ...답글 2댓글 찬성하기146댓글 비추천하기2 DAUM 바로가기후아아2017.09.26 23:01식사 1만원, 선물 1만원, 경조사비  5만원(1·1·5규정)\n",
      "로 바꾸자답글 2댓글 찬성하기147댓글 비추천하기4 DAUM 바로가기HugaGage2017.09.26 23:01반드시 지켜야한다답글쓰기댓글 찬성하기145댓글 비추천하기5 DAUM 바로가기구라왕2017.09.26 23:04국회의원도 참여해라답글쓰기댓글 찬성하기138댓글 비추천하기2 DAUM 바로가기happywon2017.09.26 23:04우리 모두 청탁없는 깨끗한 사회 만듭시다. 3/5/10도   2/3/5으로 줄입시다.답글쓰기댓글 찬성하기112댓글 비추천하기3 DAUM 바로가기태평2017.09.26 23:04언론인 만 반대가 최고. 이 개시엑끼들은  지들은 ♩♪ 정의로운 척 하는데 뒤 구멍으로는 쓸어 담고 싶어서. 퉤.답글 1댓글 찬성하기96댓글 비추천하기2 DAUM 바로가기하림2017.09.26 23:02받은개들 전부 쏴주겨라답글쓰기댓글 찬성하기76댓글 비추천하기4 DAUM 바로가기SimonRyu2017.09.26 23:10학교가 깨끗해지고 있다.\n",
      "\n",
      "이젠 학생들이 주는 커피나 음료 절대 안 받는다.\n",
      "\n",
      "예전엔 성의라고 받아 주었으나 이젠 안받아도 될 김영란법이 있어서 좋다.\n",
      "\n",
      "계속 이렇게 가자! 너무 좋다.답글쓰기댓글 찬성하기52댓글 비추천하기2 DAUM 바로가기음식쓰레기통2017.09.26 23:09위에서 아래로주는건 선물\n",
      "아래서 위로주는건  뇌물답글쓰기댓글 찬성하기44댓글 비추천하기2 DAUM 바로가기iyoulike2017.09.26 23:06김영란법이후로 학부모 상담 갈때 부담이 사라졌습니다. 예의상 뇌물이 아닌 선물로  쿠키 한상자라도 들고 가야하나 늘 마음이 불편했습니다. 전 직장인으로써도 좋습니다. 정이라고 자꾸 들어오는 커피.빵..간식들 부담스러웠네요..이제 시작인데 없어지면 안됩니다답글 1댓글 찬성하기42댓글 비추천하기2 DAUM 바로가기적폐청산2017.09.26 23:04참. 어이 상실이다\n",
      "뇌물인정 수위를 낮추어 달라?\n",
      "이 나라가 얼마나 썩어 있었는지답글쓰기댓글 찬성하기41댓글 비추천하기2 DAUM 바로가기중궈2017.09.26 23:063/5/10이 아닌라 \n",
      "\n",
      "0/0/0이 바람직하다답글 1댓글 찬성하기40댓글 비추천하기2 DAUM 바로가기적폐청산2017.09.26 23:05안받고 안주면 되는것을 뇌물을 흥정한다는게\n",
      "참 추접스럽다.답글쓰기댓글 찬성하기38댓글 비추천하기2 DAUM 바로가기물새한마리2017.09.26 23:14청탁금지법 때문에\n",
      "타격 입는 산업이 있다면\n",
      "부정부패로 비정상적으로 유지된 산업이므로\n",
      "청렴한 국가로 가기 위해서\n",
      "망해버리거나 강제 구조조정해야 함답글쓰기댓글 찬성하기37댓글 비추천하기2 DAUM 바로가기파란색2017.09.26 23:08미친 뇌물이 없어져서 망한다는 산업은 원래 경쟁력이 없는거야..♬♪.그냥 망해답글쓰기댓글 찬성하기34댓글 비추천하기2 DAUM 바로가기한국남자2017.09.26 23:033-5-10이 삼천원 오천원 만원을ㄹ 얘기하는거면 개정찬성.\n",
      "\n",
      "솔직히 자식학교에 선생보러 가는데 빈손은 좀 그렇다.  캔커피 오백원짜리 여섯개묶음 하나 정도는..\n",
      "\n",
      "갑질하는 공무원들한테 솔직히 빈손으로 가기는 좀 그렇다. 박카스 1Box정도는.\n",
      "\n",
      "제발 니들돈으로 사먹고 술마시고 상품사고골프치고 해라. 개베이비들아\n",
      "\n",
      "최소한의 양심의 가책은 느끼며 받아먹으란 말이다.답글 1댓글 찬성하기34댓글 비추천하기3 DAUM 바로가기바른생활맨2017.09.26 23:02아직도 뿌리가 남아있다\n",
      "더강력한 제도 만들어라답글쓰기댓글 찬성하기32댓글 비추천하기3 DAUM 바로가기천-hㅏ2017.09.26 23:12불이익도 있겠지만 투명한 사회를 위해서 꼭 필요하고 농축산등은 앓는 소리보다 김영란벚에 맞는 상품을 개발하고 판매하시는게 합당할 것 같음답글쓰기댓글 찬성하기19댓글 비추천하기2 DAUM 바로가기인호파더2017.09.26 23:16업계들아\n",
      "세상 좋아진다는데\n",
      "뒷다리 잡지 마라.답글쓰기댓글 찬성하기17댓글 비추천하기2 DAUM 바로가기unsun2017.09.27 00:13난교사꿈꾸는사람이지만선물안받아도하나도안아쉽고.촌지안받아도됌. 진짜로 .월급만받고아이들편지만받아도좋을거같음 . 김영란법완전지지하고 여기저기비리나접대나이런거다사라졌음좋겠음ㅜㅜ!답글쓰기댓글 찬성하기15댓글 비추천하기0 DAUM 바로가기강가2017.09.26 23:11바꾸지마 청탁금지법 부정부패로 먹고 살고싶냐답글쓰기댓글 찬성하기15댓글 비추천하기2 DAUM 바로가기^ ^2017.09.26 23:10더 강화해야지..좋은법도 희생이 불가피하다.답글쓰기댓글 찬성하기15댓글 비추천하기2 DAUM 바로가기애미다2017.09.26 23:11영란언니 최고!!!답글쓰기댓글 찬성하기14댓글 비추천하기2 DAUM 바로가기기본이2017.09.26 23:09부정을 부추기지 마라\n",
      "부정에 기생하려마라\n",
      "부정없는게 얼마나 정정당당인가?답글쓰기댓글 찬성하기14댓글 비추천하기2 DAUM 바로가기홀로2017.09.27 00:09기레기들 받아처먹던거 이제 지들 돈주고 사서 처먹어야되니 돈 아까운가보다 ㅋㅋㅋㅋㅋㅋ답글쓰기댓글 찬성하기12댓글 비추천하기0 DAUM 바로가기씨유2017.09.26 23:58식사 0원, 선물 0원, 경조사비  0원(ㅇㆍㅇㆍ0규정)\n",
      "으로 새로 바꾸세요이모티콘상세보기답글쓰기댓글 찬성하기12댓글 비추천하기0 DAUM 바로가기씨유2017.09.26 23:52직무관련성이 없으면 한번에 100만원까지 선물할 수 있다 ㅡ  관련성이  없으면  미쳣다고  100만을  주냐\n",
      "이거는  공식적으로  뇌물을 받아  먹겟다는  건가\n",
      "농축산업 당신네들  배 불리려고 나라가 뇌물국으로 가야합니까  어이없네요답글쓰기댓글 찬성하기12댓글 비추천하기0\n"
     ]
    }
   ],
   "source": [
    "for e in commentInfo:\n",
    "    print e.text,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "두기\n",
      "2017.09.26 22:58\n",
      "부정 부패, 청탁 없이는 생존할 수 없는 업종이라면 없어지는게 맞겠지.\n",
      "댓글 찬성하기593\n",
      "댓글 비추천하기5\n",
      "-----\n",
      "느티나무\n",
      "2017.09.26 23:01\n",
      "김영란법 찬성! 학교촌지는 예전부터 사라졌었고 학교에서 명절되면 교장교감에게 선물하던 관행없어져 너무 좋다!  월급도 많이 받는 상사들이 왜 아랫사람들에게 선물 받는걸 당연시 여겼던 건지\n",
      "댓글 찬성하기512\n",
      "댓글 비추천하기7\n",
      "-----\n",
      "미이\n",
      "2017.09.26 22:58\n",
      "았싸 1빠..........왜 자꾸 상향 조정 할라카능겨,,,,, 더 줄이고 싶은디,,,\n",
      "댓글 찬성하기386\n",
      "댓글 비추천하기8\n",
      "-----\n",
      "qjqantk\n",
      "2017.09.26 23:00\n",
      "후대를 위해서도  반드시 시행되어야한다\n",
      "댓글 찬성하기192\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "가오리\n",
      "2017.09.26 23:00\n",
      "기레기들아 받던거 못받으니까 미쳐돌겠지?\n",
      "댓글 찬성하기190\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "2121\n",
      "2017.09.26 23:03\n",
      "부정부패 때문에 성업하는 사업이 있다면 \n",
      "\n",
      "망해도 지금 망하는게 훗날\n",
      "\n",
      "더 크게 안망하는 법이다.\n",
      "\n",
      "선물 보다 정말 말한마디, 행동하나 정성을 다해봅시다.\n",
      "\n",
      "말 한마디가 천냥빛도 갚는 다 잖아요\n",
      "댓글 찬성하기160\n",
      "댓글 비추천하기3\n",
      "-----\n",
      "밝은하늘\n",
      "2017.09.26 23:04\n",
      "이런 것이 바로 한국이 얼마나 후진적이며, 부정부패에 절어 있는지를 그대로 보여주는 척도 아니겠는가? 저희들 먹고 살겠다고 국가 전체를 썩게 만들어도 상관없다는 ... ㅉㅉㅉ! 부끄러운 줄도 모르고 ...\n",
      "댓글 찬성하기146\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "후아아\n",
      "2017.09.26 23:01\n",
      "식사 1만원, 선물 1만원, 경조사비  5만원(1·1·5규정)\n",
      "로 바꾸자\n",
      "댓글 찬성하기147\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "HugaGage\n",
      "2017.09.26 23:01\n",
      "반드시 지켜야한다\n",
      "댓글 찬성하기145\n",
      "댓글 비추천하기5\n",
      "-----\n",
      "구라왕\n",
      "2017.09.26 23:04\n",
      "국회의원도 참여해라\n",
      "댓글 찬성하기138\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "happywon\n",
      "2017.09.26 23:04\n",
      "우리 모두 청탁없는 깨끗한 사회 만듭시다. 3/5/10도   2/3/5으로 줄입시다.\n",
      "댓글 찬성하기112\n",
      "댓글 비추천하기3\n",
      "-----\n",
      "태평\n",
      "2017.09.26 23:04\n",
      "언론인 만 반대가 최고. 이 개시엑끼들은  지들은 ♩♪ 정의로운 척 하는데 뒤 구멍으로는 쓸어 담고 싶어서. 퉤.\n",
      "댓글 찬성하기96\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "하림\n",
      "2017.09.26 23:02\n",
      "받은개들 전부 쏴주겨라\n",
      "댓글 찬성하기76\n",
      "댓글 비추천하기4\n",
      "-----\n",
      "SimonRyu\n",
      "2017.09.26 23:10\n",
      "학교가 깨끗해지고 있다.\n",
      "\n",
      "이젠 학생들이 주는 커피나 음료 절대 안 받는다.\n",
      "\n",
      "예전엔 성의라고 받아 주었으나 이젠 안받아도 될 김영란법이 있어서 좋다.\n",
      "\n",
      "계속 이렇게 가자! 너무 좋다.\n",
      "댓글 찬성하기52\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "음식쓰레기통\n",
      "2017.09.26 23:09\n",
      "위에서 아래로주는건 선물\n",
      "아래서 위로주는건  뇌물\n",
      "댓글 찬성하기44\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "iyoulike\n",
      "2017.09.26 23:06\n",
      "김영란법이후로 학부모 상담 갈때 부담이 사라졌습니다. 예의상 뇌물이 아닌 선물로  쿠키 한상자라도 들고 가야하나 늘 마음이 불편했습니다. 전 직장인으로써도 좋습니다. 정이라고 자꾸 들어오는 커피.빵..간식들 부담스러웠네요..이제 시작인데 없어지면 안됩니다\n",
      "댓글 찬성하기42\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "적폐청산\n",
      "2017.09.26 23:04\n",
      "참. 어이 상실이다\n",
      "뇌물인정 수위를 낮추어 달라?\n",
      "이 나라가 얼마나 썩어 있었는지\n",
      "댓글 찬성하기41\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "중궈\n",
      "2017.09.26 23:06\n",
      "3/5/10이 아닌라 \n",
      "\n",
      "0/0/0이 바람직하다\n",
      "댓글 찬성하기40\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "적폐청산\n",
      "2017.09.26 23:05\n",
      "안받고 안주면 되는것을 뇌물을 흥정한다는게\n",
      "참 추접스럽다.\n",
      "댓글 찬성하기38\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "물새한마리\n",
      "2017.09.26 23:14\n",
      "청탁금지법 때문에\n",
      "타격 입는 산업이 있다면\n",
      "부정부패로 비정상적으로 유지된 산업이므로\n",
      "청렴한 국가로 가기 위해서\n",
      "망해버리거나 강제 구조조정해야 함\n",
      "댓글 찬성하기37\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "파란색\n",
      "2017.09.26 23:08\n",
      "미친 뇌물이 없어져서 망한다는 산업은 원래 경쟁력이 없는거야..♬♪.그냥 망해\n",
      "댓글 찬성하기34\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "한국남자\n",
      "2017.09.26 23:03\n",
      "3-5-10이 삼천원 오천원 만원을ㄹ 얘기하는거면 개정찬성.\n",
      "\n",
      "솔직히 자식학교에 선생보러 가는데 빈손은 좀 그렇다.  캔커피 오백원짜리 여섯개묶음 하나 정도는..\n",
      "\n",
      "갑질하는 공무원들한테 솔직히 빈손으로 가기는 좀 그렇다. 박카스 1Box정도는.\n",
      "\n",
      "제발 니들돈으로 사먹고 술마시고 상품사고골프치고 해라. 개베이비들아\n",
      "\n",
      "최소한의 양심의 가책은 느끼며 받아먹으란 말이다.\n",
      "댓글 찬성하기34\n",
      "댓글 비추천하기3\n",
      "-----\n",
      "바른생활맨\n",
      "2017.09.26 23:02\n",
      "아직도 뿌리가 남아있다\n",
      "더강력한 제도 만들어라\n",
      "댓글 찬성하기32\n",
      "댓글 비추천하기3\n",
      "-----\n",
      "천-hㅏ\n",
      "2017.09.26 23:12\n",
      "불이익도 있겠지만 투명한 사회를 위해서 꼭 필요하고 농축산등은 앓는 소리보다 김영란벚에 맞는 상품을 개발하고 판매하시는게 합당할 것 같음\n",
      "댓글 찬성하기19\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "인호파더\n",
      "2017.09.26 23:16\n",
      "업계들아\n",
      "세상 좋아진다는데\n",
      "뒷다리 잡지 마라.\n",
      "댓글 찬성하기17\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "unsun\n",
      "2017.09.27 00:13\n",
      "난교사꿈꾸는사람이지만선물안받아도하나도안아쉽고.촌지안받아도됌. 진짜로 .월급만받고아이들편지만받아도좋을거같음 . 김영란법완전지지하고 여기저기비리나접대나이런거다사라졌음좋겠음ㅜㅜ!\n",
      "댓글 찬성하기15\n",
      "댓글 비추천하기0\n",
      "-----\n",
      "강가\n",
      "2017.09.26 23:11\n",
      "바꾸지마 청탁금지법 부정부패로 먹고 살고싶냐\n",
      "댓글 찬성하기15\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "^ ^\n",
      "2017.09.26 23:10\n",
      "더 강화해야지..좋은법도 희생이 불가피하다.\n",
      "댓글 찬성하기15\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "애미다\n",
      "2017.09.26 23:11\n",
      "영란언니 최고!!!\n",
      "댓글 찬성하기14\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "기본이\n",
      "2017.09.26 23:09\n",
      "부정을 부추기지 마라\n",
      "부정에 기생하려마라\n",
      "부정없는게 얼마나 정정당당인가?\n",
      "댓글 찬성하기14\n",
      "댓글 비추천하기2\n",
      "-----\n",
      "홀로\n",
      "2017.09.27 00:09\n",
      "기레기들 받아처먹던거 이제 지들 돈주고 사서 처먹어야되니 돈 아까운가보다 ㅋㅋㅋㅋㅋㅋ\n",
      "댓글 찬성하기12\n",
      "댓글 비추천하기0\n",
      "-----\n",
      "씨유\n",
      "2017.09.26 23:58\n",
      "식사 0원, 선물 0원, 경조사비  0원(ㅇㆍㅇㆍ0규정)\n",
      "으로 새로 바꾸세요\n",
      "댓글 찬성하기12\n",
      "댓글 비추천하기0\n",
      "-----\n",
      "씨유\n",
      "2017.09.26 23:52\n",
      "직무관련성이 없으면 한번에 100만원까지 선물할 수 있다 ㅡ  관련성이  없으면  미쳣다고  100만을  주냐\n",
      "이거는  공식적으로  뇌물을 받아  먹겟다는  건가\n",
      "농축산업 당신네들  배 불리려고 나라가 뇌물국으로 가야합니까  어이없네요\n",
      "댓글 찬성하기12\n",
      "댓글 비추천하기0\n"
     ]
    }
   ],
   "source": [
    "for e in commentInfo:\n",
    "    print \"-----\"\n",
    "    print e.find(\"a\",{\"class\":\"link_nick clickable\"}).text\n",
    "    print e.find(\"span\",{\"class\":\"txt_date\"}).text\n",
    "    print e.find(\"p\",{\"class\":\"desc_txt\"}).text\n",
    "    print e.find(\"button\",{\"class\":\"#like\"}).text\n",
    "    print e.find(\"button\",{\"class\":\"#dislike\"}).text"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
